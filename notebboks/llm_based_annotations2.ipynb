{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "from anthropic import Anthropic\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import io, csv, json, math, textwrap\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "\n",
    "# Load .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get key from environment\n",
    "api_key = os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "\n",
    "# Initialize client\n",
    "client = Anthropic(api_key=api_key)\n",
    "\n",
    "# Send a simple prompt\n",
    "response = client.messages.create(\n",
    "    model=\"claude-3-7-sonnet-20250219\",\n",
    "    max_tokens=200,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Say hello\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response.content[0].text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/.cs/conda/envs/interplm/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd, torch, os, gc\n",
    "from interplm.sae.inference import load_sae_from_hf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "DEVICE=\"cuda\"\n",
    "DTYPE=torch.float16\n",
    "\n",
    "DATA_DIR = Path(\"esm_sae_results\"); DATA_DIR.mkdir(exist_ok=True)\n",
    "SEQUENCES_DIR = Path(\"/home/ec2-user/SageMaker/InterPLM/data/uniprot/subset_25k.csv\")\n",
    "# ANNOTATIONS_DIR = Path(\"uniprotkb_swissprot_annotations.tsv.gz\")\n",
    "ANNOTATIONS_DIR = Path(\"/home/ec2-user/SageMaker/InterPLM/uniprotkb_swissprot_annotations.tsv.gz\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t33_650M_UR50D and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/esm2_t33_650M_UR50D\", do_lower_case=False)\n",
    "model     = AutoModel.from_pretrained(\"facebook/esm2_t33_650M_UR50D\",\n",
    "                                        output_hidden_states=True).to(DEVICE).eval()\n",
    "\n",
    "# Make sure the SAE you load matches the *plm_model* and *plm_layer* you want to use\n",
    "plm_model = \"esm2-650m\"   # matches your checkpoint naming\n",
    "plm_layer = 24            # <= MUST match esm_layer_sel\n",
    "sae = load_sae_from_hf(plm_model=plm_model, plm_layer=plm_layer).to(DEVICE).eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 6)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "features_all = pd.read_pickle(\"features_all.pkl\")\n",
    "features_all.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uniprot_id</th>\n",
       "      <th>length</th>\n",
       "      <th>features</th>\n",
       "      <th>max_activation</th>\n",
       "      <th>n_active_features</th>\n",
       "      <th>reconstruction_mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q9GL23</td>\n",
       "      <td>50</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002...</td>\n",
       "      <td>1.265625</td>\n",
       "      <td>1876</td>\n",
       "      <td>45.198380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q6GZU6</td>\n",
       "      <td>50</td>\n",
       "      <td>[0.00023197175, 0.0, 0.0, 0.0, 0.0013056946, 0...</td>\n",
       "      <td>0.843262</td>\n",
       "      <td>2168</td>\n",
       "      <td>13.467114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P9WJG6</td>\n",
       "      <td>50</td>\n",
       "      <td>[0.0, 0.00057144166, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>0.935059</td>\n",
       "      <td>1740</td>\n",
       "      <td>12.720748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P18924</td>\n",
       "      <td>51</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.000...</td>\n",
       "      <td>0.956543</td>\n",
       "      <td>1799</td>\n",
       "      <td>11.394856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q08076</td>\n",
       "      <td>52</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.000...</td>\n",
       "      <td>1.139648</td>\n",
       "      <td>1772</td>\n",
       "      <td>24.694654</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  uniprot_id  length                                           features  \\\n",
       "0     Q9GL23      50  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002...   \n",
       "1     Q6GZU6      50  [0.00023197175, 0.0, 0.0, 0.0, 0.0013056946, 0...   \n",
       "2     P9WJG6      50  [0.0, 0.00057144166, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "3     P18924      51  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.000...   \n",
       "4     Q08076      52  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.000...   \n",
       "\n",
       "   max_activation  n_active_features  reconstruction_mse  \n",
       "0        1.265625               1876           45.198380  \n",
       "1        0.843262               2168           13.467114  \n",
       "2        0.935059               1740           12.720748  \n",
       "3        0.956543               1799           11.394856  \n",
       "4        1.139648               1772           24.694654  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations_df = pd.read_csv(ANNOTATIONS_DIR, sep=\"\\t\", compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Entry</th>\n",
       "      <th>Reviewed</th>\n",
       "      <th>Protein names</th>\n",
       "      <th>Length</th>\n",
       "      <th>Sequence</th>\n",
       "      <th>EC number</th>\n",
       "      <th>Active site</th>\n",
       "      <th>Binding site</th>\n",
       "      <th>Cofactor</th>\n",
       "      <th>Disulfide bond</th>\n",
       "      <th>...</th>\n",
       "      <th>Helix</th>\n",
       "      <th>Turn</th>\n",
       "      <th>Beta strand</th>\n",
       "      <th>Coiled coil</th>\n",
       "      <th>Domain [CC]</th>\n",
       "      <th>Compositional bias</th>\n",
       "      <th>Domain [FT]</th>\n",
       "      <th>Motif</th>\n",
       "      <th>Region</th>\n",
       "      <th>Zinc finger</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A0A009IHW8</td>\n",
       "      <td>reviewed</td>\n",
       "      <td>2' cyclic ADP-D-ribose synthase AbTIR (2'cADPR...</td>\n",
       "      <td>269</td>\n",
       "      <td>MSLEQKKGADIISKILQIQNSIGKTTSPSTLKTKLSEISRKEQENA...</td>\n",
       "      <td>3.2.2.-; 3.2.2.6</td>\n",
       "      <td>ACT_SITE 208; /evidence=\"ECO:0000255|PROSITE-P...</td>\n",
       "      <td>BINDING 143; /ligand=\"NAD(+)\"; /ligand_id=\"ChE...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>HELIX 143..145; /evidence=\"ECO:0007829|PDB:7UW...</td>\n",
       "      <td>TURN 146..149; /evidence=\"ECO:0007829|PDB:7UWG...</td>\n",
       "      <td>STRAND 135..142; /evidence=\"ECO:0007829|PDB:7U...</td>\n",
       "      <td>COILED 31..99; /evidence=\"ECO:0000255\"</td>\n",
       "      <td>DOMAIN: The TIR domain mediates NAD(+) hydrola...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DOMAIN 133..266; /note=\"TIR\"; /evidence=\"ECO:0...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A0A023I7E1</td>\n",
       "      <td>reviewed</td>\n",
       "      <td>Glucan endo-1,3-beta-D-glucosidase 1 (Endo-1,3...</td>\n",
       "      <td>796</td>\n",
       "      <td>MRFQVIVAAATITMITSYIPGVASQSTSDGDDLFVPVSNFDPKSIF...</td>\n",
       "      <td>3.2.1.39</td>\n",
       "      <td>ACT_SITE 500; /evidence=\"ECO:0000255|PROSITE-P...</td>\n",
       "      <td>BINDING 504; /ligand=\"(1,3-beta-D-glucosyl)n\";...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>HELIX 42..44; /evidence=\"ECO:0007829|PDB:4K35\"...</td>\n",
       "      <td>TURN 287..289; /evidence=\"ECO:0007829|PDB:4K35...</td>\n",
       "      <td>STRAND 56..58; /evidence=\"ECO:0007829|PDB:4K35...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DOMAIN 31..759; /note=\"GH81\"; /evidence=\"ECO:0...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>REGION 31..276; /note=\"beta-sandwich subdomain...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A0A024B7W1</td>\n",
       "      <td>reviewed</td>\n",
       "      <td>Genome polyprotein [Cleaved into: Capsid prote...</td>\n",
       "      <td>3423</td>\n",
       "      <td>MKNPKKKSGGFRIVNMLKRGVARVSPFGGLKRLPAGLLLGHGPIRM...</td>\n",
       "      <td>2.1.1.56; 2.1.1.57; 2.7.7.48; 3.4.21.91; 3.6.1...</td>\n",
       "      <td>ACT_SITE 1553; /note=\"Charge relay system; for...</td>\n",
       "      <td>BINDING 1696..1703; /ligand=\"ATP\"; /ligand_id=...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DISULFID 350..406; /evidence=\"ECO:0000250|UniP...</td>\n",
       "      <td>...</td>\n",
       "      <td>HELIX 222..225; /evidence=\"ECO:0007829|PDB:6CO...</td>\n",
       "      <td>TURN 237..241; /evidence=\"ECO:0007829|PDB:6CO8...</td>\n",
       "      <td>STRAND 234..236; /evidence=\"ECO:0007829|PDB:6C...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DOMAIN: [Small envelope protein M]: The transm...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DOMAIN 1503..1680; /note=\"Peptidase S7\"; /evid...</td>\n",
       "      <td>MOTIF 1787..1790; /note=\"DEAH box\"; /evidence=...</td>\n",
       "      <td>REGION 1..25; /note=\"Disordered\"; /evidence=\"E...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A0A024RXP8</td>\n",
       "      <td>reviewed</td>\n",
       "      <td>Exoglucanase 1 (EC 3.2.1.91) (1,4-beta-cellobi...</td>\n",
       "      <td>514</td>\n",
       "      <td>MYRKLAVISAFLATARAQSACTLQSETHPPLTWQKCSSGGTCTQQT...</td>\n",
       "      <td>3.2.1.91</td>\n",
       "      <td>ACT_SITE 229; /note=\"Nucleophile\"; /evidence=\"...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DISULFID 21..89; /evidence=\"ECO:0000250|UniPro...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DOMAIN: The enzyme consists of two functional ...</td>\n",
       "      <td>COMPBIAS 401..437; /note=\"Polar residues\"; /ev...</td>\n",
       "      <td>DOMAIN 478..514; /note=\"CBM1\"; /evidence=\"ECO:...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>REGION 18..453; /note=\"Catalytic\"; /evidence=\"...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A0A024SC78</td>\n",
       "      <td>reviewed</td>\n",
       "      <td>Cutinase (EC 3.1.1.74)</td>\n",
       "      <td>248</td>\n",
       "      <td>MRSLAILTTLLAGHAFAYPKPAPQSVNRRDWPSINEFLSELAKVMP...</td>\n",
       "      <td>3.1.1.74</td>\n",
       "      <td>ACT_SITE 164; /note=\"Nucleophile\"; /evidence=\"...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DISULFID 55..91; /evidence=\"ECO:0000269|PubMed...</td>\n",
       "      <td>...</td>\n",
       "      <td>HELIX 51..69; /evidence=\"ECO:0007829|PDB:4PSC\"...</td>\n",
       "      <td>TURN 94..100; /evidence=\"ECO:0007829|PDB:4PSC\"...</td>\n",
       "      <td>STRAND 48..50; /evidence=\"ECO:0007829|PDB:4PSC...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DOMAIN: In contract to classical cutinases, po...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>REGION 31..70; /note=\"Lid covering the active ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Entry  Reviewed                                      Protein names  \\\n",
       "0  A0A009IHW8  reviewed  2' cyclic ADP-D-ribose synthase AbTIR (2'cADPR...   \n",
       "1  A0A023I7E1  reviewed  Glucan endo-1,3-beta-D-glucosidase 1 (Endo-1,3...   \n",
       "2  A0A024B7W1  reviewed  Genome polyprotein [Cleaved into: Capsid prote...   \n",
       "3  A0A024RXP8  reviewed  Exoglucanase 1 (EC 3.2.1.91) (1,4-beta-cellobi...   \n",
       "4  A0A024SC78  reviewed                             Cutinase (EC 3.1.1.74)   \n",
       "\n",
       "   Length                                           Sequence  \\\n",
       "0     269  MSLEQKKGADIISKILQIQNSIGKTTSPSTLKTKLSEISRKEQENA...   \n",
       "1     796  MRFQVIVAAATITMITSYIPGVASQSTSDGDDLFVPVSNFDPKSIF...   \n",
       "2    3423  MKNPKKKSGGFRIVNMLKRGVARVSPFGGLKRLPAGLLLGHGPIRM...   \n",
       "3     514  MYRKLAVISAFLATARAQSACTLQSETHPPLTWQKCSSGGTCTQQT...   \n",
       "4     248  MRSLAILTTLLAGHAFAYPKPAPQSVNRRDWPSINEFLSELAKVMP...   \n",
       "\n",
       "                                           EC number  \\\n",
       "0                                   3.2.2.-; 3.2.2.6   \n",
       "1                                           3.2.1.39   \n",
       "2  2.1.1.56; 2.1.1.57; 2.7.7.48; 3.4.21.91; 3.6.1...   \n",
       "3                                           3.2.1.91   \n",
       "4                                           3.1.1.74   \n",
       "\n",
       "                                         Active site  \\\n",
       "0  ACT_SITE 208; /evidence=\"ECO:0000255|PROSITE-P...   \n",
       "1  ACT_SITE 500; /evidence=\"ECO:0000255|PROSITE-P...   \n",
       "2  ACT_SITE 1553; /note=\"Charge relay system; for...   \n",
       "3  ACT_SITE 229; /note=\"Nucleophile\"; /evidence=\"...   \n",
       "4  ACT_SITE 164; /note=\"Nucleophile\"; /evidence=\"...   \n",
       "\n",
       "                                        Binding site Cofactor  \\\n",
       "0  BINDING 143; /ligand=\"NAD(+)\"; /ligand_id=\"ChE...      NaN   \n",
       "1  BINDING 504; /ligand=\"(1,3-beta-D-glucosyl)n\";...      NaN   \n",
       "2  BINDING 1696..1703; /ligand=\"ATP\"; /ligand_id=...      NaN   \n",
       "3                                                NaN      NaN   \n",
       "4                                                NaN      NaN   \n",
       "\n",
       "                                      Disulfide bond  ...  \\\n",
       "0                                                NaN  ...   \n",
       "1                                                NaN  ...   \n",
       "2  DISULFID 350..406; /evidence=\"ECO:0000250|UniP...  ...   \n",
       "3  DISULFID 21..89; /evidence=\"ECO:0000250|UniPro...  ...   \n",
       "4  DISULFID 55..91; /evidence=\"ECO:0000269|PubMed...  ...   \n",
       "\n",
       "                                               Helix  \\\n",
       "0  HELIX 143..145; /evidence=\"ECO:0007829|PDB:7UW...   \n",
       "1  HELIX 42..44; /evidence=\"ECO:0007829|PDB:4K35\"...   \n",
       "2  HELIX 222..225; /evidence=\"ECO:0007829|PDB:6CO...   \n",
       "3                                                NaN   \n",
       "4  HELIX 51..69; /evidence=\"ECO:0007829|PDB:4PSC\"...   \n",
       "\n",
       "                                                Turn  \\\n",
       "0  TURN 146..149; /evidence=\"ECO:0007829|PDB:7UWG...   \n",
       "1  TURN 287..289; /evidence=\"ECO:0007829|PDB:4K35...   \n",
       "2  TURN 237..241; /evidence=\"ECO:0007829|PDB:6CO8...   \n",
       "3                                                NaN   \n",
       "4  TURN 94..100; /evidence=\"ECO:0007829|PDB:4PSC\"...   \n",
       "\n",
       "                                         Beta strand  \\\n",
       "0  STRAND 135..142; /evidence=\"ECO:0007829|PDB:7U...   \n",
       "1  STRAND 56..58; /evidence=\"ECO:0007829|PDB:4K35...   \n",
       "2  STRAND 234..236; /evidence=\"ECO:0007829|PDB:6C...   \n",
       "3                                                NaN   \n",
       "4  STRAND 48..50; /evidence=\"ECO:0007829|PDB:4PSC...   \n",
       "\n",
       "                              Coiled coil  \\\n",
       "0  COILED 31..99; /evidence=\"ECO:0000255\"   \n",
       "1                                     NaN   \n",
       "2                                     NaN   \n",
       "3                                     NaN   \n",
       "4                                     NaN   \n",
       "\n",
       "                                         Domain [CC]  \\\n",
       "0  DOMAIN: The TIR domain mediates NAD(+) hydrola...   \n",
       "1                                                NaN   \n",
       "2  DOMAIN: [Small envelope protein M]: The transm...   \n",
       "3  DOMAIN: The enzyme consists of two functional ...   \n",
       "4  DOMAIN: In contract to classical cutinases, po...   \n",
       "\n",
       "                                  Compositional bias  \\\n",
       "0                                                NaN   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "3  COMPBIAS 401..437; /note=\"Polar residues\"; /ev...   \n",
       "4                                                NaN   \n",
       "\n",
       "                                         Domain [FT]  \\\n",
       "0  DOMAIN 133..266; /note=\"TIR\"; /evidence=\"ECO:0...   \n",
       "1  DOMAIN 31..759; /note=\"GH81\"; /evidence=\"ECO:0...   \n",
       "2  DOMAIN 1503..1680; /note=\"Peptidase S7\"; /evid...   \n",
       "3  DOMAIN 478..514; /note=\"CBM1\"; /evidence=\"ECO:...   \n",
       "4                                                NaN   \n",
       "\n",
       "                                               Motif  \\\n",
       "0                                                NaN   \n",
       "1                                                NaN   \n",
       "2  MOTIF 1787..1790; /note=\"DEAH box\"; /evidence=...   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "\n",
       "                                              Region Zinc finger  \n",
       "0                                                NaN         NaN  \n",
       "1  REGION 31..276; /note=\"beta-sandwich subdomain...         NaN  \n",
       "2  REGION 1..25; /note=\"Disordered\"; /evidence=\"E...         NaN  \n",
       "3  REGION 18..453; /note=\"Catalytic\"; /evidence=\"...         NaN  \n",
       "4  REGION 31..70; /note=\"Lid covering the active ...         NaN  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotations_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import random\n",
    "\n",
    "# # Parameters\n",
    "# N_FEATURES = 1200\n",
    "# BINS = np.arange(0, 1.1, 0.1)\n",
    "\n",
    "# # Randomly select feature ids\n",
    "# all_feature_ids = list(range(len(features_all.iloc[0].features)))\n",
    "# print(\"num features\", len(all_feature_ids))\n",
    "# selected_features = random.sample(all_feature_ids, N_FEATURES)\n",
    "\n",
    "# print(f\"Selected {len(selected_features)} features out of {len(all_feature_ids)}\")\n",
    "\n",
    "# # Build dataset for each feature\n",
    "# feature_datasets = {}\n",
    "\n",
    "# # Predefine bin labels\n",
    "# bin_labels = [f\"{BINS[i]:.1f}-{BINS[i+1]:.1f}\" for i in range(len(BINS)-1)]\n",
    "\n",
    "# for fid in selected_features:\n",
    "#     # Extract activations for this feature\n",
    "#     activations = [f[fid] for f in features_all[\"features\"]]\n",
    "#     df = pd.DataFrame({\n",
    "#         \"uniprot_id\": features_all[\"uniprot_id\"],\n",
    "#         \"activation\": activations\n",
    "#     })\n",
    "\n",
    "#     # Assign bins\n",
    "#     df[\"bin\"] = pd.cut(df[\"activation\"], bins=BINS, labels=bin_labels, include_lowest=True)\n",
    "\n",
    "#     sampled = []\n",
    "\n",
    "#     # Sample proteins per bin\n",
    "#     for b in df[\"bin\"].dropna().unique():\n",
    "#         bin_df = df[df[\"bin\"] == b]\n",
    "#         n = 10 if b == \"0.9-1.0\" else 2\n",
    "#         sampled.extend(bin_df.sample(min(len(bin_df), n), random_state=42).to_dict(orient=\"records\"))\n",
    "\n",
    "#     # Add 10 random zero-activation proteins \n",
    "#     zero_df = df[df[\"activation\"] == 0.0]\n",
    "#     if len(zero_df) > 0:\n",
    "#         sampled.extend(zero_df.sample(min(len(zero_df), 10), random_state=42).to_dict(orient=\"records\"))\n",
    "\n",
    "#     # Merge with metadata from annotations_df\n",
    "#     sampled_df = pd.DataFrame(sampled)\n",
    "#     merged = sampled_df.merge(annotations_df, left_on=\"uniprot_id\", right_on=\"Entry\", how=\"left\")\n",
    "\n",
    "#     feature_datasets[fid] = merged\n",
    "\n",
    "# # Example feature dataset\n",
    "# example_fid = selected_features[0]\n",
    "# feature_datasets[example_fid].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original max activation (feature 0): 0.02611415\n",
      "Normalized max activation (feature 0): 1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "#Stakc into [num_proteins, num_features]\n",
    "X = np.vstack(features_all['features'].values) #Shape (N, F)\n",
    "\n",
    "#Max activation per feature across all proteins\n",
    "max_per_feature = X.max(axis=0) # shape: (F,)\n",
    "eps = 1e-12\n",
    "max_safe = np.where(max_per_feature > 0, max_per_feature, eps)\n",
    "#Normalize\n",
    "X_norm = X / max_safe\n",
    "\n",
    "#Save back\n",
    "features_all = features_all.copy()\n",
    "features_all[\"features_norm\"] = [row for row in X_norm]\n",
    "print(\"Original max activation (feature 0):\", X[:,0].max())\n",
    "print(\"Normalized max activation (feature 0):\", X_norm[:,0].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "# Parameters\n",
    "N_FEATURES = 10240\n",
    "BINS = np.arange(0, 1.1, 0.1)\n",
    "\n",
    "# Randomly select feature ids\n",
    "# all_feature_ids = list(range(len(features_all.iloc[0].features)))\n",
    "# print(\"num features\", len(all_feature_ids))\n",
    "# selected_features = random.sample(all_feature_ids, N_FEATURES)\n",
    "\n",
    "# print(f\"Selected {len(selected_features)} features out of {len(all_feature_ids)}\")\n",
    "\n",
    "# # Build dataset for each feature\n",
    "# feature_datasets = {}\n",
    "\n",
    "# # Predefine bin labels\n",
    "# bin_labels = [f\"{BINS[i]:.1f}-{BINS[i+1]:.1f}\" for i in range(len(BINS)-1)]\n",
    "\n",
    "# for fid in selected_features:\n",
    "#     # Extract activations for this feature\n",
    "#     activations = [f[fid] for f in features_all[\"features_norm\"]]\n",
    "#     df = pd.DataFrame({\n",
    "#         \"uniprot_id\": features_all[\"uniprot_id\"],\n",
    "#         \"activation\": activations\n",
    "#     })\n",
    "\n",
    "#     # Assign bins\n",
    "#     df[\"bin\"] = pd.cut(df[\"activation\"], bins=BINS, labels=bin_labels, include_lowest=True)\n",
    "\n",
    "#     sampled = []\n",
    "\n",
    "#     # Sample proteins per bin\n",
    "#     for b in df[\"bin\"].dropna().unique():\n",
    "#         bin_df = df[df[\"bin\"] == b]\n",
    "#         n = 10 if b == \"0.9-1.0\" else 2\n",
    "#         sampled.extend(bin_df.sample(min(len(bin_df), n), random_state=42).to_dict(orient=\"records\"))\n",
    "\n",
    "#     # Add 10 random zero-activation proteins \n",
    "#     zero_df = df[df[\"activation\"] == 0.0]\n",
    "#     if len(zero_df) > 0:\n",
    "#         sampled.extend(zero_df.sample(min(len(zero_df), 10), random_state=42).to_dict(orient=\"records\"))\n",
    "\n",
    "#     # Merge with metadata from annotations_df\n",
    "#     sampled_df = pd.DataFrame(sampled)\n",
    "#     merged = sampled_df.merge(annotations_df, left_on=\"uniprot_id\", right_on=\"Entry\", how=\"left\")\n",
    "\n",
    "#     feature_datasets[fid] = merged\n",
    "\n",
    "# # Example feature dataset\n",
    "# example_fid = selected_features[0]\n",
    "# feature_datasets[example_fid].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "feature_datasets\n",
    "# # Suppose feature_datasets is your dict of DataFrames\n",
    "# with open(\"feature_datasets.pkl\", \"wb\") as f:\n",
    "#     pickle.dump(feature_datasets, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"feature_datasets.pkl\", \"rb\") as f:\n",
    "    feature_datasets = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pickle\n",
    "\n",
    "# Make sure it's reproducible\n",
    "random.seed(42)\n",
    "\n",
    "# Get all keys\n",
    "all_keys = list(feature_datasets.keys())\n",
    "\n",
    "# Sample 1200 keys (without replacement)\n",
    "sample_keys = random.sample(all_keys, 1200)\n",
    "\n",
    "# Build a new dict with only those\n",
    "subset = {k: feature_datasets[k] for k in sample_keys}\n",
    "\n",
    "# Save to pickle\n",
    "with open(\"feature_datasets_subset.pkl\", \"wb\") as f:\n",
    "    pickle.dump(subset, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Amino Acid Indices and activations for better LLM annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import extract_esm_features_batch\n",
    "\n",
    "@torch.no_grad()\n",
    "def extract_sae_features(hidden_states: torch.Tensor, sae):\n",
    "    \"\"\"\n",
    "    Pass ESM hidden states through the Sparse Autoencoder (SAE).\n",
    "\n",
    "    Args\n",
    "    ----\n",
    "    hidden_states : torch.Tensor\n",
    "        Shape [B, L, d] or [L, d].\n",
    "        - B = batch size (optional if unsqueezed)\n",
    "        - L = sequence length\n",
    "        - d = ESM embedding dimension (e.g., 1280 for esm2_t33_650M)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    sae_features : torch.Tensor\n",
    "        Shape [B, L, F]\n",
    "        Sparse latent features per residue.\n",
    "        F = number of SAE dictionary atoms / features.\n",
    "\n",
    "    recon : torch.Tensor\n",
    "        Shape [B, L, d]\n",
    "        Reconstructed embeddings in token space.\n",
    "\n",
    "    error : torch.Tensor\n",
    "        Shape [B, L, d]\n",
    "        Residual = hidden_states - recon\n",
    "    \"\"\"\n",
    "    if hidden_states.dim() == 2:          # [L, d]\n",
    "        hidden_states = hidden_states.unsqueeze(0)  # → [1, L, d]\n",
    "    x = hidden_states.to(torch.float32)      # <- ensure fp32 for SAE\n",
    "\n",
    "    # SAE should have encode() and decode() that operate on last dimension\n",
    "    sae_features = sae.encode(x)     # [B, L, F]\n",
    "    recon        = sae.decode(sae_features)      # [B, L, d]\n",
    "    error        = hidden_states - recon         # [B, L, d]\n",
    "\n",
    "    return sae_features, recon, error\n",
    "\n",
    "#Config for extracting activated positions\n",
    "\n",
    "TOP_K = 8 # How many positions to record per protein\n",
    "MIN_ACT = 0.0 #Only consider positions with activation > MIN_ACT\n",
    "BATCH_SIZE = 16 #For ESM/SAE Inference\n",
    "\n",
    "\n",
    "def _batched(iterable, n):\n",
    "    \"\"\"Yield Successive n-sized chunks from iterable\n",
    "    \"\"\"\n",
    "    it = list(iterable)\n",
    "    for i in range(0, len(it), n):\n",
    "        yield it[i:i+n]\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from typing import List, Tuple, Optional, Literal\n",
    "\n",
    "TOP_K = 8\n",
    "MIN_ACT = 0.0\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "def _batched(iterable, n):\n",
    "    it = list(iterable)\n",
    "    for i in range(0, len(it), n):\n",
    "        yield it[i:i+n]\n",
    "\n",
    "def _normalize_1d(\n",
    "    x: np.ndarray,\n",
    "    mode: Literal[\"seq_max\",\"feature_global_max\",\"zscore\",\"none\"] = \"seq_max\",\n",
    "    global_max: Optional[float] = None,\n",
    "    eps: float = 1e-8\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Normalize a 1D activation vector x (valid positions only).\n",
    "    \"\"\"\n",
    "    if mode == \"none\":\n",
    "        return x.copy()\n",
    "\n",
    "    if mode == \"feature_global_max\":\n",
    "        if global_max is None or global_max <= eps:\n",
    "            # fallback to seq_max if global not available/safe\n",
    "            mode = \"seq_max\"\n",
    "        else:\n",
    "            return x / (global_max + eps)\n",
    "\n",
    "    if mode == \"seq_max\":\n",
    "        m = np.max(x) if x.size else 0.0\n",
    "        return x / (m + eps)\n",
    "\n",
    "    if mode == \"zscore\":\n",
    "        mu = float(np.mean(x)) if x.size else 0.0\n",
    "        sd = float(np.std(x)) if x.size else 0.0\n",
    "        return (x - mu) / (sd + eps)\n",
    "\n",
    "    # Fallback (shouldn't hit)\n",
    "    return x.copy()\n",
    "\n",
    "@torch.no_grad()\n",
    "def compute_activated_positions_for_feature(\n",
    "    fid: int,\n",
    "    seqs: List[str],\n",
    "    batch_size: int = BATCH_SIZE,\n",
    "    max_per_feature: Optional[np.ndarray] = None,\n",
    "    norm_mode: Literal[\"seq_max\",\"feature_global_max\",\"zscore\",\"none\"] = \"seq_max\",\n",
    "    top_k: int = TOP_K,\n",
    "    min_act: float = MIN_ACT,\n",
    "    device: str = \"cuda\"\n",
    ") -> Tuple[List[List[int]], List[List[str]], List[List[float]], List[List[float]]]:\n",
    "    \"\"\"\n",
    "    For a list of sequences and a single SAE feature id (fid),\n",
    "    return per-sequence top-K activated residue indices, AA identities,\n",
    "    normalized scores (per selected position), and raw scores.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    all_indices : List[List[int]]\n",
    "        Per-sequence Top-K indices (0-based).\n",
    "    all_aas : List[List[str]]\n",
    "        Per-sequence amino acids at those indices.\n",
    "    norm_vals : List[List[float]]\n",
    "        Per-sequence normalized activations aligned with Top-K order.\n",
    "    raw_vals : List[List[float]]\n",
    "        Per-sequence raw activations aligned with Top-K order.\n",
    "    \"\"\"\n",
    "    all_indices: List[List[int]] = []\n",
    "    all_aas: List[List[str]] = []\n",
    "    norm_vals: List[List[float]] = []\n",
    "    raw_vals: List[List[float]] = []\n",
    "\n",
    "    # Optional global max for this feature (for 'feature_global_max' mode)\n",
    "    global_max = None\n",
    "    if norm_mode == \"feature_global_max\" and max_per_feature is not None:\n",
    "        if 0 <= fid < len(max_per_feature):\n",
    "            gm = float(max_per_feature[fid])\n",
    "            global_max = gm if np.isfinite(gm) else None\n",
    "\n",
    "    for chunk in _batched(seqs, batch_size):\n",
    "        # ESM -> SAE: token representations and mask\n",
    "        token_reps, attn_mask = extract_esm_features_batch(\n",
    "            chunk, layer_sel=plm_layer, device=device, model=model, tokenizer=tokenizer\n",
    "        )  # token_reps: [B, L, H], attn_mask: [B, L] bool\n",
    "        sae_feats, _, _ = extract_sae_features(token_reps, sae)  # [B, L, F]\n",
    "\n",
    "        # Select feature channel -> [B, L] on CPU\n",
    "        feat_act = sae_feats[..., fid].float().cpu()\n",
    "        mask = attn_mask.cpu()  # [B, L] bool\n",
    "\n",
    "        for seq, act_row, m in zip(chunk, feat_act, mask):\n",
    "            L = int(m.sum().item())  # valid residues\n",
    "            act_valid = act_row[:L].numpy() if L > 0 else np.array([], dtype=np.float32)\n",
    "\n",
    "            # positions above threshold\n",
    "            valid_idx = np.where(act_valid > min_act)[0]\n",
    "            if valid_idx.size == 0:\n",
    "                all_indices.append([])\n",
    "                all_aas.append([])\n",
    "                norm_vals.append([])\n",
    "                raw_vals.append([])\n",
    "                continue\n",
    "\n",
    "            # sort by activation desc within valid subset and take top_k\n",
    "            order = np.argsort(-act_valid[valid_idx])\n",
    "            chosen_local = valid_idx[order[:top_k]].tolist()\n",
    "\n",
    "            # raw values for the chosen positions\n",
    "            chosen_raw = act_valid[chosen_local]\n",
    "\n",
    "            # normalization (done on the full valid slice, then gather chosen)\n",
    "            norm_full = _normalize_1d(\n",
    "                act_valid, mode=norm_mode, global_max=global_max\n",
    "            )\n",
    "            chosen_norm = norm_full[chosen_local]\n",
    "\n",
    "            # map to AAs (defensive indexing)\n",
    "            aas = [seq[i] if i < len(seq) else \"X\" for i in chosen_local]\n",
    "\n",
    "            all_indices.append(chosen_local)\n",
    "            all_aas.append(aas)\n",
    "            norm_vals.append([float(v) for v in chosen_norm])\n",
    "            raw_vals.append([float(v) for v in chosen_raw])\n",
    "\n",
    "        # free tensors early\n",
    "        del token_reps, sae_feats, feat_act, attn_mask\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    return all_indices, all_aas, norm_vals, raw_vals\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using ray so this doesn't take an hour and a half"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integrate with feature_datasets dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-14 02:44:01,309\tINFO worker.py:1951 -- Started a local Ray instance.\n",
      "Features (overall): 100%|██████████| 10240/10240 [09:27<00:00, 18.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[done] wrote 10248 files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ----------------------------\n",
    "# Core compute function (uses passed-in model/tokenizer/sae) — same logic you posted\n",
    "# ----------------------------\n",
    "@torch.no_grad()\n",
    "def _compute_activated_positions_for_feature_wrapped(\n",
    "    fid: int,\n",
    "    seqs: List[str],\n",
    "    *,\n",
    "    batch_size: int,\n",
    "    max_per_feature: Optional[np.ndarray] = None,\n",
    "    norm_mode: Literal[\"seq_max\", \"feature_global_max\", \"zscore\", \"none\"] = \"seq_max\",\n",
    "    top_k: int = 5,\n",
    "    min_act: float = 0.0,\n",
    "    device: str = \"cuda:0\",\n",
    "    plm_layer: int = 24,\n",
    "    model=None,\n",
    "    tokenizer=None,\n",
    "    sae=None,\n",
    ") -> Tuple[List[List[int]], List[List[str]], List[List[float]], List[List[float]]]:\n",
    "    all_indices: List[List[int]] = []\n",
    "    all_aas: List[List[str]] = []\n",
    "    norm_vals: List[List[float]] = []\n",
    "    raw_vals: List[List[float]] = []\n",
    "\n",
    "    global_max = None\n",
    "    if norm_mode == \"feature_global_max\" and max_per_feature is not None:\n",
    "        if 0 <= fid < len(max_per_feature):\n",
    "            gm = float(max_per_feature[fid])\n",
    "            global_max = gm if np.isfinite(gm) else None\n",
    "\n",
    "    for chunk in _batched(seqs, batch_size):\n",
    "        token_reps, attn_mask = extract_esm_features_batch(\n",
    "            chunk,\n",
    "            layer_sel=plm_layer,\n",
    "            device=device,\n",
    "            model=model,\n",
    "            tokenizer=tokenizer,\n",
    "        )\n",
    "\n",
    "        sae_feats, _, _ = extract_sae_features(token_reps, sae)  # [B, L, F]\n",
    "        feat_act = sae_feats[..., fid].float().cpu()\n",
    "        mask = attn_mask.cpu()\n",
    "\n",
    "        for seq, act_row, m in zip(chunk, feat_act, mask):\n",
    "            L = int(m.sum().item())\n",
    "            act_valid = act_row[:L].numpy() if L > 0 else np.array([], dtype=np.float32)\n",
    "\n",
    "            valid_idx = np.where(act_valid > min_act)[0]\n",
    "            if valid_idx.size == 0:\n",
    "                all_indices.append([])\n",
    "                all_aas.append([])\n",
    "                norm_vals.append([])\n",
    "                raw_vals.append([])\n",
    "                continue\n",
    "\n",
    "            order = np.argsort(-act_valid[valid_idx])\n",
    "            chosen_local = valid_idx[order[:top_k]].tolist()\n",
    "\n",
    "            chosen_raw = act_valid[chosen_local]\n",
    "            norm_full = _normalize_1d(act_valid, mode=norm_mode, global_max=global_max)\n",
    "            chosen_norm = norm_full[chosen_local]\n",
    "\n",
    "            aas = [seq[i] if i < len(seq) else \"X\" for i in chosen_local]\n",
    "\n",
    "            all_indices.append(chosen_local)\n",
    "            all_aas.append(aas)\n",
    "            norm_vals.append([float(v) for v in chosen_norm])\n",
    "            raw_vals.append([float(v) for v in chosen_raw])\n",
    "\n",
    "        # clean up\n",
    "        del token_reps, sae_feats, feat_act, attn_mask\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    return all_indices, all_aas, norm_vals, raw_vals\n",
    "\n",
    "# ray_feature_activation.py  (only the relevant parts shown)\n",
    "import os\n",
    "import ray\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional, Literal, Tuple\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from interplm.sae.inference import load_sae_from_hf\n",
    "from tqdm.auto import tqdm\n",
    "from ray.util.queue import Queue\n",
    "\n",
    "from utils import extract_esm_features_batch, _batched, _normalize_1d, extract_sae_features\n",
    "\n",
    "DATA_DIR = Path(\"esm_sae_results\"); DATA_DIR.mkdir(exist_ok=True, parents=True)\n",
    "os.environ.setdefault(\"HF_HOME\", str(DATA_DIR / \"hf_cache\"))\n",
    "os.environ.setdefault(\"TRANSFORMERS_CACHE\", str(DATA_DIR / \"hf_cache\"))\n",
    "os.environ.setdefault(\"PYTORCH_CUDA_ALLOC_CONF\", \"expandable_segments:True,max_split_size_mb:128\")\n",
    "\n",
    "ray.shutdown()\n",
    "# Optional: silence worker stdout spam\n",
    "ray.init(ignore_reinit_error=True, log_to_driver=False)\n",
    "\n",
    "N_GPUS = int(ray.available_resources().get(\"GPU\", 0))\n",
    "WORLD_SIZE = max(1, min(8, N_GPUS))\n",
    "\n",
    "# --- write inputs (as you already do) ---\n",
    "FEATURE_PICKLE = DATA_DIR / \"feature_datasets.pkl\"\n",
    "META_PICKLE    = DATA_DIR / \"feature_meta.pkl\"\n",
    "NORM_MODE = \"none\"\n",
    "ESM_LAYER_SEL = 24\n",
    "pd.to_pickle(feature_datasets, FEATURE_PICKLE)\n",
    "pd.to_pickle(\n",
    "    dict(\n",
    "        all_fids=list(feature_datasets.keys()),\n",
    "        norm_mode=NORM_MODE,\n",
    "        top_k=TOP_K,\n",
    "        min_act=MIN_ACT,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        plm_layer=(ESM_LAYER_SEL if isinstance(ESM_LAYER_SEL, int) else 24),\n",
    "        max_per_feature=np.asarray(max_safe) if max_safe is not None else None,\n",
    "    ),\n",
    "    META_PICKLE,\n",
    ")\n",
    "\n",
    "\n",
    "# ---------- Actor: NO tqdm here; report progress to the driver Queue ----------\n",
    "@ray.remote(num_gpus=1, num_cpus=0)\n",
    "class FeatureWorker:\n",
    "    def __init__(self, progress: Queue, amp_dtype: torch.dtype = torch.float16, plm_layer: int = 24):\n",
    "        self.progress = progress\n",
    "        self.device = torch.device(\"cuda:0\")\n",
    "        self.dtype  = amp_dtype\n",
    "        self.plm_layer = plm_layer\n",
    "\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\"facebook/esm2_t33_650M_UR50D\", do_lower_case=False)\n",
    "        self.model = AutoModel.from_pretrained(\n",
    "            \"facebook/esm2_t33_650M_UR50D\",\n",
    "            output_hidden_states=True,\n",
    "            torch_dtype=self.dtype,\n",
    "            low_cpu_mem_usage=True,\n",
    "        ).to(self.device).eval()\n",
    "\n",
    "        self.sae = load_sae_from_hf(plm_model=\"esm2-650m\", plm_layer=self.plm_layer).to(self.device).eval()\n",
    "\n",
    "    def process_shard(\n",
    "        self,\n",
    "        rank: int,\n",
    "        world_size: int,\n",
    "        feature_pickle_path: str,\n",
    "        meta_pickle_path: str,\n",
    "        out_prefix: str = \"feature_acts\",\n",
    "    ) -> List[str]:\n",
    "        fd: Dict[int, pd.DataFrame] = pd.read_pickle(feature_pickle_path)\n",
    "        meta = pd.read_pickle(meta_pickle_path)\n",
    "\n",
    "        all_fids: List[int] = meta[\"all_fids\"]\n",
    "        norm_mode: str      = meta[\"norm_mode\"]\n",
    "        top_k: int          = meta[\"top_k\"]\n",
    "        min_act: float      = meta[\"min_act\"]\n",
    "        batch_size: int     = meta[\"batch_size\"]\n",
    "        plm_layer: int      = meta[\"plm_layer\"]\n",
    "        max_per_feature     = meta[\"max_per_feature\"]\n",
    "\n",
    "        shard_fids = all_fids[rank::world_size]\n",
    "        paths = []\n",
    "\n",
    "        for fid in shard_fids:\n",
    "            df = fd[fid].copy()\n",
    "            if \"Sequence\" not in df.columns:\n",
    "                raise KeyError(\"Expected a 'Sequence' column in feature_datasets[fid].\")\n",
    "\n",
    "            seqs = df[\"Sequence\"].astype(str).fillna(\"\").tolist()\n",
    "\n",
    "            idx_lists, aa_lists, norm_vals, raw_vals = _compute_activated_positions_for_feature_wrapped(\n",
    "                fid=fid,\n",
    "                seqs=seqs,\n",
    "                batch_size=batch_size,\n",
    "                max_per_feature=max_per_feature,\n",
    "                norm_mode=norm_mode,\n",
    "                top_k=top_k,\n",
    "                min_act=min_act,\n",
    "                device=str(self.device),\n",
    "                plm_layer=plm_layer,\n",
    "                model=self.model,\n",
    "                tokenizer=self.tokenizer,\n",
    "                sae=self.sae,\n",
    "            )\n",
    "\n",
    "            df[\"activated_indices\"] = idx_lists\n",
    "            df[\"activated_aas\"] = aa_lists\n",
    "            df[\"seq_max_activation_norm\"] = norm_vals\n",
    "            df[\"activated_indices_str\"] = df[\"activated_indices\"].apply(lambda xs: \",\".join(map(str, xs)) if xs else \"\")\n",
    "            df[\"activated_aas_str\"] = df[\"activated_aas\"].apply(lambda xs: \",\".join(xs) if xs else \"\")\n",
    "            df[\"seq_max_activation_norm_str\"] = df[\"seq_max_activation_norm\"].apply(\n",
    "                lambda xs: \",\".join(map(str, xs)) if xs else \"\"\n",
    "            )\n",
    "\n",
    "            out_path = DATA_DIR / f\"{out_prefix}_fid{fid}_rank{rank}.pkl\"\n",
    "            df.to_pickle(out_path)\n",
    "            paths.append(str(out_path))\n",
    "\n",
    "            # tell the driver we finished one FID\n",
    "            self.progress.put(1)\n",
    "\n",
    "        shard_bundle = DATA_DIR / f\"{out_prefix}_rank{rank}.final.pkl\"\n",
    "        pd.to_pickle({\"rank\": rank, \"paths\": paths}, shard_bundle)\n",
    "        return [str(p) for p in paths] + [str(shard_bundle)]\n",
    "\n",
    "\n",
    "# ---------- Kick off workers; single tqdm on the driver ----------\n",
    "progress_q = Queue(maxsize=100000)\n",
    "\n",
    "actors = [\n",
    "    FeatureWorker.remote(progress=progress_q, amp_dtype=torch.float16,\n",
    "                         plm_layer=(ESM_LAYER_SEL if isinstance(ESM_LAYER_SEL, int) else 24))\n",
    "    for _ in range(WORLD_SIZE)\n",
    "]\n",
    "\n",
    "futs = [\n",
    "    actors[r].process_shard.remote(\n",
    "        rank=r,\n",
    "        world_size=WORLD_SIZE,\n",
    "        feature_pickle_path=str(FEATURE_PICKLE),\n",
    "        meta_pickle_path=str(META_PICKLE),\n",
    "        out_prefix=\"feature_acts\",\n",
    "    )\n",
    "    for r in range(WORLD_SIZE)\n",
    "]\n",
    "\n",
    "# total number of FIDs overall (not per shard)\n",
    "total_fids = len(pd.read_pickle(META_PICKLE)[\"all_fids\"])\n",
    "pbar = tqdm(total=total_fids, desc=\"Features (overall)\", leave=True)\n",
    "\n",
    "pending = set(futs)\n",
    "while pending:\n",
    "    # 1) Drain any progress events so the bar moves while tasks run\n",
    "    drained = 0\n",
    "    while True:\n",
    "        try:\n",
    "            drained += progress_q.get_nowait()\n",
    "        except Exception:\n",
    "            break\n",
    "    if drained:\n",
    "        pbar.update(drained)\n",
    "\n",
    "    # 2) Wait briefly for any task completion (non-blocking-ish)\n",
    "    done, not_done = ray.wait(list(pending), num_returns=1, timeout=0.25)\n",
    "    if done:\n",
    "        pending.difference_update(done)\n",
    "\n",
    "# Final drain (in case a few increments were still queued)\n",
    "drained = 0\n",
    "while True:\n",
    "    try:\n",
    "        drained += progress_q.get_nowait()\n",
    "    except Exception:\n",
    "        break\n",
    "if drained:\n",
    "    pbar.update(drained)\n",
    "\n",
    "pbar.close()\n",
    "\n",
    "out_paths_per_rank = ray.get(futs)\n",
    "flat_paths = [p for sub in out_paths_per_rank for p in sub]\n",
    "print(f\"[done] wrote {len(flat_paths)} files\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def merge_outputs_into_feature_datasets(feature_datasets: Dict[int, pd.DataFrame], paths: List[str]) -> None:\n",
    "    \"\"\"\n",
    "    For each per-FID pickle in 'paths', read it and replace feature_datasets[fid]. Edits the dict in place\n",
    "    \"\"\"\n",
    "    fid_paths = [p for p in paths if \"_fid\" in os.path.basename(p)]\n",
    "    for p in tqdm(fid_paths, desc=\"Merging results into feature_datasets\"):\n",
    "        name = os.path.basename(p)\n",
    "        m = re.search(r\"fid(\\d+)\", name)\n",
    "        if not m:\n",
    "            continue\n",
    "        fid = int(m.group(1))\n",
    "        feature_datasets[fid] = pd.read_pickle(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Merging results into feature_datasets: 100%|██████████| 10240/10240 [00:08<00:00, 1185.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated feature_datasets in place.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "out_paths_per_rank = ray.get(futs)\n",
    "flat_paths = [p for sub in out_paths_per_rank for p in sub]\n",
    "merge_outputs_into_feature_datasets(feature_datasets, flat_paths)\n",
    "print(\"Updated feature_datasets in place.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "FINAL_PATH = Path(\"per_amino_acid_feature_datasets_with_annotations.pkl\")\n",
    "\n",
    "# # Save\n",
    "# pd.to_pickle(feature_datasets, FINAL_PATH)  # uses highest protocol by default\n",
    "\n",
    "# Load later\n",
    "feature_datasets = pd.read_pickle(FINAL_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{5590: (21, 34), 7300: (26, 34), 595: (29, 34), 2669: (19, 34), 6281: (23, 34)}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(feature_datasets)[:5]  # first few feature IDs (keys)\n",
    "\n",
    "{fid: df.shape for fid, df in list(feature_datasets.items())[:5]}  # shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uniprot_id</th>\n",
       "      <th>activation</th>\n",
       "      <th>bin</th>\n",
       "      <th>Entry</th>\n",
       "      <th>Reviewed</th>\n",
       "      <th>Protein names</th>\n",
       "      <th>Length</th>\n",
       "      <th>Sequence</th>\n",
       "      <th>EC number</th>\n",
       "      <th>Active site</th>\n",
       "      <th>...</th>\n",
       "      <th>Domain [FT]</th>\n",
       "      <th>Motif</th>\n",
       "      <th>Region</th>\n",
       "      <th>Zinc finger</th>\n",
       "      <th>activated_indices</th>\n",
       "      <th>activated_aas</th>\n",
       "      <th>seq_max_activation_norm</th>\n",
       "      <th>activated_indices_str</th>\n",
       "      <th>activated_aas_str</th>\n",
       "      <th>seq_max_activation_norm_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A6LSD0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0-0.1</td>\n",
       "      <td>A6LSD0</td>\n",
       "      <td>reviewed</td>\n",
       "      <td>Acetyl-coenzyme A carboxylase carboxyl transfe...</td>\n",
       "      <td>287</td>\n",
       "      <td>MLKDLFVKRQYATVKSSTLKKSISEEKPNIPSGMWEKCDKCNSMIY...</td>\n",
       "      <td>2.1.3.15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>DOMAIN 34..287; /note=\"CoA carboxyltransferase...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ZN_FING 38..60; /note=\"C4-type\"; /evidence=\"EC...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P46005</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0-0.1</td>\n",
       "      <td>P46005</td>\n",
       "      <td>reviewed</td>\n",
       "      <td>Outer membrane usher protein AggC</td>\n",
       "      <td>842</td>\n",
       "      <td>MKTSSFIIVILLCFRIENVIAHTFSFDASLLNHGSGGIDLTLLEKG...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q5WEW8</td>\n",
       "      <td>0.104561</td>\n",
       "      <td>0.1-0.2</td>\n",
       "      <td>Q5WEW8</td>\n",
       "      <td>reviewed</td>\n",
       "      <td>Arginine biosynthesis bifunctional protein Arg...</td>\n",
       "      <td>408</td>\n",
       "      <td>MLTKQTTGQAWKQIKGSITDVKGFTTAGAHCGLKRKRLDIGAIFCD...</td>\n",
       "      <td>2.3.1.1; 2.3.1.35</td>\n",
       "      <td>ACT_SITE 195; /note=\"Nucleophile\"; /evidence=\"...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[257, 258, 256, 277, 247, 254, 274, 255]</td>\n",
       "      <td>[W, A, D, K, N, H, K, P]</td>\n",
       "      <td>[0.07567556202411652, 0.048477932810783386, 0....</td>\n",
       "      <td>257,258,256,277,247,254,274,255</td>\n",
       "      <td>W,A,D,K,N,H,K,P</td>\n",
       "      <td>0.07567556202411652,0.048477932810783386,0.044...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q9Y5C1</td>\n",
       "      <td>0.116409</td>\n",
       "      <td>0.1-0.2</td>\n",
       "      <td>Q9Y5C1</td>\n",
       "      <td>reviewed</td>\n",
       "      <td>Angiopoietin-related protein 3 (Angiopoietin-5...</td>\n",
       "      <td>460</td>\n",
       "      <td>MFTIKLLLFIVPLVISSRIDQDNSSFDSLSPEPKSRFAMLDDVKIL...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>DOMAIN 237..455; /note=\"Fibrinogen C-terminal\"...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>REGION 17..207; /note=\"Sufficient to inhibit L...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[393, 413, 396, 392, 260, 394, 422, 385]</td>\n",
       "      <td>[C, N, G, N, A, P, K, H]</td>\n",
       "      <td>[0.04759537801146507, 0.04610564932227135, 0.0...</td>\n",
       "      <td>393,413,396,392,260,394,422,385</td>\n",
       "      <td>C,N,G,N,A,P,K,H</td>\n",
       "      <td>0.04759537801146507,0.04610564932227135,0.0401...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q06303</td>\n",
       "      <td>0.387987</td>\n",
       "      <td>0.3-0.4</td>\n",
       "      <td>Q06303</td>\n",
       "      <td>reviewed</td>\n",
       "      <td>Aerolysin-4 (Hemolysin-4)</td>\n",
       "      <td>492</td>\n",
       "      <td>MKKLKITGLSLIISGLLMAQAQAAEPVYPDQLRLFSLGQEVCGDKY...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>REGION 68..84; /note=\"Interaction with host N-...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[77, 69, 62, 68, 66, 59, 58, 146]</td>\n",
       "      <td>[V, I, G, Q, Q, N, S, G]</td>\n",
       "      <td>[0.08769077807664871, 0.08646269887685776, 0.0...</td>\n",
       "      <td>77,69,62,68,66,59,58,146</td>\n",
       "      <td>V,I,G,Q,Q,N,S,G</td>\n",
       "      <td>0.08769077807664871,0.08646269887685776,0.0838...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>P09166</td>\n",
       "      <td>0.311142</td>\n",
       "      <td>0.3-0.4</td>\n",
       "      <td>P09166</td>\n",
       "      <td>reviewed</td>\n",
       "      <td>Aerolysin</td>\n",
       "      <td>492</td>\n",
       "      <td>MKALKITGLSLIISATLAAQTNAAEPIYPDQLRLFSLGEDVCGTDY...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>REGION 68..84; /note=\"Interaction with host N-...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[69, 60, 77, 68, 62, 61, 59, 78]</td>\n",
       "      <td>[I, I, V, Q, A, V, N, I]</td>\n",
       "      <td>[0.08975762128829956, 0.07494804263114929, 0.0...</td>\n",
       "      <td>69,60,77,68,62,61,59,78</td>\n",
       "      <td>I,I,V,Q,A,V,N,I</td>\n",
       "      <td>0.08975762128829956,0.07494804263114929,0.0744...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>P15465</td>\n",
       "      <td>0.218435</td>\n",
       "      <td>0.2-0.3</td>\n",
       "      <td>P15465</td>\n",
       "      <td>reviewed</td>\n",
       "      <td>Albumin-1 (WBA-1)</td>\n",
       "      <td>175</td>\n",
       "      <td>ADDPVYDAEGNKLVNRGKYTIVSFSDGAGIDVVATGNENPEDPLSI...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[55, 51, 63, 62, 65, 53, 52, 64]</td>\n",
       "      <td>[A, N, K, D, P, M, I, T]</td>\n",
       "      <td>[0.03894788399338722, 0.03494536876678467, 0.0...</td>\n",
       "      <td>55,51,63,62,65,53,52,64</td>\n",
       "      <td>A,N,K,D,P,M,I,T</td>\n",
       "      <td>0.03894788399338722,0.03494536876678467,0.0346...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Q91F58</td>\n",
       "      <td>0.267097</td>\n",
       "      <td>0.2-0.3</td>\n",
       "      <td>Q91F58</td>\n",
       "      <td>reviewed</td>\n",
       "      <td>Putative MSV199 domain-containing protein 468L</td>\n",
       "      <td>376</td>\n",
       "      <td>MEMATKKCNIFGVDSIGEPEGVVKKALDESLSLLDIFKFIEITNFD...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[106, 109, 113, 110, 108, 167, 104, 112]</td>\n",
       "      <td>[N, E, S, L, I, R, T, P]</td>\n",
       "      <td>[0.0693620815873146, 0.06051858887076378, 0.05...</td>\n",
       "      <td>106,109,113,110,108,167,104,112</td>\n",
       "      <td>N,E,S,L,I,R,T,P</td>\n",
       "      <td>0.0693620815873146,0.06051858887076378,0.05704...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>P09167</td>\n",
       "      <td>0.509103</td>\n",
       "      <td>0.5-0.6</td>\n",
       "      <td>P09167</td>\n",
       "      <td>reviewed</td>\n",
       "      <td>Aerolysin</td>\n",
       "      <td>493</td>\n",
       "      <td>MQKIKLTGLSLIISGLLMAQAQAAEPVYPDQLRLFSLGQGVCGDKY...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>REGION 68..84; /note=\"Interaction with host N-...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[77, 140, 149, 146, 66, 68, 143, 126]</td>\n",
       "      <td>[V, Y, W, G, Q, Q, H, R]</td>\n",
       "      <td>[0.0952877476811409, 0.08448244631290436, 0.08...</td>\n",
       "      <td>77,140,149,146,66,68,143,126</td>\n",
       "      <td>V,Y,W,G,Q,Q,H,R</td>\n",
       "      <td>0.0952877476811409,0.08448244631290436,0.08427...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Q08676</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.9-1.0</td>\n",
       "      <td>Q08676</td>\n",
       "      <td>reviewed</td>\n",
       "      <td>Aerolysin (Hemolysin-3)</td>\n",
       "      <td>489</td>\n",
       "      <td>MMNRIITANLANLASSLMLAQVLGWHEPVYPDQVKWAGLGTGVCAS...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>REGION 70..86; /note=\"Interaction with host N-...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[79, 136, 82, 138, 148, 70, 37, 146]</td>\n",
       "      <td>[V, F, G, K, G, Q, G, Y]</td>\n",
       "      <td>[0.15741534531116486, 0.14548814296722412, 0.1...</td>\n",
       "      <td>79,136,82,138,148,70,37,146</td>\n",
       "      <td>V,F,G,K,G,Q,G,Y</td>\n",
       "      <td>0.15741534531116486,0.14548814296722412,0.1404...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Q06304</td>\n",
       "      <td>0.703281</td>\n",
       "      <td>0.7-0.8</td>\n",
       "      <td>Q06304</td>\n",
       "      <td>reviewed</td>\n",
       "      <td>Aerolysin (Hemolysin)</td>\n",
       "      <td>488</td>\n",
       "      <td>MMNRIITANLAFLASSLMLAQVQAAEPVYPDQVKWAGLGTGVCASG...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>REGION 69..85; /note=\"Interaction with host N-...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[78, 81, 135, 145, 137, 79, 147, 127]</td>\n",
       "      <td>[V, G, F, Y, K, I, G, R]</td>\n",
       "      <td>[0.14334498345851898, 0.12291435152292252, 0.1...</td>\n",
       "      <td>78,81,135,145,137,79,147,127</td>\n",
       "      <td>V,G,F,Y,K,I,G,R</td>\n",
       "      <td>0.14334498345851898,0.12291435152292252,0.1119...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Q8NJP6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0-0.1</td>\n",
       "      <td>Q8NJP6</td>\n",
       "      <td>reviewed</td>\n",
       "      <td>Acetylxylan esterase A (EC 3.1.1.72) (AXE I) (...</td>\n",
       "      <td>382</td>\n",
       "      <td>MKSLSFSFLVTLFLYLTLSSARTLGKDVNKRVTAGSLQQVTGFGDN...</td>\n",
       "      <td>3.1.1.72</td>\n",
       "      <td>ACT_SITE 152; /note=\"Charge relay system\"; /ev...</td>\n",
       "      <td>...</td>\n",
       "      <td>DOMAIN 346..382; /note=\"CBM1\"; /evidence=\"ECO:...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>REGION 35..307; /note=\"Catalytic\"; /evidence=\"...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Q7CWL8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0-0.1</td>\n",
       "      <td>Q7CWL8</td>\n",
       "      <td>reviewed</td>\n",
       "      <td>ATP synthase subunit delta (ATP synthase F(1) ...</td>\n",
       "      <td>188</td>\n",
       "      <td>MPVAETSQGTSGVAERYASSLFELALEAGTVEAVQVELDKFGALLD...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Q63S86</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0-0.1</td>\n",
       "      <td>Q63S86</td>\n",
       "      <td>reviewed</td>\n",
       "      <td>Acyl carrier protein (ACP)</td>\n",
       "      <td>79</td>\n",
       "      <td>MDNIEQRVKKIVAEQLGVAEAEIKNEASFVNDLGADSLDTVELVMA...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>DOMAIN 2..77; /note=\"Carrier\"; /evidence=\"ECO:...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>P59312</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0-0.1</td>\n",
       "      <td>P59312</td>\n",
       "      <td>reviewed</td>\n",
       "      <td>N-acetyl-gamma-glutamyl-phosphate reductase (A...</td>\n",
       "      <td>350</td>\n",
       "      <td>MGDRVTVGIVGASGYGGVQLVRLLLEHPKVDIVYLGGEGSAGRPYT...</td>\n",
       "      <td>1.2.1.38</td>\n",
       "      <td>ACT_SITE 153; /evidence=\"ECO:0000255|HAMAP-Rul...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>B2S7M4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0-0.1</td>\n",
       "      <td>B2S7M4</td>\n",
       "      <td>reviewed</td>\n",
       "      <td>ATP synthase gamma chain (ATP synthase F1 sect...</td>\n",
       "      <td>292</td>\n",
       "      <td>MPSLKDLRNRIASVKATQKITKAMQMVAAAKLRRAQEAAEAARPYS...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>P37814</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0-0.1</td>\n",
       "      <td>P37814</td>\n",
       "      <td>reviewed</td>\n",
       "      <td>ATP synthase subunit b (ATP synthase F(0) sect...</td>\n",
       "      <td>170</td>\n",
       "      <td>MSQLPLELGLSFNGGDILFQLLAMLILLALLKKYALGPLLNIMKQR...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>P0DUI8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0-0.1</td>\n",
       "      <td>P0DUI8</td>\n",
       "      <td>reviewed</td>\n",
       "      <td>Apolipoprotein E (Apo-E)</td>\n",
       "      <td>310</td>\n",
       "      <td>MKVLWPALVVTLLAGCRADVEPGPEVQLGKEWATWQASQPWEQALG...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>REGION 77..248; /note=\"8 X 22 AA approximate t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Q21DK5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0-0.1</td>\n",
       "      <td>Q21DK5</td>\n",
       "      <td>reviewed</td>\n",
       "      <td>ATP synthase subunit delta (ATP synthase F(1) ...</td>\n",
       "      <td>178</td>\n",
       "      <td>MAEFTTLARPYAKAAFIAARDASDLGGWSKALATAAAVSQVDRVKT...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Q54HF1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0-0.1</td>\n",
       "      <td>Q54HF1</td>\n",
       "      <td>reviewed</td>\n",
       "      <td>Putative actin-24 (EC 3.6.4.-)</td>\n",
       "      <td>377</td>\n",
       "      <td>MECKEDLTIVIDNGSGMCKAGFAGYDAPHAVFPSIVGRPRHTGVMV...</td>\n",
       "      <td>3.6.4.-</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>M3XFH7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0-0.1</td>\n",
       "      <td>M3XFH7</td>\n",
       "      <td>reviewed</td>\n",
       "      <td>Aminopeptidase Q (EC 3.4.11.-) (Laeverin) (Tab...</td>\n",
       "      <td>992</td>\n",
       "      <td>MGPPSSSGFYVSRAVALLLAALAAALLLALAVLAALYGRCARVQPS...</td>\n",
       "      <td>3.4.11.-</td>\n",
       "      <td>ACT_SITE 417; /note=\"Proton acceptor\"; /eviden...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>REGION 47..92; /note=\"Disordered\"; /evidence=\"...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   uniprot_id  activation      bin   Entry  Reviewed  \\\n",
       "0      A6LSD0    0.000000  0.0-0.1  A6LSD0  reviewed   \n",
       "1      P46005    0.000000  0.0-0.1  P46005  reviewed   \n",
       "2      Q5WEW8    0.104561  0.1-0.2  Q5WEW8  reviewed   \n",
       "3      Q9Y5C1    0.116409  0.1-0.2  Q9Y5C1  reviewed   \n",
       "4      Q06303    0.387987  0.3-0.4  Q06303  reviewed   \n",
       "5      P09166    0.311142  0.3-0.4  P09166  reviewed   \n",
       "6      P15465    0.218435  0.2-0.3  P15465  reviewed   \n",
       "7      Q91F58    0.267097  0.2-0.3  Q91F58  reviewed   \n",
       "8      P09167    0.509103  0.5-0.6  P09167  reviewed   \n",
       "9      Q08676    1.000000  0.9-1.0  Q08676  reviewed   \n",
       "10     Q06304    0.703281  0.7-0.8  Q06304  reviewed   \n",
       "11     Q8NJP6    0.000000  0.0-0.1  Q8NJP6  reviewed   \n",
       "12     Q7CWL8    0.000000  0.0-0.1  Q7CWL8  reviewed   \n",
       "13     Q63S86    0.000000  0.0-0.1  Q63S86  reviewed   \n",
       "14     P59312    0.000000  0.0-0.1  P59312  reviewed   \n",
       "15     B2S7M4    0.000000  0.0-0.1  B2S7M4  reviewed   \n",
       "16     P37814    0.000000  0.0-0.1  P37814  reviewed   \n",
       "17     P0DUI8    0.000000  0.0-0.1  P0DUI8  reviewed   \n",
       "18     Q21DK5    0.000000  0.0-0.1  Q21DK5  reviewed   \n",
       "19     Q54HF1    0.000000  0.0-0.1  Q54HF1  reviewed   \n",
       "20     M3XFH7    0.000000  0.0-0.1  M3XFH7  reviewed   \n",
       "\n",
       "                                        Protein names  Length  \\\n",
       "0   Acetyl-coenzyme A carboxylase carboxyl transfe...     287   \n",
       "1                   Outer membrane usher protein AggC     842   \n",
       "2   Arginine biosynthesis bifunctional protein Arg...     408   \n",
       "3   Angiopoietin-related protein 3 (Angiopoietin-5...     460   \n",
       "4                           Aerolysin-4 (Hemolysin-4)     492   \n",
       "5                                           Aerolysin     492   \n",
       "6                                   Albumin-1 (WBA-1)     175   \n",
       "7      Putative MSV199 domain-containing protein 468L     376   \n",
       "8                                           Aerolysin     493   \n",
       "9                             Aerolysin (Hemolysin-3)     489   \n",
       "10                              Aerolysin (Hemolysin)     488   \n",
       "11  Acetylxylan esterase A (EC 3.1.1.72) (AXE I) (...     382   \n",
       "12  ATP synthase subunit delta (ATP synthase F(1) ...     188   \n",
       "13                         Acyl carrier protein (ACP)      79   \n",
       "14  N-acetyl-gamma-glutamyl-phosphate reductase (A...     350   \n",
       "15  ATP synthase gamma chain (ATP synthase F1 sect...     292   \n",
       "16  ATP synthase subunit b (ATP synthase F(0) sect...     170   \n",
       "17                           Apolipoprotein E (Apo-E)     310   \n",
       "18  ATP synthase subunit delta (ATP synthase F(1) ...     178   \n",
       "19                     Putative actin-24 (EC 3.6.4.-)     377   \n",
       "20  Aminopeptidase Q (EC 3.4.11.-) (Laeverin) (Tab...     992   \n",
       "\n",
       "                                             Sequence          EC number  \\\n",
       "0   MLKDLFVKRQYATVKSSTLKKSISEEKPNIPSGMWEKCDKCNSMIY...           2.1.3.15   \n",
       "1   MKTSSFIIVILLCFRIENVIAHTFSFDASLLNHGSGGIDLTLLEKG...                NaN   \n",
       "2   MLTKQTTGQAWKQIKGSITDVKGFTTAGAHCGLKRKRLDIGAIFCD...  2.3.1.1; 2.3.1.35   \n",
       "3   MFTIKLLLFIVPLVISSRIDQDNSSFDSLSPEPKSRFAMLDDVKIL...                NaN   \n",
       "4   MKKLKITGLSLIISGLLMAQAQAAEPVYPDQLRLFSLGQEVCGDKY...                NaN   \n",
       "5   MKALKITGLSLIISATLAAQTNAAEPIYPDQLRLFSLGEDVCGTDY...                NaN   \n",
       "6   ADDPVYDAEGNKLVNRGKYTIVSFSDGAGIDVVATGNENPEDPLSI...                NaN   \n",
       "7   MEMATKKCNIFGVDSIGEPEGVVKKALDESLSLLDIFKFIEITNFD...                NaN   \n",
       "8   MQKIKLTGLSLIISGLLMAQAQAAEPVYPDQLRLFSLGQGVCGDKY...                NaN   \n",
       "9   MMNRIITANLANLASSLMLAQVLGWHEPVYPDQVKWAGLGTGVCAS...                NaN   \n",
       "10  MMNRIITANLAFLASSLMLAQVQAAEPVYPDQVKWAGLGTGVCASG...                NaN   \n",
       "11  MKSLSFSFLVTLFLYLTLSSARTLGKDVNKRVTAGSLQQVTGFGDN...           3.1.1.72   \n",
       "12  MPVAETSQGTSGVAERYASSLFELALEAGTVEAVQVELDKFGALLD...                NaN   \n",
       "13  MDNIEQRVKKIVAEQLGVAEAEIKNEASFVNDLGADSLDTVELVMA...                NaN   \n",
       "14  MGDRVTVGIVGASGYGGVQLVRLLLEHPKVDIVYLGGEGSAGRPYT...           1.2.1.38   \n",
       "15  MPSLKDLRNRIASVKATQKITKAMQMVAAAKLRRAQEAAEAARPYS...                NaN   \n",
       "16  MSQLPLELGLSFNGGDILFQLLAMLILLALLKKYALGPLLNIMKQR...                NaN   \n",
       "17  MKVLWPALVVTLLAGCRADVEPGPEVQLGKEWATWQASQPWEQALG...                NaN   \n",
       "18  MAEFTTLARPYAKAAFIAARDASDLGGWSKALATAAAVSQVDRVKT...                NaN   \n",
       "19  MECKEDLTIVIDNGSGMCKAGFAGYDAPHAVFPSIVGRPRHTGVMV...            3.6.4.-   \n",
       "20  MGPPSSSGFYVSRAVALLLAALAAALLLALAVLAALYGRCARVQPS...           3.4.11.-   \n",
       "\n",
       "                                          Active site  ...  \\\n",
       "0                                                 NaN  ...   \n",
       "1                                                 NaN  ...   \n",
       "2   ACT_SITE 195; /note=\"Nucleophile\"; /evidence=\"...  ...   \n",
       "3                                                 NaN  ...   \n",
       "4                                                 NaN  ...   \n",
       "5                                                 NaN  ...   \n",
       "6                                                 NaN  ...   \n",
       "7                                                 NaN  ...   \n",
       "8                                                 NaN  ...   \n",
       "9                                                 NaN  ...   \n",
       "10                                                NaN  ...   \n",
       "11  ACT_SITE 152; /note=\"Charge relay system\"; /ev...  ...   \n",
       "12                                                NaN  ...   \n",
       "13                                                NaN  ...   \n",
       "14  ACT_SITE 153; /evidence=\"ECO:0000255|HAMAP-Rul...  ...   \n",
       "15                                                NaN  ...   \n",
       "16                                                NaN  ...   \n",
       "17                                                NaN  ...   \n",
       "18                                                NaN  ...   \n",
       "19                                                NaN  ...   \n",
       "20  ACT_SITE 417; /note=\"Proton acceptor\"; /eviden...  ...   \n",
       "\n",
       "                                          Domain [FT] Motif  \\\n",
       "0   DOMAIN 34..287; /note=\"CoA carboxyltransferase...   NaN   \n",
       "1                                                 NaN   NaN   \n",
       "2                                                 NaN   NaN   \n",
       "3   DOMAIN 237..455; /note=\"Fibrinogen C-terminal\"...   NaN   \n",
       "4                                                 NaN   NaN   \n",
       "5                                                 NaN   NaN   \n",
       "6                                                 NaN   NaN   \n",
       "7                                                 NaN   NaN   \n",
       "8                                                 NaN   NaN   \n",
       "9                                                 NaN   NaN   \n",
       "10                                                NaN   NaN   \n",
       "11  DOMAIN 346..382; /note=\"CBM1\"; /evidence=\"ECO:...   NaN   \n",
       "12                                                NaN   NaN   \n",
       "13  DOMAIN 2..77; /note=\"Carrier\"; /evidence=\"ECO:...   NaN   \n",
       "14                                                NaN   NaN   \n",
       "15                                                NaN   NaN   \n",
       "16                                                NaN   NaN   \n",
       "17                                                NaN   NaN   \n",
       "18                                                NaN   NaN   \n",
       "19                                                NaN   NaN   \n",
       "20                                                NaN   NaN   \n",
       "\n",
       "                                               Region  \\\n",
       "0                                                 NaN   \n",
       "1                                                 NaN   \n",
       "2                                                 NaN   \n",
       "3   REGION 17..207; /note=\"Sufficient to inhibit L...   \n",
       "4   REGION 68..84; /note=\"Interaction with host N-...   \n",
       "5   REGION 68..84; /note=\"Interaction with host N-...   \n",
       "6                                                 NaN   \n",
       "7                                                 NaN   \n",
       "8   REGION 68..84; /note=\"Interaction with host N-...   \n",
       "9   REGION 70..86; /note=\"Interaction with host N-...   \n",
       "10  REGION 69..85; /note=\"Interaction with host N-...   \n",
       "11  REGION 35..307; /note=\"Catalytic\"; /evidence=\"...   \n",
       "12                                                NaN   \n",
       "13                                                NaN   \n",
       "14                                                NaN   \n",
       "15                                                NaN   \n",
       "16                                                NaN   \n",
       "17  REGION 77..248; /note=\"8 X 22 AA approximate t...   \n",
       "18                                                NaN   \n",
       "19                                                NaN   \n",
       "20  REGION 47..92; /note=\"Disordered\"; /evidence=\"...   \n",
       "\n",
       "                                          Zinc finger  \\\n",
       "0   ZN_FING 38..60; /note=\"C4-type\"; /evidence=\"EC...   \n",
       "1                                                 NaN   \n",
       "2                                                 NaN   \n",
       "3                                                 NaN   \n",
       "4                                                 NaN   \n",
       "5                                                 NaN   \n",
       "6                                                 NaN   \n",
       "7                                                 NaN   \n",
       "8                                                 NaN   \n",
       "9                                                 NaN   \n",
       "10                                                NaN   \n",
       "11                                                NaN   \n",
       "12                                                NaN   \n",
       "13                                                NaN   \n",
       "14                                                NaN   \n",
       "15                                                NaN   \n",
       "16                                                NaN   \n",
       "17                                                NaN   \n",
       "18                                                NaN   \n",
       "19                                                NaN   \n",
       "20                                                NaN   \n",
       "\n",
       "                           activated_indices             activated_aas  \\\n",
       "0                                         []                        []   \n",
       "1                                         []                        []   \n",
       "2   [257, 258, 256, 277, 247, 254, 274, 255]  [W, A, D, K, N, H, K, P]   \n",
       "3   [393, 413, 396, 392, 260, 394, 422, 385]  [C, N, G, N, A, P, K, H]   \n",
       "4          [77, 69, 62, 68, 66, 59, 58, 146]  [V, I, G, Q, Q, N, S, G]   \n",
       "5           [69, 60, 77, 68, 62, 61, 59, 78]  [I, I, V, Q, A, V, N, I]   \n",
       "6           [55, 51, 63, 62, 65, 53, 52, 64]  [A, N, K, D, P, M, I, T]   \n",
       "7   [106, 109, 113, 110, 108, 167, 104, 112]  [N, E, S, L, I, R, T, P]   \n",
       "8      [77, 140, 149, 146, 66, 68, 143, 126]  [V, Y, W, G, Q, Q, H, R]   \n",
       "9       [79, 136, 82, 138, 148, 70, 37, 146]  [V, F, G, K, G, Q, G, Y]   \n",
       "10     [78, 81, 135, 145, 137, 79, 147, 127]  [V, G, F, Y, K, I, G, R]   \n",
       "11                                        []                        []   \n",
       "12                                        []                        []   \n",
       "13                                        []                        []   \n",
       "14                                        []                        []   \n",
       "15                                        []                        []   \n",
       "16                                        []                        []   \n",
       "17                                        []                        []   \n",
       "18                                        []                        []   \n",
       "19                                        []                        []   \n",
       "20                                        []                        []   \n",
       "\n",
       "                              seq_max_activation_norm  \\\n",
       "0                                                  []   \n",
       "1                                                  []   \n",
       "2   [0.07567556202411652, 0.048477932810783386, 0....   \n",
       "3   [0.04759537801146507, 0.04610564932227135, 0.0...   \n",
       "4   [0.08769077807664871, 0.08646269887685776, 0.0...   \n",
       "5   [0.08975762128829956, 0.07494804263114929, 0.0...   \n",
       "6   [0.03894788399338722, 0.03494536876678467, 0.0...   \n",
       "7   [0.0693620815873146, 0.06051858887076378, 0.05...   \n",
       "8   [0.0952877476811409, 0.08448244631290436, 0.08...   \n",
       "9   [0.15741534531116486, 0.14548814296722412, 0.1...   \n",
       "10  [0.14334498345851898, 0.12291435152292252, 0.1...   \n",
       "11                                                 []   \n",
       "12                                                 []   \n",
       "13                                                 []   \n",
       "14                                                 []   \n",
       "15                                                 []   \n",
       "16                                                 []   \n",
       "17                                                 []   \n",
       "18                                                 []   \n",
       "19                                                 []   \n",
       "20                                                 []   \n",
       "\n",
       "              activated_indices_str activated_aas_str  \\\n",
       "0                                                       \n",
       "1                                                       \n",
       "2   257,258,256,277,247,254,274,255   W,A,D,K,N,H,K,P   \n",
       "3   393,413,396,392,260,394,422,385   C,N,G,N,A,P,K,H   \n",
       "4          77,69,62,68,66,59,58,146   V,I,G,Q,Q,N,S,G   \n",
       "5           69,60,77,68,62,61,59,78   I,I,V,Q,A,V,N,I   \n",
       "6           55,51,63,62,65,53,52,64   A,N,K,D,P,M,I,T   \n",
       "7   106,109,113,110,108,167,104,112   N,E,S,L,I,R,T,P   \n",
       "8      77,140,149,146,66,68,143,126   V,Y,W,G,Q,Q,H,R   \n",
       "9       79,136,82,138,148,70,37,146   V,F,G,K,G,Q,G,Y   \n",
       "10     78,81,135,145,137,79,147,127   V,G,F,Y,K,I,G,R   \n",
       "11                                                      \n",
       "12                                                      \n",
       "13                                                      \n",
       "14                                                      \n",
       "15                                                      \n",
       "16                                                      \n",
       "17                                                      \n",
       "18                                                      \n",
       "19                                                      \n",
       "20                                                      \n",
       "\n",
       "                          seq_max_activation_norm_str  \n",
       "0                                                      \n",
       "1                                                      \n",
       "2   0.07567556202411652,0.048477932810783386,0.044...  \n",
       "3   0.04759537801146507,0.04610564932227135,0.0401...  \n",
       "4   0.08769077807664871,0.08646269887685776,0.0838...  \n",
       "5   0.08975762128829956,0.07494804263114929,0.0744...  \n",
       "6   0.03894788399338722,0.03494536876678467,0.0346...  \n",
       "7   0.0693620815873146,0.06051858887076378,0.05704...  \n",
       "8   0.0952877476811409,0.08448244631290436,0.08427...  \n",
       "9   0.15741534531116486,0.14548814296722412,0.1404...  \n",
       "10  0.14334498345851898,0.12291435152292252,0.1119...  \n",
       "11                                                     \n",
       "12                                                     \n",
       "13                                                     \n",
       "14                                                     \n",
       "15                                                     \n",
       "16                                                     \n",
       "17                                                     \n",
       "18                                                     \n",
       "19                                                     \n",
       "20                                                     \n",
       "\n",
       "[21 rows x 34 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_datasets[5590]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to: /home/ec2-user/SageMaker/InterPLM/per_amino_acid_feature_datasets_with_annotations.pkl\n",
      "File size: 386.13 MB  (404,884,661 bytes)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Show on-disk size\n",
    "size_bytes = FINAL_PATH.stat().st_size\n",
    "def sizeof(n):\n",
    "    for unit in (\"B\",\"KB\",\"MB\",\"GB\",\"TB\"):\n",
    "        if n < 1024 or unit == \"TB\":\n",
    "            return f\"{n:.2f} {unit}\"\n",
    "        n /= 1024\n",
    "print(f\"Saved to: {FINAL_PATH.resolve()}\")\n",
    "print(f\"File size: {sizeof(size_bytes)}  ({size_bytes:,} bytes)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppose feature_datasets is your dict of DataFrames\n",
    "with open(\"feature_datasets_with_amino_acids.pkl\", \"wb\") as f:\n",
    "    pickle.dump(feature_datasets, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "# --- Setup (once per notebook) ---\n",
    "# pip install anthropic python-dotenv\n",
    "from anthropic import Anthropic\n",
    "from dotenv import load_dotenv\n",
    "import os, time, json, math, textwrap\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Dict\n",
    "from typing import Iterable, Optional, Union, List, Dict\n",
    "\n",
    "# Load .env (expects ANTHROPIC_API_KEY=...)\n",
    "load_dotenv()\n",
    "client = Anthropic(api_key=os.getenv(\"ANTHROPIC_API_KEY\"))\n",
    "\n",
    "# --- Config ---\n",
    "MODEL_NAME = \"claude-3-5-sonnet-20240620\"\n",
    "MAX_TOKENS = 800  # enough for description + summary\n",
    "TEMPERATURE = 0.0 # deterministic\n",
    "CHECKPOINT_EVERY = 50\n",
    "OUTPUT_PATH = \"claude_feature_annotations.csv\"\n",
    "\n",
    "# Columns to show Claude (customize as you like)\n",
    "# We'll include what exists; missing columns are auto-dropped\n",
    "PREFERRED_COLS = [\n",
    "    # keys/ids\n",
    "    \"uniprot_id\", \"Entry\", \"Protein names\",\n",
    "    # size/sequence shape\n",
    "    \"Length\",\n",
    "    # functional annotations\n",
    "    \"EC number\", \"Active site\", \"Binding site\", \"Cofactor\", \"Disulfide bond\",\n",
    "    \"Helix\", \"Turn\", \"Beta strand\", \"Coiled coil\",\n",
    "    \"Domain [CC]\", \"Compositional bias\", \"Domain [FT]\", \"Motif\", \"Region\", \"Zinc finger\",\n",
    "    # your per-feature fields\n",
    "    \"activation\", \"bin\",\n",
    "    # optional (only used if present)\n",
    "    \"activated_indices\", \"activated_aas\"\n",
    "]\n",
    "\n",
    "# Limit rows/cols so the table fits comfortably in context\n",
    "MAX_ROWS = 80   # you can raise/lower if you hit token limits\n",
    "TRUNCATE_STR_LEN = 120  # truncate long text fields so tables tay compact\n",
    "\n",
    "\n",
    "def _coerce_and_trim_cols(df: pd.DataFrame, cols: list[str]) -> pd.DataFrame:\n",
    "    \"\"\"Select existing columns, stringify, and truncate long strings so the table is compact.\"\"\"\n",
    "    use_cols = [c for c in cols if c in df.columns]\n",
    "    if not use_cols:\n",
    "        # Fallback: show whatever is available\n",
    "        use_cols = list(df.columns)\n",
    "\n",
    "    out = df[use_cols].copy()\n",
    "\n",
    "    # Coerce to string and truncate long values\n",
    "    for c in use_cols:\n",
    "        out[c] = out[c].astype(str).str.replace(r\"\\s+\", \" \", regex=True)\n",
    "        out[c] = out[c].apply(lambda s: s[:TRUNCATE_STR_LEN] + \"…\" if len(s) > TRUNCATE_STR_LEN else s)\n",
    "\n",
    "    # Keep only first MAX_ROWS to control token usage\n",
    "    return out.head(MAX_ROWS)\n",
    "\n",
    "\n",
    "PROMPT_TEMPLATE = \"\"\"Generate description and summary\n",
    "Analyze this protein dataset to determine what predicts the ’Maximum activation value’ and ‘Amino acids of\n",
    "highest activated indices in protein’ columns. This description should be as concise as possible but sufficient to\n",
    "predict these two columns on held-out data given only the description and the rest of the protein metadata\n",
    "provided. The feature could be specific to a protein family, a structural motif, a sequence motif, a functional\n",
    "role, etc. These WILL be used to predict how much unseen proteins are activated by the feature so only\n",
    "highlight relevant factors for this.\n",
    "\n",
    "Focus on:\n",
    "• Properties of proteins from the metadata that are associated with high vs medium vs low activation.\n",
    "• Where in the protein sequence activation occurs (in relation to the protein sequence, length, structure,\n",
    "  or other properties)\n",
    "• What functional annotations (binding sites, domains, etc.) and amino acids are present at or near the\n",
    "  activated positions\n",
    "• This description that will be used to help predict missing activation values should start with:\n",
    "  “The activation patterns are characterized by:”\n",
    "\n",
    "Then, in 1 sentence, summarize what biological feature or pattern this neural network activation is detecting.\n",
    "This concise summary should start with “The feature activates on”.\n",
    "\n",
    "Protein record:\n",
    "{TABLE}\n",
    "\"\"\"\n",
    "\n",
    "def build_prompt(table_df: pd.DataFrame) -> str:\n",
    "    table_md = table_df.to_markdown(index=False)\n",
    "    return PROMPT_TEMPLATE.replace(\"{TABLE}\", table_md)\n",
    "\n",
    "# Configure once\n",
    "BEDROCK_REGION = \"us-east-1\"\n",
    "MODEL_ID = \"us.anthropic.claude-sonnet-4-20250514-v1:0\"  # change if you prefer another Claude on Bedrock\n",
    "\n",
    "\n",
    "_bedrock = boto3.client(\"bedrock-runtime\", region_name=BEDROCK_REGION)\n",
    "\n",
    "\n",
    "# def call_claude(prompt: str) -> str:\n",
    "#     \"\"\"Call Claude, return raw text.\"\"\"\n",
    "\n",
    "#     #Build Bedrock/Anthropic messages pyalod\n",
    "#     messages = [\n",
    "#     {\n",
    "#         \"role\": \"user\",\n",
    "#         \"content\": [{\"type\":\"text\", \"text\": prompt}]\n",
    "#     }\n",
    "#     ]\n",
    "\n",
    "#     body = {\n",
    "#         \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "#         \"max_tokens\": MAX_TOKENS,\n",
    "#         \"temperature\" : TEMPERATURE,\n",
    "#         \"messages\": messages\n",
    "#     }\n",
    "\n",
    "#     resp = _bedrock.invoke_model(\n",
    "#         modelId=MODEL_ID,\n",
    "#         body=json.dumps(body),\n",
    "#         contentType = \"application/json\",\n",
    "#         accept=\"application/json\",\n",
    "#     )\n",
    "#     payload = json.loads(resp[\"body\"].read())\n",
    "\n",
    "#     #Concatenate all text content blocks(CLaude may return multiple)\n",
    "#     text_parts = []\n",
    "#     for part in payload.get(\"content\", []):\n",
    "#         if part.get(\"type\") == \"text\":\n",
    "#             text_parts.append(part.get(\"text\", \"\"))\n",
    "#     return \"\".join(text_parts)\n",
    "\n",
    "def call_claude(\n",
    "    prompt: str,\n",
    "    *,\n",
    "    max_tokens: int = 512,\n",
    "    temperature: float = 0.2,\n",
    "    top_p: Optional[float] = None,\n",
    "    stop_sequences: Optional[Iterable[str]] = None,\n",
    "    system: Optional[Union[str, List[Dict]]] = None,\n",
    "    model_id: str = MODEL_ID,\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Call Claude via AWS Bedrock and return the concatenated text response.\n",
    "\n",
    "    Args:\n",
    "        prompt: user prompt (string)\n",
    "        max_tokens: max tokens to generate\n",
    "        temperature: sampling temperature\n",
    "        top_p: nucleus sampling\n",
    "        stop_sequences: iterable of stop strings\n",
    "        system: optional system instruction. You can pass a plain string,\n",
    "                or a Bedrock-ready list of content blocks (dicts).\n",
    "        model_id: Bedrock model id (default set above)\n",
    "\n",
    "    Returns:\n",
    "        The assistant's text (may be empty if no text blocks returned).\n",
    "    \"\"\"\n",
    "    # Build Bedrock/Anthropic messages payload\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [{\"type\": \"text\", \"text\": prompt}],\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    body = {\n",
    "        \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "        \"max_tokens\": max_tokens,\n",
    "        \"temperature\": temperature,\n",
    "        \"messages\": messages,\n",
    "    }\n",
    "    if top_p is not None:\n",
    "        body[\"top_p\"] = top_p\n",
    "    if stop_sequences:\n",
    "        body[\"stop_sequences\"] = list(stop_sequences)\n",
    "    if system:\n",
    "        # Accept either a simple string or already-structured content blocks\n",
    "        if isinstance(system, str):\n",
    "            body[\"system\"] = [{\"type\": \"text\", \"text\": system}]\n",
    "        else:\n",
    "            body[\"system\"] = system\n",
    "\n",
    "    resp = _bedrock.invoke_model(\n",
    "        modelId=model_id,\n",
    "        body=json.dumps(body),\n",
    "        contentType=\"application/json\",\n",
    "        accept=\"application/json\",\n",
    "    )\n",
    "\n",
    "    payload = json.loads(resp[\"body\"].read())\n",
    "    # Concatenate all text content blocks (Claude may return multiple)\n",
    "    text_parts = []\n",
    "    for part in payload.get(\"content\", []):\n",
    "        if part.get(\"type\") == \"text\":\n",
    "            text_parts.append(part.get(\"text\", \"\"))\n",
    "    return \"\".join(text_parts)\n",
    "\n",
    "\n",
    "def parse_description_and_summary(text: str) -> dict:\n",
    "    \"\"\"\n",
    "    Best-effort parse: extract the long description (must start with the required phrase)\n",
    "    and the one-sentence summary (starts with 'The feature activates on').\n",
    "    Falls back to raw if patterns aren’t found.\n",
    "    \"\"\"\n",
    "    desc = \"\"\n",
    "    summ = \"\"\n",
    "    lines = [l.strip() for l in text.splitlines() if l.strip()]\n",
    "\n",
    "    # Find the description block\n",
    "    start_idx = None\n",
    "    for i, l in enumerate(lines):\n",
    "        if l.lower().startswith(\"the activation patterns are characterized by:\"):\n",
    "            start_idx = i\n",
    "            break\n",
    "    if start_idx is not None:\n",
    "        # collect until we hit the summary or end\n",
    "        buff = []\n",
    "        for j in range(start_idx, len(lines)):\n",
    "            if lines[j].lower().startswith(\"the feature activates on\"):\n",
    "                break\n",
    "            buff.append(lines[j])\n",
    "        desc = \"\\n\".join(buff).strip()\n",
    "\n",
    "    # Find the one-sentence summary\n",
    "    for l in lines:\n",
    "        if l.lower().startswith(\"the feature activates on\"):\n",
    "            # keep first sentence\n",
    "            summ = l.split(\"\\n\")[0].strip()\n",
    "            break\n",
    "\n",
    "    return {\n",
    "        \"description\": desc or \"\",\n",
    "        \"summary\": summ or \"\",\n",
    "        \"raw\": text.strip()\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # --- Main loop over feature datasets ---\n",
    "# # Expects: feature_datasets: Dict[int, pd.DataFrame]\n",
    "# results_rows = []\n",
    "\n",
    "# processed = 0\n",
    "# for fid, df in tqdm(list(feature_datasets.items())[:1200], desc=\"llm to opus\"):\n",
    "#     # Build a compact table for the model\n",
    "#     view = _coerce_and_trim_cols(df, PREFERRED_COLS)\n",
    "#     prompt = build_prompt(view)\n",
    "\n",
    "#     try:\n",
    "#         text = call_claude(prompt)\n",
    "#         parsed = parse_description_and_summary(text)\n",
    "#     except Exception as e:\n",
    "#         parsed = {\"description\": \"\", \"summary\": \"\", \"raw\": f\"[ERROR] {e}\"}\n",
    "\n",
    "#     results_rows.append({\n",
    "#         \"feature_id\": fid,\n",
    "#         \"n_rows_shown\": len(view),\n",
    "#         \"description\": parsed[\"description\"],\n",
    "#         \"summary\": parsed[\"summary\"],\n",
    "#         \"raw_response\": parsed[\"raw\"],\n",
    "#     })\n",
    "\n",
    "#     processed += 1\n",
    "#     if processed % CHECKPOINT_EVERY == 0:\n",
    "#         pd.DataFrame(results_rows).to_csv(OUTPUT_PATH, index=False)\n",
    "\n",
    "# # Final save\n",
    "# df_results = pd.DataFrame(results_rows)\n",
    "# df_results.to_csv(OUTPUT_PATH, index=False)\n",
    "# print(f\"[done] {len(df_results)} features → {OUTPUT_PATH}\")\n",
    "# df_results.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[done] 1 features → claude_feature_annotations.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_id</th>\n",
       "      <th>n_rows_shown</th>\n",
       "      <th>description</th>\n",
       "      <th>summary</th>\n",
       "      <th>raw_response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2167</td>\n",
       "      <td>29</td>\n",
       "      <td>The activation patterns are characterized by: ...</td>\n",
       "      <td>The feature activates on zinc finger domains a...</td>\n",
       "      <td>**Description:**\\n\\nThe activation patterns ar...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature_id  n_rows_shown  \\\n",
       "0        2167            29   \n",
       "\n",
       "                                         description  \\\n",
       "0  The activation patterns are characterized by: ...   \n",
       "\n",
       "                                             summary  \\\n",
       "0  The feature activates on zinc finger domains a...   \n",
       "\n",
       "                                        raw_response  \n",
       "0  **Description:**\\n\\nThe activation patterns ar...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_rows = []\n",
    "processed = 0\n",
    "\n",
    "fid = 2167\n",
    "df  = feature_datasets[fid]          # <- this is a DataFrame\n",
    "\n",
    "view   = _coerce_and_trim_cols(df, PREFERRED_COLS)\n",
    "prompt = build_prompt(view)\n",
    "\n",
    "try:\n",
    "    text   = call_claude(prompt)\n",
    "    parsed = parse_description_and_summary(text)\n",
    "except Exception as e:\n",
    "    parsed = {\"description\": \"\", \"summary\": \"\", \"raw\": f\"[ERROR] {e}\"}\n",
    "\n",
    "results_rows.append({\n",
    "    \"feature_id\": fid,\n",
    "    \"n_rows_shown\": len(view),\n",
    "    \"description\": parsed[\"description\"],\n",
    "    \"summary\": parsed[\"summary\"],\n",
    "    \"raw_response\": parsed[\"raw\"],\n",
    "})\n",
    "\n",
    "# Save\n",
    "df_results = pd.DataFrame(results_rows)\n",
    "df_results.to_csv(OUTPUT_PATH, index=False)\n",
    "print(f\"[done] {len(df_results)} features → {OUTPUT_PATH}\")\n",
    "display(df_results.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validating feature descriptions via activaiton pattern prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io, csv, json, math, textwrap\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "\n",
    "# ---------- 1) Choose compact metadata columns ----------\n",
    "META_COLS = [\n",
    "    \"Entry\", \"Reviewed\", \"Protein names\", \"Length\", \"EC number\",\n",
    "    \"Active site\", \"Binding site\", \"Metal binding\", \"Site\",\n",
    "    \"Domain [FT]\", \"Motif\", \"Region\", \"Zinc finger\",\n",
    "]\n",
    "\n",
    "def _coerce_cols(df: pd.DataFrame, cols: List[str]) -> pd.DataFrame:\n",
    "    keep = [c for c in cols if c in df.columns]\n",
    "    out = df[keep].copy()\n",
    "    # Normalize NaNs to empty strings for cleaner prompts\n",
    "    for c in keep:\n",
    "        out[c] = out[c].fillna(\"\").astype(str).str.strip()\n",
    "    return out\n",
    "\n",
    "# ---------- 2) Build a compact, token-budget-friendly metadata block ----------\n",
    "def make_metadata_block(df_query: pd.DataFrame, max_rows: int = 20) -> str:\n",
    "    \"\"\"\n",
    "    Turn metadata rows into a compact, line-based table the LLM can scan quickly.\n",
    "    We avoid long sequences to keep tokens down.\n",
    "    \"\"\"\n",
    "    dfm = _coerce_cols(df_query, META_COLS).head(max_rows)\n",
    "    # Render as CSV-like lines (no Markdown) to discourage prose\n",
    "    lines = [\",\".join(dfm.columns)]\n",
    "    for _, row in dfm.iterrows():\n",
    "        vals = [row[c].replace(\"\\n\", \" \").replace(\",\", \";\") for c in dfm.columns]\n",
    "        lines.append(\",\".join(vals))\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "\n",
    "# ---------- 3) Prompt template for validation ----------\n",
    "VALIDATION_INSTRUCTIONS = \"\"\"\\\n",
    "You are scoring how strongly a single latent feature activates on proteins based on Swiss-Prot metadata.\n",
    "\n",
    "Task: For each query protein, predict the *maximum feature activation value* in [0.0, 1.0]\n",
    "according to how well it matches the described activation patterns.\n",
    "\n",
    "Rules:\n",
    "- Output ONLY a CSV with the header EXACTLY: \"Entry,Maximum activation value\"\n",
    "- One row per Entry in the query table, same Entry IDs.\n",
    "- Use a decimal in [0.0, 1.0]; you may use up to 3 decimals (e.g., 0.137).\n",
    "- No extra text, explanations, units, JSON, code fences, or headers beyond that single CSV.\n",
    "- If the protein is unrelated to the pattern, output 0.0.\n",
    "- Base your judgment only on the provided Swiss-Prot metadata and the description below.\n",
    "\n",
    "Scoring rubric (guidance, not to be output):\n",
    "- Strong, explicit matches to motifs/sites/domains directly named in the description → closer to 0.8–1.0\n",
    "- Partial matches or related patterns (e.g., same fold/family, weaker motif evidence) → ~0.3–0.7\n",
    "- Weak/indirect hints only → ~0.05–0.3\n",
    "- No match → 0.0\n",
    "\"\"\"\n",
    "\n",
    "def build_validation_prompt(\n",
    "    feature_id: int,\n",
    "    description: str,\n",
    "    metadata_csv_block: str,\n",
    "    query_entries: List[str],\n",
    ") -> str:\n",
    "    # Build an empty query CSV the model should fill\n",
    "    empty_table = \"Entry,Maximum activation value\\n\" + \"\\n\".join(query_entries)\n",
    "    return textwrap.dedent(f\"\"\"\\\n",
    "        {VALIDATION_INSTRUCTIONS}\n",
    "\n",
    "        Feature ID: f/{feature_id}\n",
    "\n",
    "        The activation patterns are characterized by:\n",
    "        \\\"\\\"\\\"{description.strip()}\\\"\\\"\\\"\n",
    "\n",
    "        Swiss-Prot metadata for the query proteins (CSV):\n",
    "        {metadata_csv_block}\n",
    "\n",
    "        Table to fill out (return ONLY this table with predicted values):\n",
    "        {empty_table}\n",
    "    \"\"\").strip()\n",
    "\n",
    "# ---------- 4) Parser for the model's CSV output ----------\n",
    "def parse_prediction_csv(csv_text: str) -> pd.DataFrame:\n",
    "    # Be robust to accidental code fences or whitespace\n",
    "    txt = csv_text.strip()\n",
    "    if txt.startswith(\"```\"):\n",
    "        txt = txt.strip(\"`\").strip()\n",
    "        # Remove possible language hints like ```csv\n",
    "        first_newline = txt.find(\"\\n\")\n",
    "        if first_newline != -1:\n",
    "            maybe_header = txt[:first_newline].lower()\n",
    "            if \"entry\" not in maybe_header:\n",
    "                txt = txt[first_newline+1:]\n",
    "\n",
    "    # Parse CSV strictly on two columns\n",
    "    reader = csv.reader(io.StringIO(txt))\n",
    "    rows = list(reader)\n",
    "    if not rows or len(rows[0]) < 2 or rows[0][0].strip().lower() != \"entry\":\n",
    "        raise ValueError(\"Missing or malformed CSV header. Expected 'Entry,Maximum activation value'.\")\n",
    "\n",
    "    data = []\n",
    "    for r in rows[1:]:\n",
    "        if not r:\n",
    "            continue\n",
    "        entry = r[0].strip()\n",
    "        val_raw = r[1].strip() if len(r) > 1 else \"\"\n",
    "        if not entry:\n",
    "            continue\n",
    "        # Coerce to float in [0,1]\n",
    "        try:\n",
    "            v = float(val_raw)\n",
    "        except Exception:\n",
    "            # Try to strip stray chars\n",
    "            val_raw2 = \"\".join(ch for ch in val_raw if (ch.isdigit() or ch in \".\"))\n",
    "            v = float(val_raw2) if val_raw2 else np.nan\n",
    "        if math.isnan(v):\n",
    "            v = 0.0\n",
    "        v = max(0.0, min(1.0, v))\n",
    "        data.append((entry, v))\n",
    "\n",
    "    df = pd.DataFrame(data, columns=[\"Entry\", \"pred_activation\"])\n",
    "    # Deduplicate keeping the first occurrence\n",
    "    df = df[~df[\"Entry\"].duplicated(keep=\"first\")].reset_index(drop=True)\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Tuple, Dict\n",
    "\n",
    "def predict_activations_via_llm(\n",
    "    feature_id: int,\n",
    "    description: str,\n",
    "    df_all: pd.DataFrame,\n",
    "    *,\n",
    "    n_query: int = 50,\n",
    "    seed: int = 0,\n",
    "    batch_size: int = 20,\n",
    "    use_entry_col: bool = True,\n",
    "    call_fn=call_claude,  # your Bedrock-backed call_claude(prompt)->str\n",
    ") -> Tuple[pd.DataFrame, Dict[str, float]]:\n",
    "    \"\"\"\n",
    "    Select a held-out set, ask Claude to predict max activation, parse predictions, and evaluate.\n",
    "\n",
    "    df_all must include 'Entry' (or 'uniprot_id'), metadata cols, and 'activation' (float in [0, 1]).\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    id_col = \"Entry\" if (use_entry_col and \"Entry\" in df_all.columns) else \"uniprot_id\"\n",
    "\n",
    "    # Keep rows that have an ID and activation\n",
    "    df_all = df_all.dropna(subset=[id_col, \"activation\"]).copy()\n",
    "    df_all[id_col] = df_all[id_col].astype(str)\n",
    "\n",
    "    # Sample query set (held-out)\n",
    "    if n_query > len(df_all):\n",
    "        n_query = len(df_all)\n",
    "    query_idx = rng.choice(df_all.index.values, size=n_query, replace=False)\n",
    "    df_query = df_all.loc[query_idx].copy()\n",
    "\n",
    "    # Predict in batches to control tokens\n",
    "    preds = []\n",
    "    for start in range(0, len(df_query), batch_size):\n",
    "        chunk = df_query.iloc[start:start+batch_size].copy()\n",
    "\n",
    "        # Prepare metadata CSV block and query Entry list\n",
    "        meta_block = make_metadata_block(chunk)\n",
    "        entries = list(chunk[id_col].values)\n",
    "\n",
    "        prompt = build_validation_prompt(\n",
    "            feature_id=feature_id,\n",
    "            description=description,\n",
    "            metadata_csv_block=meta_block,\n",
    "            query_entries=entries,\n",
    "        )\n",
    "\n",
    "        # Strong output constraint: ONLY CSV\n",
    "        resp_text = call_fn(\n",
    "            prompt,\n",
    "            system=\"Return only the CSV requested. No extra text.\"\n",
    "        )\n",
    "\n",
    "        df_pred = parse_prediction_csv(resp_text)\n",
    "        preds.append(df_pred)\n",
    "\n",
    "    df_pred_all = pd.concat(preds, ignore_index=True)\n",
    "\n",
    "    # Join with ground truth (use df_query here)\n",
    "    df_eval = df_query[[id_col, \"activation\"]].merge(\n",
    "        df_pred_all.rename(columns={\"Entry\": id_col}),\n",
    "        on=id_col,\n",
    "        how=\"left\",\n",
    "    )\n",
    "    df_eval[\"pred_activation\"] = df_eval[\"pred_activation\"].fillna(0.0)\n",
    "\n",
    "    # Metrics\n",
    "    y = df_eval[\"activation\"].astype(float).values\n",
    "    yhat = df_eval[\"pred_activation\"].astype(float).values\n",
    "    pearson = float(np.corrcoef(y, yhat)[0, 1]) if len(df_eval) > 1 else np.nan\n",
    "    mae = float(np.mean(np.abs(y - yhat))) if len(df_eval) else np.nan\n",
    "    mse = float(np.mean((y - yhat) ** 2)) if len(df_eval) else np.nan\n",
    "    metrics = {\"pearson_r\": pearson, \"mae\": mae, \"mse\": mse}\n",
    "\n",
    "    return df_eval.sort_values(id_col).reset_index(drop=True), metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at the big summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_id</th>\n",
       "      <th>n_rows_shown</th>\n",
       "      <th>description</th>\n",
       "      <th>summary</th>\n",
       "      <th>raw_response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5590</td>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Looking at this protein dataset, I can analyze...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7300</td>\n",
       "      <td>26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Looking at this protein dataset, I can identif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>595</td>\n",
       "      <td>29</td>\n",
       "      <td>The activation patterns are characterized by: ...</td>\n",
       "      <td>The feature activates on disordered protein re...</td>\n",
       "      <td>**Description:**\\n\\nThe activation patterns ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2669</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>**The activation patterns are characterized by...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6281</td>\n",
       "      <td>23</td>\n",
       "      <td>The activation patterns are characterized by: ...</td>\n",
       "      <td>The feature activates on C-terminal extensions...</td>\n",
       "      <td>The activation patterns are characterized by: ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature_id  n_rows_shown  \\\n",
       "0        5590            21   \n",
       "1        7300            26   \n",
       "2         595            29   \n",
       "3        2669            19   \n",
       "4        6281            23   \n",
       "\n",
       "                                         description  \\\n",
       "0                                                NaN   \n",
       "1                                                NaN   \n",
       "2  The activation patterns are characterized by: ...   \n",
       "3                                                NaN   \n",
       "4  The activation patterns are characterized by: ...   \n",
       "\n",
       "                                             summary  \\\n",
       "0                                                NaN   \n",
       "1                                                NaN   \n",
       "2  The feature activates on disordered protein re...   \n",
       "3                                                NaN   \n",
       "4  The feature activates on C-terminal extensions...   \n",
       "\n",
       "                                        raw_response  \n",
       "0  Looking at this protein dataset, I can analyze...  \n",
       "1  Looking at this protein dataset, I can identif...  \n",
       "2  **Description:**\\n\\nThe activation patterns ar...  \n",
       "3  **The activation patterns are characterized by...  \n",
       "4  The activation patterns are characterized by: ...  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pn\n",
    "big_summary = pd.read_csv(\"final_claude_feature_annotations.csv\")\n",
    "big_summary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def pick_10_features(big_summary, feature_datasets, min_rows=30, seed=0):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    cand = big_summary[\n",
    "        big_summary[\"description\"].notna() & big_summary[\"summary\"].notna()\n",
    "    ].copy()\n",
    "\n",
    "    # Keep only features that have a usable df\n",
    "    keep = []\n",
    "    for _, row in cand.iterrows():\n",
    "        fid = int(row[\"feature_id\"])\n",
    "        if fid not in feature_datasets:\n",
    "            continue\n",
    "        df = feature_datasets[fid]\n",
    "        has_id = (\"Entry\" in df.columns) or (\"uniprot_id\" in df.columns)\n",
    "        if not has_id or \"activation\" not in df.columns:\n",
    "            continue\n",
    "        if df[\"activation\"].dropna().shape[0] < min_rows:\n",
    "            continue\n",
    "        keep.append(fid)\n",
    "\n",
    "    keep = list(dict.fromkeys(keep))  # dedup\n",
    "    if not keep:\n",
    "        raise ValueError(\"No valid features with descriptions + usable data.\")\n",
    "    if len(keep) > 10:\n",
    "        keep = list(rng.choice(keep, size=10, replace=False))\n",
    "    return keep\n",
    "\n",
    "# ---- Run it\n",
    "feature_ids = pick_10_features(big_summary, feature_datasets, min_rows=30, seed=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9093, 5511, 9734, 7274, 8939, 1068, 5297, 1243, 1297, 117]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "features: 100%|██████████| 10/10 [01:11<00:00,  7.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   feature_id  pearson_r       mae       mse\n",
      "3        7274   0.971164  0.053357  0.009148\n",
      "0        9093   0.967111  0.068453  0.011185\n",
      "6        5297   0.935163  0.083581  0.027240\n",
      "7        1243   0.927260  0.101508  0.024594\n",
      "8        1297   0.900699  0.111129  0.037984\n",
      "4        8939   0.884668  0.087675  0.033477\n",
      "9         117   0.792196  0.146848  0.051391\n",
      "2        9734   0.717159  0.161985  0.064969\n",
      "1        5511   0.689147  0.200065  0.098775\n",
      "5        1068   0.541301  0.279320  0.156865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Entry</th>\n",
       "      <th>activation</th>\n",
       "      <th>pred_activation</th>\n",
       "      <th>feature_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A4YH98</td>\n",
       "      <td>0.944795</td>\n",
       "      <td>0.9</td>\n",
       "      <td>9093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A8AAB6</td>\n",
       "      <td>0.870041</td>\n",
       "      <td>0.9</td>\n",
       "      <td>9093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A8MBV3</td>\n",
       "      <td>0.915112</td>\n",
       "      <td>0.9</td>\n",
       "      <td>9093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B5VPM5</td>\n",
       "      <td>0.300445</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B5Z062</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9093</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Entry  activation  pred_activation  feature_id\n",
       "0  A4YH98    0.944795              0.9        9093\n",
       "1  A8AAB6    0.870041              0.9        9093\n",
       "2  A8MBV3    0.915112              0.9        9093\n",
       "3  B5VPM5    0.300445              0.0        9093\n",
       "4  B5Z062    0.000000              0.0        9093"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = []\n",
    "all_eval = []\n",
    "from tqdm import tqdm\n",
    "for fid in tqdm(feature_ids, desc=\"features\"):\n",
    "    desc = big_summary.loc[big_summary[\"feature_id\"] == fid, \"description\"].iloc[0]\n",
    "    df_feat = feature_datasets[fid]\n",
    "\n",
    "    df_eval, stats = predict_activations_via_llm(\n",
    "        feature_id=fid,\n",
    "        description=desc,\n",
    "        df_all=df_feat,\n",
    "        n_query=50,      # tweak as you like\n",
    "        seed=42,\n",
    "        batch_size=20,\n",
    "    )\n",
    "    stats[\"feature_id\"] = fid\n",
    "    results.append(stats)\n",
    "    df_eval[\"feature_id\"] = fid\n",
    "    all_eval.append(df_eval)\n",
    "\n",
    "metrics_df = pd.DataFrame(results)[[\"feature_id\",\"pearson_r\",\"mae\",\"mse\"]].sort_values(\"pearson_r\", ascending=False)\n",
    "preview_eval = pd.concat(all_eval, ignore_index=True)\n",
    "\n",
    "print(metrics_df)\n",
    "preview_eval.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Entry', 'activation', 'pred_activation', 'feature_id'], dtype='object')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preview_eval.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "feature_id\n",
       "8939    38\n",
       "1243    38\n",
       "9093    38\n",
       "5297    35\n",
       "5511    34\n",
       "dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many proteins did we evaluate per feature?\n",
    "preview_eval.groupby(\"feature_id\").size().sort_values(ascending=False).head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Entry</th>\n",
       "      <th>activation</th>\n",
       "      <th>pred_activation</th>\n",
       "      <th>feature_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A4YH98</td>\n",
       "      <td>0.944795</td>\n",
       "      <td>0.9</td>\n",
       "      <td>9093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A8AAB6</td>\n",
       "      <td>0.870041</td>\n",
       "      <td>0.9</td>\n",
       "      <td>9093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A8MBV3</td>\n",
       "      <td>0.915112</td>\n",
       "      <td>0.9</td>\n",
       "      <td>9093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B5VPM5</td>\n",
       "      <td>0.300445</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B5Z062</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>C3MQ89</td>\n",
       "      <td>0.745696</td>\n",
       "      <td>0.6</td>\n",
       "      <td>9093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>C3MQN7</td>\n",
       "      <td>0.916713</td>\n",
       "      <td>0.9</td>\n",
       "      <td>9093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>C3MWN7</td>\n",
       "      <td>0.916713</td>\n",
       "      <td>0.9</td>\n",
       "      <td>9093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>C3NEW5</td>\n",
       "      <td>0.916713</td>\n",
       "      <td>0.9</td>\n",
       "      <td>9093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>C3NGS9</td>\n",
       "      <td>0.916713</td>\n",
       "      <td>0.9</td>\n",
       "      <td>9093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>C4KHI6</td>\n",
       "      <td>0.748224</td>\n",
       "      <td>0.6</td>\n",
       "      <td>9093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>C4KHX2</td>\n",
       "      <td>0.916713</td>\n",
       "      <td>0.9</td>\n",
       "      <td>9093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>C9K7C3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>O22130</td>\n",
       "      <td>0.529096</td>\n",
       "      <td>0.6</td>\n",
       "      <td>9093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>O43823</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>O49658</td>\n",
       "      <td>0.449939</td>\n",
       "      <td>0.6</td>\n",
       "      <td>9093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>P0A0P8</td>\n",
       "      <td>0.226291</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>P32629</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>P50000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>P9WQ03</td>\n",
       "      <td>0.481161</td>\n",
       "      <td>0.6</td>\n",
       "      <td>9093</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Entry  activation  pred_activation  feature_id\n",
       "0   A4YH98    0.944795              0.9        9093\n",
       "1   A8AAB6    0.870041              0.9        9093\n",
       "2   A8MBV3    0.915112              0.9        9093\n",
       "3   B5VPM5    0.300445              0.0        9093\n",
       "4   B5Z062    0.000000              0.0        9093\n",
       "5   C3MQ89    0.745696              0.6        9093\n",
       "6   C3MQN7    0.916713              0.9        9093\n",
       "7   C3MWN7    0.916713              0.9        9093\n",
       "8   C3NEW5    0.916713              0.9        9093\n",
       "9   C3NGS9    0.916713              0.9        9093\n",
       "10  C4KHI6    0.748224              0.6        9093\n",
       "11  C4KHX2    0.916713              0.9        9093\n",
       "12  C9K7C3    0.000000              0.0        9093\n",
       "13  O22130    0.529096              0.6        9093\n",
       "14  O43823    0.000000              0.0        9093\n",
       "15  O49658    0.449939              0.6        9093\n",
       "16  P0A0P8    0.226291              0.0        9093\n",
       "17  P32629    0.000000              0.0        9093\n",
       "18  P50000    0.000000              0.0        9093\n",
       "19  P9WQ03    0.481161              0.6        9093"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# See only one feature’s rows\n",
    "preview_eval.query(\"feature_id == 9093\").head(20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Entry</th>\n",
       "      <th>activation</th>\n",
       "      <th>pred_activation</th>\n",
       "      <th>feature_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>A0A848M4Z0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.10</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>A2X1A1</td>\n",
       "      <td>0.439998</td>\n",
       "      <td>0.65</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>A5N7J5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.10</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>A0A1L1QK34</td>\n",
       "      <td>0.238514</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>B1VH34</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>B4SW28</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>A0A977JPB5</td>\n",
       "      <td>0.482518</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>A2X2K3</td>\n",
       "      <td>0.221492</td>\n",
       "      <td>0.20</td>\n",
       "      <td>1243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>A4W8A9</td>\n",
       "      <td>0.948163</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>A4GYP5</td>\n",
       "      <td>0.481105</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>A6Q3U3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>A7HQY7</td>\n",
       "      <td>0.173965</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>A0L065</td>\n",
       "      <td>0.980236</td>\n",
       "      <td>0.91</td>\n",
       "      <td>5297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>A4QLU0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>A4W1V8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>A1EA04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.65</td>\n",
       "      <td>5511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>A1JPP6</td>\n",
       "      <td>0.413447</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>A1WAX5</td>\n",
       "      <td>0.547943</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>A4FW85</td>\n",
       "      <td>0.271499</td>\n",
       "      <td>0.20</td>\n",
       "      <td>7274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>B7MAI6</td>\n",
       "      <td>0.150073</td>\n",
       "      <td>0.10</td>\n",
       "      <td>7274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>D4AWM9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>A0A217ER65</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>A7NEH8</td>\n",
       "      <td>0.161204</td>\n",
       "      <td>0.20</td>\n",
       "      <td>8939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>A8L4H3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A4YH98</td>\n",
       "      <td>0.944795</td>\n",
       "      <td>0.90</td>\n",
       "      <td>9093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A8AAB6</td>\n",
       "      <td>0.870041</td>\n",
       "      <td>0.90</td>\n",
       "      <td>9093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A8MBV3</td>\n",
       "      <td>0.915112</td>\n",
       "      <td>0.90</td>\n",
       "      <td>9093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>A0QV24</td>\n",
       "      <td>0.453641</td>\n",
       "      <td>0.20</td>\n",
       "      <td>9734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>A2BT26</td>\n",
       "      <td>0.713357</td>\n",
       "      <td>0.80</td>\n",
       "      <td>9734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>A3QB90</td>\n",
       "      <td>0.551319</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9734</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Entry  activation  pred_activation  feature_id\n",
       "307  A0A848M4Z0    0.000000             0.10         117\n",
       "308      A2X1A1    0.439998             0.65         117\n",
       "309      A5N7J5    0.000000             0.10         117\n",
       "173  A0A1L1QK34    0.238514             0.90        1068\n",
       "174      B1VH34    0.000000             0.00        1068\n",
       "175      B4SW28    0.000000             0.00        1068\n",
       "239  A0A977JPB5    0.482518             0.60        1243\n",
       "240      A2X2K3    0.221492             0.20        1243\n",
       "241      A4W8A9    0.948163             1.00        1243\n",
       "277      A4GYP5    0.481105             0.50        1297\n",
       "278      A6Q3U3    0.000000             0.00        1297\n",
       "279      A7HQY7    0.173965             0.00        1297\n",
       "204      A0L065    0.980236             0.91        5297\n",
       "205      A4QLU0    0.000000             0.00        5297\n",
       "206      A4W1V8    0.000000             0.00        5297\n",
       "38       A1EA04    0.000000             0.65        5511\n",
       "39       A1JPP6    0.413447             0.00        5511\n",
       "40       A1WAX5    0.547943             0.00        5511\n",
       "102      A4FW85    0.271499             0.20        7274\n",
       "103      B7MAI6    0.150073             0.10        7274\n",
       "104      D4AWM9    0.000000             0.00        7274\n",
       "135  A0A217ER65    0.000000             0.00        8939\n",
       "136      A7NEH8    0.161204             0.20        8939\n",
       "137      A8L4H3    0.000000             0.00        8939\n",
       "0        A4YH98    0.944795             0.90        9093\n",
       "1        A8AAB6    0.870041             0.90        9093\n",
       "2        A8MBV3    0.915112             0.90        9093\n",
       "72       A0QV24    0.453641             0.20        9734\n",
       "73       A2BT26    0.713357             0.80        9734\n",
       "74       A3QB90    0.551319             0.00        9734"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Peek a few rows per feature\n",
    "preview_eval.sort_values([\"feature_id\", \"Entry\"]).groupby(\"feature_id\").head(3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9671108645836247"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify correlation for one feature (should match metrics_df)\n",
    "fid = 9093\n",
    "sub = preview_eval[preview_eval[\"feature_id\"] == fid]\n",
    "np.corrcoef(sub[\"activation\"], sub[\"pred_activation\"])[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['kde_plots/feature_7274.png',\n",
       " 'kde_plots/feature_9093.png',\n",
       " 'kde_plots/feature_5297.png',\n",
       " 'kde_plots/feature_1243.png',\n",
       " 'kde_plots/feature_1297.png',\n",
       " 'kde_plots/feature_8939.png']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, textwrap\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# preview_eval: long DF with columns [\"Entry\",\"activation\",\"pred_activation\",\"feature_id\", ...]\n",
    "# metrics_df:   DF with one row per feature, columns [\"feature_id\",\"pearson_r\",\"mae\",\"mse\"]\n",
    "# big_summary:  DF with [\"feature_id\",\"description\", ...] (or \"summary\" if you prefer)\n",
    "\n",
    "def _kde2d_unit_square(x, y, grid=150, bandwidth=0.08):\n",
    "    \"\"\"\n",
    "    Very small 2D Gaussian KDE on [0,1]x[0,1] without SciPy.\n",
    "    Fine for n ~ 50–200 points.\n",
    "    \"\"\"\n",
    "    xi = np.linspace(0.0, 1.0, grid)\n",
    "    yi = np.linspace(0.0, 1.0, grid)\n",
    "    X, Y = np.meshgrid(xi, yi)\n",
    "    Z = np.zeros_like(X)\n",
    "    bw2 = 2 * (bandwidth ** 2)\n",
    "\n",
    "    # Sum Gaussian bumps\n",
    "    for x0, y0 in zip(x, y):\n",
    "        Z += np.exp(-((X - x0) ** 2 + (Y - y0) ** 2) / bw2)\n",
    "\n",
    "    # Normalization not critical for visualization; this keeps values sane\n",
    "    Z /= (len(x) if len(x) else 1)\n",
    "    return X, Y, Z\n",
    "\n",
    "def plot_kde_for_feature(sub: pd.DataFrame, fid: int, pearson: float, desc: str,\n",
    "                         out_dir: str = \"kde_plots\", bandwidth: float = 0.08):\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    x = sub[\"pred_activation\"].astype(float).to_numpy()\n",
    "    y = sub[\"activation\"].astype(float).to_numpy()\n",
    "\n",
    "    if len(x) < 2:\n",
    "        print(f\"[skip] feature {fid}: not enough points\")\n",
    "        return None\n",
    "\n",
    "    X, Y, Z = _kde2d_unit_square(x, y, grid=160, bandwidth=bandwidth)\n",
    "\n",
    "    plt.figure(figsize=(5.2, 4.6))\n",
    "    # Density\n",
    "    plt.contourf(X, Y, Z, levels=24)   # no explicit colors (uses defaults)\n",
    "    # Diagonal\n",
    "    plt.plot([0, 1], [0, 1])\n",
    "    # Light scatter overlay to show points\n",
    "    plt.scatter(x, y, s=15, alpha=0.5)\n",
    "\n",
    "    plt.xlabel(\"Predicted Activation\")\n",
    "    plt.ylabel(\"True Activation\")\n",
    "    plt.title(f\"Feature {fid} (pearson r = {pearson:.2f})\")\n",
    "\n",
    "    # Wrap the description into a neat paragraph above the plot\n",
    "    if isinstance(desc, str) and desc.strip():\n",
    "        wrapped = textwrap.fill(desc.strip(), width=90)\n",
    "        plt.gcf().text(0.5, 1.02, wrapped, ha=\"center\", va=\"bottom\")\n",
    "\n",
    "    out_path = os.path.join(out_dir, f\"feature_{fid}.png\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_path, dpi=200, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "    return out_path\n",
    "\n",
    "def plot_kde_for_features(preview_eval: pd.DataFrame,\n",
    "                          metrics_df: pd.DataFrame,\n",
    "                          big_summary: pd.DataFrame,\n",
    "                          feature_ids=None,\n",
    "                          top_k: int = None,\n",
    "                          out_dir: str = \"kde_plots\",\n",
    "                          bandwidth: float = 0.08):\n",
    "    \"\"\"\n",
    "    - If feature_ids is given, plots those.\n",
    "    - Else if top_k is given, takes top_k by pearson_r.\n",
    "    - Else plots all features present in metrics_df.\n",
    "    \"\"\"\n",
    "    # Build quick lookups\n",
    "    pearson_map = metrics_df.set_index(\"feature_id\")[\"pearson_r\"].to_dict()\n",
    "    # prefer 'description'; fall back to 'summary' if missing\n",
    "    desc_series = (big_summary.set_index(\"feature_id\")[\"description\"]\n",
    "                   if \"description\" in big_summary.columns\n",
    "                   else big_summary.set_index(\"feature_id\")[\"summary\"])\n",
    "    desc_map = desc_series.fillna(\"\").to_dict()\n",
    "\n",
    "    if feature_ids is None:\n",
    "        fids = list(metrics_df[\"feature_id\"])\n",
    "        if top_k is not None and top_k < len(fids):\n",
    "            fids = (metrics_df.sort_values(\"pearson_r\", ascending=False)\n",
    "                              .head(top_k)[\"feature_id\"].tolist())\n",
    "    else:\n",
    "        fids = list(feature_ids)\n",
    "\n",
    "    saved = []\n",
    "    for fid in fids:\n",
    "        sub = preview_eval[preview_eval[\"feature_id\"] == fid].copy()\n",
    "        if sub.empty:\n",
    "            print(f\"[skip] feature {fid}: no rows in preview_eval\")\n",
    "            continue\n",
    "        pearson = float(pearson_map.get(fid, np.corrcoef(\n",
    "            sub[\"activation\"].astype(float), sub[\"pred_activation\"].astype(float)\n",
    "        )[0,1]))\n",
    "        desc = desc_map.get(fid, \"\")\n",
    "        path = plot_kde_for_feature(sub, fid, pearson, desc, out_dir=out_dir, bandwidth=bandwidth)\n",
    "        if path:\n",
    "            saved.append(path)\n",
    "    return saved\n",
    "\n",
    "# ---- Example usage ----\n",
    "# Pick top 6 features by Pearson r and plot\n",
    "saved_paths = plot_kde_for_features(preview_eval, metrics_df, big_summary, top_k=6, out_dir=\"kde_plots\")\n",
    "saved_paths\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.13 ('interplm')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1106d1d489397abf5d77132595a521cf67d890f951d991cd34215b053d2a27e6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
