{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Large-Scale SAE Analysis with UniProt Dataset\n",
    "\n",
    "This notebook demonstrates how to analyze sparse autoencoders (SAEs) using a larger UniProt dataset,\n",
    "following the InterPLM recommendations. We'll download Swiss-Prot data, create annotations, and mine SAE features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/.cs/conda/envs/interplm/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import subprocess\n",
    "import gzip\n",
    "import urllib.request\n",
    "from Bio import SeqIO\n",
    "import re\n",
    "from collections import defaultdict\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "# InterPLM imports\n",
    "from transformers import AutoTokenizer, EsmModel\n",
    "from interplm.sae.inference import load_sae_from_hf\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_curve, roc_curve\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Set up data directory\n",
    "DATA_DIR = Path(os.environ.get('INTERPLM_DATA', '/home/ec2-user/InterPLM/data'))\n",
    "DATA_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'features_all' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 35\u001b[39m\n\u001b[32m     32\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m pd.concat(frames, ignore_index=\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mif\u001b[39;00m frames \u001b[38;5;28;01melse\u001b[39;00m pd.DataFrame()\n\u001b[32m     34\u001b[39m \u001b[38;5;66;03m# Use your processed IDs:\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m want = \u001b[43mfeatures_all\u001b[49m[\u001b[33m\"\u001b[39m\u001b[33muniprot_id\u001b[39m\u001b[33m\"\u001b[39m].unique().tolist()\n\u001b[32m     36\u001b[39m ann  = fetch_for_accessions(want)\n\u001b[32m     37\u001b[39m ann.to_csv(\u001b[33m\"\u001b[39m\u001b[33muniprot_annotations_for_my_set.tsv\u001b[39m\u001b[33m\"\u001b[39m, sep=\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[33m\"\u001b[39m, index=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[31mNameError\u001b[39m: name 'features_all' is not defined"
     ]
    }
   ],
   "source": [
    "import time, requests, pandas as pd\n",
    "from io import StringIO\n",
    "from pathlib import Path\n",
    "\n",
    "SEARCH = \"https://rest.uniprot.org/uniprotkb/search\"\n",
    "fields = (\n",
    "    \"accession,reviewed,protein_name,length,sequence,\"\n",
    "    \"ec,ft_act_site,ft_binding,cc_cofactor,ft_disulfid,\"\n",
    "    \"ft_carbohyd,ft_lipid,ft_mod_res,ft_signal,ft_transit,\"\n",
    "    \"ft_helix,ft_turn,ft_strand,ft_coiled,cc_domain,\"\n",
    "    \"ft_compbias,ft_domain,ft_motif,ft_region,ft_zn_fing\"\n",
    ")\n",
    "\n",
    "def fetch_for_accessions(accessions, chunk=200, pause=0.2, retries=5):\n",
    "    accs = list(dict.fromkeys(accessions))\n",
    "    frames = []\n",
    "    for i in range(0, len(accs), chunk):\n",
    "        batch = accs[i:i+chunk]\n",
    "        params = {\n",
    "            \"query\": \"(\" + \" OR \".join(f\"accession:{a}\" for a in batch) + \")\",\n",
    "            \"fields\": fields,\n",
    "            \"format\": \"tsv\",\n",
    "        }\n",
    "        for attempt in range(retries):\n",
    "            r = requests.get(SEARCH, params=params, timeout=60)\n",
    "            if r.status_code == 200: break\n",
    "            if r.status_code in (429,500,502,503,504):\n",
    "                time.sleep(pause * (2**attempt)); continue\n",
    "            r.raise_for_status()\n",
    "        frames.append(pd.read_csv(StringIO(r.text), sep=\"\\t\"))\n",
    "        if pause: time.sleep(pause)\n",
    "    return pd.concat(frames, ignore_index=True) if frames else pd.DataFrame()\n",
    "\n",
    "# Use your processed IDs:\n",
    "want = features_all[\"uniprot_id\"].unique().tolist()\n",
    "ann  = fetch_for_accessions(want)\n",
    "ann.to_csv(\"uniprot_annotations_for_my_set.tsv\", sep=\"\\t\", index=False)\n",
    "print(ann.shape, \"→ uniprot_annotations_for_my_set.tsv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Download Large UniProt Dataset\n",
    "\n",
    "Following InterPLM's recommendations, we'll download Swiss-Prot which contains high-quality, manually curated protein sequences with rich annotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FASTA file already exists at /home/ec2-user/InterPLM/data/uniprot/uniprot_sprot.fasta.gz\n",
      "Annotations file already exists at /home/ec2-user/InterPLM/data/uniprot/proteins_annotations.tsv.gz\n",
      "\n",
      "FASTA file: /home/ec2-user/InterPLM/data/uniprot/uniprot_sprot.fasta.gz\n",
      "Annotations file: /home/ec2-user/InterPLM/data/uniprot/proteins_annotations.tsv.gz\n"
     ]
    }
   ],
   "source": [
    "def download_uniprot_data(data_dir: Path, subset_size: int = 50000):\n",
    "    \"\"\"\n",
    "    Download UniProt Swiss-Prot data with annotations.\n",
    "    Following InterPLM README recommendations for larger dataset analysis.\n",
    "    \"\"\"\n",
    "    uniprot_dir = data_dir / 'uniprot'\n",
    "    uniprot_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    # Download Swiss-Prot FASTA file\n",
    "    fasta_url = \"https://ftp.uniprot.org/pub/databases/uniprot/current_release/knowledgebase/complete/uniprot_sprot.fasta.gz\"\n",
    "    fasta_path = uniprot_dir / \"uniprot_sprot.fasta.gz\"\n",
    "    \n",
    "    if not fasta_path.exists():\n",
    "        print(\"Downloading Swiss-Prot FASTA file (this may take a while)...\")\n",
    "        urllib.request.urlretrieve(fasta_url, fasta_path)\n",
    "        print(f\"Downloaded to {fasta_path}\")\n",
    "    else:\n",
    "        print(f\"FASTA file already exists at {fasta_path}\")\n",
    "    \n",
    "    # Download UniProtKB annotations (TSV format with rich metadata)\n",
    "    # Broader query to get more proteins with good overlap\n",
    "    annotations_url = (\n",
    "        \"https://rest.uniprot.org/uniprotkb/stream?compressed=true&\"\n",
    "        \"fields=accession%2Creviewed%2Cprotein_name%2Clength%2Csequence%2C\"\n",
    "        \"ec%2Cft_act_site%2Cft_binding%2Ccc_cofactor%2Cft_disulfid%2C\"\n",
    "        \"ft_carbohyd%2Cft_lipid%2Cft_mod_res%2Cft_signal%2Cft_transit%2C\"\n",
    "        \"ft_helix%2Cft_turn%2Cft_strand%2Cft_coiled%2Ccc_domain%2C\"\n",
    "        \"ft_compbias%2Cft_domain%2Cft_motif%2Cft_region%2Cft_zn_fing%2C\"\n",
    "        \"xref_alphafolddb&format=tsv&query=%28reviewed%3Atrue%29+AND+\"\n",
    "        \"%28length%3A%5B50+TO+1022%5D%29\"\n",
    "    )\n",
    "    \n",
    "    annotations_path = uniprot_dir / \"proteins_annotations.tsv.gz\"\n",
    "    \n",
    "    if not annotations_path.exists():\n",
    "        print(\"Downloading UniProt annotations...\")\n",
    "        urllib.request.urlretrieve(annotations_url, annotations_path)\n",
    "        print(f\"Downloaded annotations to {annotations_path}\")\n",
    "    else:\n",
    "        print(f\"Annotations file already exists at {annotations_path}\")\n",
    "    \n",
    "    return fasta_path, annotations_path\n",
    "\n",
    "# Download the data\n",
    "fasta_path, annotations_path = download_uniprot_data(DATA_DIR)\n",
    "\n",
    "print(f\"\\nFASTA file: {fasta_path}\")\n",
    "print(f\"Annotations file: {annotations_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Process and Filter Sequences\n",
    "\n",
    "Create a manageable subset of sequences for analysis while maintaining diversity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing sequences from /home/ec2-user/InterPLM/data/uniprot/uniprot_sprot.fasta.gz...\n",
      "Processed 0 sequences, kept 1\n",
      "Processed 10,000 sequences, kept 9,532\n",
      "Processed 20,000 sequences, kept 18,561\n",
      "Processed 30,000 sequences, kept 28,385\n",
      "Processed 40,000 sequences, kept 37,954\n",
      "\n",
      "Created subset with 40,000 sequences\n",
      "Length range: 50 - 1022\n",
      "Mean length: 344.5\n",
      "Saved to /home/ec2-user/InterPLM/data/uniprot/subset_25k.fasta and /home/ec2-user/InterPLM/data/uniprot/subset_25k.csv\n",
      "\n",
      "=== Sequence Statistics ===\n",
      "count    40000.000000\n",
      "mean       344.486825\n",
      "std        184.688538\n",
      "min         50.000000\n",
      "25%        186.000000\n",
      "50%        330.000000\n",
      "75%        461.000000\n",
      "max       1022.000000\n",
      "Name: length, dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def create_sequence_subset(fasta_path: Path, output_path: Path, \n",
    "                          max_sequences: int = 25000, \n",
    "                          min_length: int = 50, \n",
    "                          max_length: int = 1022):\n",
    "    \"\"\"\n",
    "    Create a filtered subset of sequences for ESM-2 compatibility.\n",
    "    Following InterPLM's recommendations for sequence length limits.\n",
    "    \"\"\"\n",
    "    print(f\"Processing sequences from {fasta_path}...\")\n",
    "    \n",
    "    sequences = []\n",
    "    \n",
    "    with gzip.open(fasta_path, 'rt') as handle:\n",
    "        for i, record in enumerate(SeqIO.parse(handle, \"fasta\")):\n",
    "            if len(sequences) >= max_sequences:\n",
    "                break\n",
    "                \n",
    "            seq_len = len(record.seq)\n",
    "            if min_length <= seq_len <= max_length:\n",
    "                # Extract UniProt ID and description\n",
    "                uniprot_id = record.id.split('|')[1] if '|' in record.id else record.id\n",
    "                description = record.description\n",
    "                \n",
    "                sequences.append({\n",
    "                    'uniprot_id': uniprot_id,\n",
    "                    'sequence': str(record.seq),\n",
    "                    'length': seq_len,\n",
    "                    'description': description\n",
    "                })\n",
    "            \n",
    "            if i % 10000 == 0:\n",
    "                print(f\"Processed {i:,} sequences, kept {len(sequences):,}\")\n",
    "    \n",
    "    # Convert to DataFrame and save\n",
    "    df = pd.DataFrame(sequences)\n",
    "    \n",
    "    # Save as both CSV and FASTA\n",
    "    df.to_csv(output_path.with_suffix('.csv'), index=False)\n",
    "    \n",
    "    # Write FASTA file\n",
    "    with open(output_path, 'w') as f:\n",
    "        for _, row in df.iterrows():\n",
    "            f.write(f\">{row['uniprot_id']}|{row['description']}\\n\")\n",
    "            f.write(f\"{row['sequence']}\\n\")\n",
    "    \n",
    "    print(f\"\\nCreated subset with {len(df):,} sequences\")\n",
    "    print(f\"Length range: {df['length'].min()} - {df['length'].max()}\")\n",
    "    print(f\"Mean length: {df['length'].mean():.1f}\")\n",
    "    print(f\"Saved to {output_path} and {output_path.with_suffix('.csv')}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Create larger subset for better analysis\n",
    "subset_path = DATA_DIR / 'uniprot' / 'subset_25k.fasta'\n",
    "sequences_df = create_sequence_subset(fasta_path, subset_path, max_sequences=40000)\n",
    "\n",
    "# Display basic statistics\n",
    "print(\"\\n=== Sequence Statistics ===\")\n",
    "print(sequences_df['length'].describe())\n",
    "\n",
    "# Plot length distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(sequences_df['length'], bins=50, alpha=0.7, edgecolor='black')\n",
    "plt.xlabel('Sequence Length')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Distribution of Protein Sequence Lengths')\n",
    "plt.axvline(sequences_df['length'].mean(), color='red', linestyle='--', \n",
    "           label=f'Mean: {sequences_df[\"length\"].mean():.1f}')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences_df.to_csv(\"sequences.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Load Models and Extract Features\n",
    "\n",
    "Load the ESM-2 model and pre-trained SAE, then extract features from our protein sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ESM-2 model: facebook/esm2_t33_650M_UR50D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t33_650M_UR50D and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading SAE for esm2-650m layer 24\n",
      "SAE architecture: AutoEncoder(\n",
      "  (encoder): Linear(in_features=1280, out_features=10240, bias=True)\n",
      "  (decoder): Linear(in_features=10240, out_features=1280, bias=False)\n",
      ")\n",
      "Dictionary size: 10240\n"
     ]
    }
   ],
   "source": [
    "# Model configuration\n",
    "model_name = 'facebook/esm2_t33_650M_UR50D'  # Using 650M model for better features\n",
    "plm_model = \"esm2-650m\"\n",
    "plm_layer = 24  # Middle layer often has good interpretable features\n",
    "\n",
    "print(f\"Loading ESM-2 model: {model_name}\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "esm_model = EsmModel.from_pretrained(model_name, output_hidden_states=True).to(device).eval()\n",
    "\n",
    "print(f\"Loading SAE for {plm_model} layer {plm_layer}\")\n",
    "sae = load_sae_from_hf(plm_model=plm_model, plm_layer=plm_layer).to(device).eval()\n",
    "\n",
    "print(f\"SAE architecture: {sae}\")\n",
    "print(f\"Dictionary size: {sae.encoder.out_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ.setdefault(\"PYTORCH_CUDA_ALLOC_CONF\", \"expandable_segments:True,max_split_size_mb:128\")\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "DTYPE  = torch.float16\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "torch.set_float32_matmul_precision(\"high\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t33_650M_UR50D and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "from typing import List, Literal, Tuple\n",
    "\n",
    "# Example: load once at top-level\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/esm2_t33_650M_UR50D\", do_lower_case=False)\n",
    "model     = AutoModel.from_pretrained(\"facebook/esm2_t33_650M_UR50D\", output_hidden_states=True).to(DEVICE)\n",
    "model.eval()\n",
    "@torch.no_grad()\n",
    "def extract_sae_features(hidden_states: torch.Tensor):\n",
    "    \"\"\"\n",
    "    Pass ESM hidden states through the Sparse Autoencoder (SAE).\n",
    "\n",
    "    Args\n",
    "    ----\n",
    "    hidden_states : torch.Tensor\n",
    "        Shape [B, L, d] or [L, d].\n",
    "        - B = batch size (optional if unsqueezed)\n",
    "        - L = sequence length\n",
    "        - d = ESM embedding dimension (e.g., 1280 for esm2_t33_650M)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    sae_features : torch.Tensor\n",
    "        Shape [B, L, F]\n",
    "        Sparse latent features per residue.\n",
    "        F = number of SAE dictionary atoms / features.\n",
    "\n",
    "    recon : torch.Tensor\n",
    "        Shape [B, L, d]\n",
    "        Reconstructed embeddings in token space.\n",
    "\n",
    "    error : torch.Tensor\n",
    "        Shape [B, L, d]\n",
    "        Residual = hidden_states - recon\n",
    "    \"\"\"\n",
    "    if hidden_states.dim() == 2:          # [L, d]\n",
    "        hidden_states = hidden_states.unsqueeze(0)  # → [1, L, d]\n",
    "\n",
    "    # SAE should have encode() and decode() that operate on last dimension\n",
    "    sae_features = sae.encode(hidden_states)     # [B, L, F]\n",
    "    recon        = sae.decode(sae_features)      # [B, L, d]\n",
    "    error        = hidden_states - recon         # [B, L, d]\n",
    "\n",
    "    return sae_features, recon, error\n",
    "\n",
    "def pool_sequence_features(\n",
    "    features: torch.Tensor,   # [B, L, F] or [L, F]\n",
    "    method: str = \"max_mean\",\n",
    "    mask: torch.Tensor = None # optional [B, L] attention mask\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Pool per-residue features to per-sequence vectors.\n",
    "\n",
    "    Args\n",
    "    ----\n",
    "    features : torch.Tensor\n",
    "        Shape [B, L, F] (or [L, F] → will unsqueeze to batch 1).\n",
    "        - B = batch size\n",
    "        - L = sequence length\n",
    "        - F = number of SAE features\n",
    "    method : str\n",
    "        \"max_mean\" → concatenate mean + max → [B, 2F]\n",
    "        \"mean\"     → masked mean → [B, F]\n",
    "        \"max\"      → masked max  → [B, F]\n",
    "    mask : torch.Tensor, optional\n",
    "        Shape [B, L] bool (True = valid residue, False = pad).\n",
    "        If None, assumes all tokens are valid.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pooled : torch.Tensor\n",
    "        Shape depends on method:\n",
    "          - max_mean: [B, 2F]\n",
    "          - mean or max: [B, F]\n",
    "    \"\"\"\n",
    "    if features.dim() == 2:  # [L, F]\n",
    "        features = features.unsqueeze(0)  # [1, L, F]\n",
    "\n",
    "    B, L, F = features.shape\n",
    "    if mask is None:\n",
    "        mask = torch.ones(B, L, dtype=torch.bool, device=features.device)\n",
    "\n",
    "    # apply mask\n",
    "    mask_f = mask.float().unsqueeze(-1)  # [B, L, 1]\n",
    "    feats_masked = features * mask_f\n",
    "\n",
    "    if method == \"mean\":\n",
    "        pooled = feats_masked.sum(1) / mask_f.sum(1).clamp_min(1e-8)\n",
    "        return pooled  # [B, F]\n",
    "\n",
    "    elif method == \"max\":\n",
    "        very_neg = torch.finfo(features.dtype).min\n",
    "        feats_masked = feats_masked.masked_fill(~mask.unsqueeze(-1), very_neg)\n",
    "        return feats_masked.max(1).values  # [B, F]\n",
    "\n",
    "    elif method == \"max_mean\":\n",
    "        mean_pool = feats_masked.sum(1) / mask_f.sum(1).clamp_min(1e-8)  # [B, F]\n",
    "        very_neg = torch.finfo(features.dtype).min\n",
    "        feats_masked = feats_masked.masked_fill(~mask.unsqueeze(-1), very_neg)\n",
    "        max_pool = feats_masked.max(1).values  # [B, F]\n",
    "        return torch.cat([mean_pool, max_pool], dim=-1)  # [B, 2F]\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown pooling method: {method}\")\n",
    "        \n",
    "@torch.no_grad()\n",
    "def extract_esm_features_batch(\n",
    "    sequences: List[str],\n",
    "    layer: Literal[\"last\", \"sum\", \"cat\"] = \"last\",\n",
    "    return_all_layers: bool = False,\n",
    "    device: torch.device = DEVICE,\n",
    "    dtype = torch.float16   # or torch.bfloat16 if you prefer\n",
    ") -> Tuple[torch.Tensor, torch.Tensor, list]:\n",
    "    \"\"\"\n",
    "    Returns batched token representations from ESM.\n",
    "\n",
    "    Args\n",
    "    ----\n",
    "    sequences: list of protein strings (no special tokens)\n",
    "    layer:\n",
    "      - \"last\": use last hidden state only → [B, L, d]\n",
    "      - \"sum\" : sum all layers (including embedding layer) → [B, L, d]\n",
    "      - \"cat\" : concatenate all layers → [B, L, d * (n_layers+1)]  (very big)\n",
    "    return_all_layers: if True, also return python list of all layers [n_layers+1] each [B, L, d]\n",
    "    device, dtype: inference device & autocast dtype\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    token_reps:  [B, L, d] (or [B, L, d_total] for \"cat\")\n",
    "    attn_mask:   [B, L] (bool)\n",
    "    all_layers:  list of [B, L, d] (empty list if return_all_layers=False)\n",
    "    \"\"\"\n",
    "    # tokenize with padding (no truncation for proteins)\n",
    "    batch = tokenizer(\n",
    "        sequences,\n",
    "        return_tensors=\"pt\",\n",
    "        add_special_tokens=False,\n",
    "        padding=True\n",
    "    )\n",
    "    batch = {k: v.to(device) for k, v in batch.items()}\n",
    "    attn_mask = batch[\"attention_mask\"].to(torch.bool)  # [B, L]\n",
    "\n",
    "    with torch.autocast(device_type=\"cuda\", dtype=dtype):\n",
    "        out = model(**batch, output_hidden_states=True, return_dict=True)\n",
    "        # out.hidden_states is a tuple(length = n_layers+1): [embedding, layer1, ..., layerN]\n",
    "        hidden_states = out.hidden_states  # each [B, L, d]\n",
    "\n",
    "        if layer == \"last\":\n",
    "            token_reps = hidden_states[-1]\n",
    "        elif layer == \"sum\":\n",
    "            token_reps = torch.stack(hidden_states, dim=0).sum(0)    # sum over layers → [B, L, d]\n",
    "        elif layer == \"cat\":\n",
    "            token_reps = torch.cat(hidden_states, dim=-1)            # concat → [B, L, d*(n_layers+1)]\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown layer option: {layer}\")\n",
    "\n",
    "    if return_all_layers:\n",
    "        return token_reps, attn_mask, list(hidden_states)\n",
    "    else:\n",
    "        return token_reps, attn_mask, []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, gc\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def _to_cpu_and_free(*tensors):\n",
    "    out = []\n",
    "    for t in tensors:\n",
    "        if t is None:\n",
    "            out.append(None)\n",
    "            continue\n",
    "        out.append(t.detach().to(\"cpu\", non_blocking=True))\n",
    "        del t\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    return out if len(out) > 1 else out[0]\n",
    "\n",
    "def process_sequences_bucketed(\n",
    "    sequences_df: pd.DataFrame,\n",
    "    batch_size: int = 16,\n",
    "    save_every: int = 1000,\n",
    "    cache_name: str = \"sae_features\",\n",
    "    desc: str = \"processing\",\n",
    "    esm_layer: str = \"last\"\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Stable, memory-aware feature extraction:\n",
    "      - buckets by sequence length to reduce padding\n",
    "      - mixed precision + no_grad\n",
    "      - immediate CPU offload of results\n",
    "      - OOM-aware dynamic batch shrinking + resume\n",
    "    Saves pooled per-sequence features and simple stats.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    DATA_DIR.mkdir(exist_ok=True, parents=True)\n",
    "    cache_dir = DATA_DIR / f\"{cache_name}_cache\"\n",
    "    cache_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    # Sort by length → reduces padding waste (memory ~ B * max_len_in_batch)\n",
    "    df = sequences_df.copy()\n",
    "    df[\"L\"] = df[\"sequence\"].str.len()\n",
    "    df = df.sort_values(\"L\").reset_index(drop=True)\n",
    "\n",
    "    results = []\n",
    "    processed = 0\n",
    "    next_save_threshold = save_every\n",
    "\n",
    "    pbar = tqdm(total=len(df), desc=desc, dynamic_ncols=True)\n",
    "\n",
    "    cur_bs = batch_size\n",
    "    i = 0\n",
    "    while i < len(df):\n",
    "        window = df.iloc[i : min(i + cur_bs, len(df))]\n",
    "        seqs = window[\"sequence\"].tolist()\n",
    "        ids  = window[\"uniprot_id\"].tolist()\n",
    "\n",
    "        try:\n",
    "            with torch.no_grad(), torch.autocast(device_type=\"cuda\", dtype=DTYPE):\n",
    "                # 1) ESM token reps (batched): [B, L, d], attn_mask: [B, L]\n",
    "                token_reps, attn_mask, _ = extract_esm_features_batch(\n",
    "                    seqs, layer=esm_layer, return_all_layers=False, device=DEVICE, dtype=DTYPE\n",
    "                )\n",
    "\n",
    "                # 2) SAE: latents [B, L, F], recon [B, L, d], error [B, L, d]\n",
    "                sae_feats, recon, err = extract_sae_features(token_reps)\n",
    "                #sae_feats is basically a set of f features every residue l of sequence b\n",
    "\n",
    "                # 3) Pool over residues to per-sequence vector [B, F] (masked mean)\n",
    "                #    (keep per-residue in a separate path if you need detailed attribution)\n",
    "                pooled = pool_sequence_features(sae_feats, mask=attn_mask, method=\"mean\")  # [B, F]\n",
    "                #same thing here, f sae features for sequence b, this time mean pooled\n",
    "\n",
    "                # Move everything we summarize from to CPU\n",
    "                pooled, sae_feats, err = _to_cpu_and_free(pooled, sae_feats, err)\n",
    "\n",
    "            # Summarize per sequence\n",
    "            for j, uid in enumerate(ids):\n",
    "                # pooled[j] : [F] → per-sequence latent summary\n",
    "                # sae_feats[j]: [L, F] → per-residue latents for sequence j\n",
    "                # err[j]: [L, d] → residuals per residue\n",
    "                \n",
    "                features_vec = pooled[j].numpy()  #Grab all the f pooled features across residue for a given sequence j\n",
    "                max_act      = sae_feats[j].amax().item()             # single max across all residues/features\n",
    "                n_active     = (sae_feats[j] > 0.1).sum().item()      # count of >0.1 activations\n",
    "                recon_mse    = (err[j].pow(2).mean()).item()          # average residual MSE\n",
    "\n",
    "                results.append({\n",
    "                    \"uniprot_id\": uid,\n",
    "                    \"length\": int(len(seqs[j])),\n",
    "                    \"features\": features_vec,         # [F]\n",
    "                    \"max_activation\": max_act,\n",
    "                    \"n_active_features\": n_active,\n",
    "                    \"reconstruction_mse\": recon_mse,\n",
    "                })\n",
    "\n",
    "            processed += len(window)\n",
    "            pbar.update(len(window))\n",
    "            i += len(window)\n",
    "\n",
    "            if processed >= next_save_threshold or processed == len(df):\n",
    "                cache_file = cache_dir / f\"{cache_name}_{processed}.pkl\"\n",
    "                pd.DataFrame(results).to_pickle(cache_file)\n",
    "                print(f\"[checkpoint] saved {processed} → {cache_file}\")\n",
    "                next_save_threshold += save_every\n",
    "\n",
    "        except RuntimeError as e:\n",
    "            if \"CUDA out of memory\" in str(e):\n",
    "                torch.cuda.empty_cache(); gc.collect()\n",
    "                if cur_bs > 1:\n",
    "                    cur_bs = max(1, cur_bs // 2)\n",
    "                    print(f\"[OOM] reducing batch_size → {cur_bs} and retrying the same window\")\n",
    "                    continue\n",
    "                else:\n",
    "                    # last resort: skip a single sequence\n",
    "                    print(f\"[OOM] Skipping {ids[0]} (length={len(seqs[0])})\")\n",
    "                    i += 1\n",
    "                    pbar.update(1)\n",
    "                    continue\n",
    "            else:\n",
    "                print(f\"[ERROR] {ids[0]}: {e}\")\n",
    "                i += 1\n",
    "                pbar.update(1)\n",
    "                continue\n",
    "\n",
    "    pbar.close()\n",
    "    out_df = pd.DataFrame(results)\n",
    "    out_path = DATA_DIR / f\"{cache_name}.pkl\"\n",
    "    out_df.to_pickle(out_path)\n",
    "    print(f\"[done] {len(out_df)} sequences → {out_path}\")\n",
    "    return out_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "extracting:   4%|▍         | 1008/25000 [00:23<09:19, 42.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[checkpoint] saved 1008 → /home/ec2-user/InterPLM/data/sae_features_cache/sae_features_1008.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "extracting:   8%|▊         | 2000/25000 [00:43<06:38, 57.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[checkpoint] saved 2000 → /home/ec2-user/InterPLM/data/sae_features_cache/sae_features_2000.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "extracting:  12%|█▏        | 3008/25000 [01:01<06:36, 55.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[checkpoint] saved 3008 → /home/ec2-user/InterPLM/data/sae_features_cache/sae_features_3008.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "extracting:  16%|█▌        | 4000/25000 [01:19<06:21, 55.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[checkpoint] saved 4000 → /home/ec2-user/InterPLM/data/sae_features_cache/sae_features_4000.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "extracting:  20%|██        | 5008/25000 [01:38<06:18, 52.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[checkpoint] saved 5008 → /home/ec2-user/InterPLM/data/sae_features_cache/sae_features_5008.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "extracting:  24%|██▍       | 6000/25000 [01:57<06:11, 51.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[checkpoint] saved 6000 → /home/ec2-user/InterPLM/data/sae_features_cache/sae_features_6000.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "extracting:  28%|██▊       | 7008/25000 [02:17<06:13, 48.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[checkpoint] saved 7008 → /home/ec2-user/InterPLM/data/sae_features_cache/sae_features_7008.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "extracting:  32%|███▏      | 8000/25000 [02:39<06:08, 46.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[checkpoint] saved 8000 → /home/ec2-user/InterPLM/data/sae_features_cache/sae_features_8000.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "extracting:  36%|███▌      | 9008/25000 [03:01<05:52, 45.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[checkpoint] saved 9008 → /home/ec2-user/InterPLM/data/sae_features_cache/sae_features_9008.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "extracting:  40%|████      | 10000/25000 [03:23<05:37, 44.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[checkpoint] saved 10000 → /home/ec2-user/InterPLM/data/sae_features_cache/sae_features_10000.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "extracting:  44%|████▍     | 11008/25000 [03:46<05:22, 43.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[checkpoint] saved 11008 → /home/ec2-user/InterPLM/data/sae_features_cache/sae_features_11008.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "extracting:  48%|████▊     | 12000/25000 [04:10<05:03, 42.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[checkpoint] saved 12000 → /home/ec2-user/InterPLM/data/sae_features_cache/sae_features_12000.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "extracting:  52%|█████▏    | 13008/25000 [04:35<04:53, 40.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[checkpoint] saved 13008 → /home/ec2-user/InterPLM/data/sae_features_cache/sae_features_13008.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "extracting:  56%|█████▌    | 14000/25000 [04:59<04:27, 41.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[checkpoint] saved 14000 → /home/ec2-user/InterPLM/data/sae_features_cache/sae_features_14000.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "extracting:  60%|██████    | 15008/25000 [05:24<04:09, 40.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[checkpoint] saved 15008 → /home/ec2-user/InterPLM/data/sae_features_cache/sae_features_15008.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "extracting:  64%|██████▍   | 16000/25000 [05:49<03:46, 39.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[checkpoint] saved 16000 → /home/ec2-user/InterPLM/data/sae_features_cache/sae_features_16000.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "extracting:  68%|██████▊   | 17008/25000 [06:17<03:38, 36.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[checkpoint] saved 17008 → /home/ec2-user/InterPLM/data/sae_features_cache/sae_features_17008.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "extracting:  72%|███████▏  | 18000/25000 [06:45<03:21, 34.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[checkpoint] saved 18000 → /home/ec2-user/InterPLM/data/sae_features_cache/sae_features_18000.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "extracting:  76%|███████▌  | 19008/25000 [07:14<02:57, 33.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[checkpoint] saved 19008 → /home/ec2-user/InterPLM/data/sae_features_cache/sae_features_19008.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "extracting:  80%|████████  | 20000/25000 [07:45<02:37, 31.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[checkpoint] saved 20000 → /home/ec2-user/InterPLM/data/sae_features_cache/sae_features_20000.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "extracting:  84%|████████▍ | 21008/25000 [08:18<02:09, 30.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[checkpoint] saved 21008 → /home/ec2-user/InterPLM/data/sae_features_cache/sae_features_21008.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "extracting:  88%|████████▊ | 22000/25000 [08:51<01:42, 29.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[checkpoint] saved 22000 → /home/ec2-user/InterPLM/data/sae_features_cache/sae_features_22000.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "extracting:  92%|█████████▏| 23008/25000 [09:30<01:12, 27.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[checkpoint] saved 23008 → /home/ec2-user/InterPLM/data/sae_features_cache/sae_features_23008.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "extracting:  96%|█████████▌| 24000/25000 [10:08<00:39, 25.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[checkpoint] saved 24000 → /home/ec2-user/InterPLM/data/sae_features_cache/sae_features_24000.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "extracting: 100%|██████████| 25000/25000 [10:53<00:00, 38.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[checkpoint] saved 25000 → /home/ec2-user/InterPLM/data/sae_features_cache/sae_features_25000.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[done] 25000 sequences → /home/ec2-user/InterPLM/data/sae_features.pkl\n"
     ]
    }
   ],
   "source": [
    "features_df = process_sequences_bucketed(\n",
    "    sequences_df,\n",
    "    batch_size=16,        # adjust up/down depending on GPU memory\n",
    "    save_every=1000,      # checkpoint every 1000 seqs\n",
    "    cache_name=\"sae_features\",\n",
    "    desc=\"extracting\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-08 22:45:49,929\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "2025-09-08 22:45:51,326\tINFO worker.py:1951 -- Started a local Ray instance.\n"
     ]
    }
   ],
   "source": [
    "import ray, pandas as pd, os\n",
    "\n",
    "ray.init(ignore_reinit_error=True, num_gpus=8)\n",
    "\n",
    "DATA_DIR = Path(\"esm_sae_results\"); DATA_DIR.mkdir(exist_ok=True)\n",
    "sequences_df.to_pickle(DATA_DIR/\"sequences_df.pkl\")\n",
    "\n",
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "@ray.remote(num_gpus=1)\n",
    "def ray_worker(rank: int, world_size: int, input_path: str, out_name: str,\n",
    "                batch_size: int = 16, save_every:int=1000, esm_layer:str = \"last\"):\n",
    "    os.environ.setdefault(\"PYTORCH_CUDA_ALLOC_CONF\", \"expandable_segments:True,max_split_size_mb:128\")\n",
    "\n",
    "    # detect the assigned GPU id Ray gave us\n",
    "    gpu_ids = os.environ.get(\"CUDA_VISIBLE_DEVICES\", \"0\")\n",
    "    print(f\"[rank {rank}] sees CUDA_VISIBLE_DEVICES={gpu_ids}\")\n",
    "\n",
    "    from transformers import AutoTokenizer, AutoModel\n",
    "    DEVICE = torch.device(\"cuda:0\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"facebook/esm2_t33_650M_UR50D\", do_lower_case=False)\n",
    "    model     = AutoModel.from_pretrained(\"facebook/esm2_t33_650M_UR50D\",\n",
    "                                          output_hidden_states=True).to(DEVICE).eval()\n",
    "    # load SAE here ...\n",
    "    sae = load_sae_from_hf(plm_model=plm_model, plm_layer=plm_layer).to(device).eval()\n",
    "\n",
    "    df = pd.read_pickle(input_path)\n",
    "    shard = df.iloc[rank::world_size].reset_index(drop=True)\n",
    "\n",
    "    cache_name = f\"{out_name}_rank{rank}\"\n",
    "    out_df = process_sequences_bucketed(\n",
    "        sequences_df=shard,\n",
    "        batch_size=batch_size,\n",
    "        save_every=save_every,\n",
    "        cache_name=cache_name,\n",
    "        desc=f\"rank{rank}\",\n",
    "        esm_layer=esm_layer,\n",
    "    )\n",
    "\n",
    "    out_path = Path(\"esm_sae_results\") / f\"{cache_name}.final.pkl\"\n",
    "    out_df.to_pickle(out_path)\n",
    "    return str(out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The remote function __main__.ray_worker is too large (2600 MiB > FUNCTION_SIZE_ERROR_THRESHOLD=95 MiB). Check that its definition is not implicitly capturing a large array or other object in scope. Tip: use ray.put() to put large objects in the Ray object store.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m WORLD_SIZE = \u001b[32m8\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m futs = \u001b[43m[\u001b[49m\u001b[43mray_worker\u001b[49m\u001b[43m.\u001b[49m\u001b[43mremote\u001b[49m\u001b[43m(\u001b[49m\u001b[43mr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mWORLD_SIZE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mDATA_DIR\u001b[49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msequences_df.pkl\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msae_features\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mWORLD_SIZE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m      4\u001b[39m paths = ray.get(futs); paths\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 2\u001b[39m, in \u001b[36m<listcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m      1\u001b[39m WORLD_SIZE = \u001b[32m8\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m futs = [\u001b[43mray_worker\u001b[49m\u001b[43m.\u001b[49m\u001b[43mremote\u001b[49m\u001b[43m(\u001b[49m\u001b[43mr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mWORLD_SIZE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mDATA_DIR\u001b[49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msequences_df.pkl\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msae_features\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(WORLD_SIZE)]\n\u001b[32m      4\u001b[39m paths = ray.get(futs); paths\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/SageMaker/.cs/conda/envs/interplm/lib/python3.11/site-packages/ray/remote_function.py:163\u001b[39m, in \u001b[36mRemoteFunction.__init__.<locals>._remote_proxy\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    161\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(function)\n\u001b[32m    162\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_remote_proxy\u001b[39m(*args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m163\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_remote\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[43m        \u001b[49m\u001b[43mserialized_runtime_env_info\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_serialized_base_runtime_env_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    166\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    167\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_default_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/SageMaker/.cs/conda/envs/interplm/lib/python3.11/site-packages/ray/_private/auto_init_hook.py:22\u001b[39m, in \u001b[36mwrap_auto_init.<locals>.auto_init_wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     19\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(fn)\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mauto_init_wrapper\u001b[39m(*args, **kwargs):\n\u001b[32m     21\u001b[39m     auto_init_ray()\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/SageMaker/.cs/conda/envs/interplm/lib/python3.11/site-packages/ray/util/tracing/tracing_helper.py:310\u001b[39m, in \u001b[36m_tracing_task_invocation.<locals>._invocation_remote_span\u001b[39m\u001b[34m(self, args, kwargs, *_args, **_kwargs)\u001b[39m\n\u001b[32m    308\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    309\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m_ray_trace_ctx\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kwargs\n\u001b[32m--> \u001b[39m\u001b[32m310\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    312\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m_ray_trace_ctx\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kwargs\n\u001b[32m    313\u001b[39m tracer = _opentelemetry.trace.get_tracer(\u001b[34m__name__\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/SageMaker/.cs/conda/envs/interplm/lib/python3.11/site-packages/ray/remote_function.py:372\u001b[39m, in \u001b[36mRemoteFunction._remote\u001b[39m\u001b[34m(self, args, kwargs, serialized_runtime_env_info, **task_options)\u001b[39m\n\u001b[32m    366\u001b[39m     \u001b[38;5;28mself\u001b[39m._pickled_function = pickle_dumps(\n\u001b[32m    367\u001b[39m         \u001b[38;5;28mself\u001b[39m._function,\n\u001b[32m    368\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCould not serialize the function \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m._function_descriptor.repr\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    369\u001b[39m     )\n\u001b[32m    371\u001b[39m     \u001b[38;5;28mself\u001b[39m._last_export_cluster_and_job = worker.current_cluster_and_job\n\u001b[32m--> \u001b[39m\u001b[32m372\u001b[39m     \u001b[43mworker\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfunction_actor_manager\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexport\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    374\u001b[39m kwargs = {} \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m kwargs\n\u001b[32m    375\u001b[39m args = [] \u001b[38;5;28;01mif\u001b[39;00m args \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m args\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/SageMaker/.cs/conda/envs/interplm/lib/python3.11/site-packages/ray/_private/function_manager.py:217\u001b[39m, in \u001b[36mFunctionActorManager.export\u001b[39m\u001b[34m(self, remote_function)\u001b[39m\n\u001b[32m    214\u001b[39m function = remote_function._function\n\u001b[32m    215\u001b[39m pickled_function = remote_function._pickled_function\n\u001b[32m--> \u001b[39m\u001b[32m217\u001b[39m \u001b[43mcheck_oversized_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    218\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpickled_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[43m    \u001b[49m\u001b[43mremote_function\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_function_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    220\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mremote function\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    221\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_worker\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    222\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    223\u001b[39m key = make_function_table_key(\n\u001b[32m    224\u001b[39m     \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mRemoteFunction\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    225\u001b[39m     \u001b[38;5;28mself\u001b[39m._worker.current_job_id,\n\u001b[32m    226\u001b[39m     remote_function._function_descriptor.function_id.binary(),\n\u001b[32m    227\u001b[39m )\n\u001b[32m    228\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._worker.gcs_client.internal_kv_exists(key, KV_NAMESPACE_FUNCTION_TABLE):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/SageMaker/.cs/conda/envs/interplm/lib/python3.11/site-packages/ray/_private/utils.py:607\u001b[39m, in \u001b[36mcheck_oversized_function\u001b[39m\u001b[34m(pickled, name, obj_type, worker)\u001b[39m\n\u001b[32m    595\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    596\u001b[39m     error = (\n\u001b[32m    597\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThe \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m is too large (\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m MiB > FUNCTION_SIZE_ERROR_THRESHOLD=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    598\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m MiB). Check that its definition is not implicitly capturing a \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    605\u001b[39m         ray_constants.FUNCTION_SIZE_ERROR_THRESHOLD // (\u001b[32m1024\u001b[39m * \u001b[32m1024\u001b[39m),\n\u001b[32m    606\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m607\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(error)\n",
      "\u001b[31mValueError\u001b[39m: The remote function __main__.ray_worker is too large (2600 MiB > FUNCTION_SIZE_ERROR_THRESHOLD=95 MiB). Check that its definition is not implicitly capturing a large array or other object in scope. Tip: use ray.put() to put large objects in the Ray object store."
     ]
    }
   ],
   "source": [
    "WORLD_SIZE = 8\n",
    "futs = [ray_worker.remote(r, WORLD_SIZE, str(DATA_DIR / \"sequences_df.pkl\"), \"sae_features\")\n",
    "        for r in range(WORLD_SIZE)]\n",
    "paths = ray.get(futs); paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Merge\n",
    "import glob, pandas as pd\n",
    "parts = [pd.read_pickle(p) for p in sorted(glob.glob(\"esm_sae_results/sae_features_rank*.final.pkl\"))]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Process Full Dataset and Extract Features\n",
    "\n",
    "Extract SAE features for all sequences in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing first 25000 sequences for analysis...\n",
      "Processing 25000 sequences...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "processing:   8%|▊         | 118/1563 [01:28<21:16,  1.13it/s]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "def process_sequences_batch(sequences_df: pd.DataFrame, \n",
    "                           batch_size: int = 32,\n",
    "                           save_every: int = 500):\n",
    "    \"\"\"\n",
    "    Process sequences in batches and extract SAE features.\n",
    "    Save intermediate results to avoid losing progress.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    cache_dir = DATA_DIR / 'sae_features_cache'\n",
    "    cache_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    print(f\"Processing {len(sequences_df)} sequences...\")\n",
    "    \n",
    "    for i in tqdm(range(0, len(sequences_df), batch_size), desc=\"processing\"):\n",
    "        batch = sequences_df.iloc[i:i+batch_size]\n",
    "        \n",
    "        for _, row in batch.iterrows():\n",
    "            try:\n",
    "                seq = row['sequence']\n",
    "                uniprot_id = row['uniprot_id']\n",
    "                \n",
    "                # Extract features\n",
    "                hidden_states = extract_esm_features(seq)\n",
    "                sae_features, _, error = extract_sae_features(hidden_states)\n",
    "                \n",
    "                # Pool to sequence level\n",
    "                pooled_features = pool_sequence_features(sae_features)\n",
    "                \n",
    "                # Store results\n",
    "                result = {\n",
    "                    'uniprot_id': uniprot_id,\n",
    "                    'length': len(seq),\n",
    "                    'features': pooled_features.cpu().numpy(),\n",
    "                    'max_activation': sae_features.max().item(),\n",
    "                    'n_active_features': (sae_features > 0.1).sum().item(),\n",
    "                    'reconstruction_mse': torch.mean(error**2).item()\n",
    "                }\n",
    "                results.append(result)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {row['uniprot_id']}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        # Progress update\n",
    "        processed = min(i + batch_size, len(sequences_df))\n",
    "        # print(f\"Processed {processed}/{len(sequences_df)} sequences ({100*processed/len(sequences_df):.1f}%)\")\n",
    "        \n",
    "        # Save intermediate results\n",
    "        if processed % save_every == 0 or processed == len(sequences_df):\n",
    "            cache_file = cache_dir / f'features_batch_{processed}.pkl'\n",
    "            pd.DataFrame(results).to_pickle(cache_file)\n",
    "            print(f\"Saved intermediate results to {cache_file}\")\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "# Process larger subset for meaningful analysis\n",
    "subset_size = len(sequences_df)  # Process first 3000 sequences\n",
    "print(f\"Processing first {subset_size} sequences for analysis...\")\n",
    "\n",
    "features_df = process_sequences_batch(sequences_df.head(subset_size), batch_size=16)\n",
    "\n",
    "print(f\"\\nExtracted features for {len(features_df)} sequences\")\n",
    "print(f\"Feature dimensions: {features_df['features'].iloc[0].shape}\")\n",
    "\n",
    "# Save complete results\n",
    "features_path = DATA_DIR / 'sae_features.pkl'\n",
    "features_df.to_pickle(features_path)\n",
    "print(f\"Saved all features to {features_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Create Rich Protein Annotations\n",
    "\n",
    "Extract and process UniProt annotations to create binary concept labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_uniprot_annotations(annotations_path: Path):\n",
    "    \"\"\"\n",
    "    Parse UniProt annotations and create binary concept labels.\n",
    "    \"\"\"\n",
    "    print(f\"Loading annotations from {annotations_path}...\")\n",
    "    \n",
    "    # Read the TSV file\n",
    "    annotations_df = pd.read_csv(annotations_path, sep='\\t', compression='gzip')\n",
    "    \n",
    "    print(f\"Loaded {len(annotations_df)} protein annotations\")\n",
    "    print(f\"Available columns: {list(annotations_df.columns)}\")\n",
    "    \n",
    "    # Filter annotations to match our sequence subset\n",
    "    print(f\"\\\\nFiltering annotations to match processed sequences...\")\n",
    "    processed_ids = set(sequences_df['uniprot_id'])\n",
    "    annotations_df = annotations_df[annotations_df['Entry'].isin(processed_ids)]\n",
    "    print(f\"After filtering: {len(annotations_df)} annotations remain\")\n",
    "    \n",
    "    if len(annotations_df) == 0:\n",
    "        print(\"ERROR: No matching annotations found!\")\n",
    "        print(\"This suggests the UniProt IDs don't match between FASTA and annotations.\")\n",
    "        print(\"Checking a few examples...\")\n",
    "        print(f\"FASTA IDs (first 5): {list(sequences_df['uniprot_id'].head())}\")\n",
    "        # Try loading a few annotation entries to see format\n",
    "        temp_df = pd.read_csv(annotations_path, sep='\\\\t', compression='gzip', nrows=5)\n",
    "        print(f\"Annotation IDs (first 5): {list(temp_df['Entry'])}\")\n",
    "        return None, None\n",
    "    \n",
    "    # Create binary concept labels\n",
    "    concepts = {}\n",
    "    \n",
    "    # Structural features\n",
    "    concepts['has_signal_peptide'] = ~annotations_df['Signal peptide'].isna()\n",
    "    concepts['has_disulfide_bond'] = ~annotations_df['Disulfide bond'].isna()\n",
    "    concepts['has_helix'] = ~annotations_df['Helix'].isna()\n",
    "    concepts['has_strand'] = ~annotations_df['Beta strand'].isna()\n",
    "    concepts['has_turn'] = ~annotations_df['Turn'].isna()\n",
    "    concepts['has_coiled_coil'] = ~annotations_df['Coiled coil'].isna()\n",
    "    \n",
    "    # Post-translational modifications\n",
    "    concepts['has_glycosylation'] = ~annotations_df['Glycosylation'].isna()\n",
    "    concepts['has_lipidation'] = ~annotations_df['Lipidation'].isna()\n",
    "    concepts['has_modification'] = ~annotations_df['Modified residue'].isna()\n",
    "    \n",
    "    # Functional features\n",
    "    concepts['has_active_site'] = ~annotations_df['Active site'].isna()\n",
    "    concepts['has_binding_site'] = ~annotations_df['Binding site'].isna()\n",
    "    concepts['has_enzyme_activity'] = ~annotations_df['EC number'].isna()\n",
    "    \n",
    "    # Sequence features\n",
    "    concepts['has_domain'] = ~annotations_df['Domain [FT]'].isna()\n",
    "    concepts['has_motif'] = ~annotations_df['Motif'].isna()\n",
    "    concepts['has_region'] = ~annotations_df['Region'].isna()\n",
    "    concepts['has_zinc_finger'] = ~annotations_df['Zinc finger'].isna()\n",
    "    concepts['has_compositional_bias'] = ~annotations_df['Compositional bias'].isna()\n",
    "    \n",
    "    # Length-based categories\n",
    "    concepts['short_protein'] = annotations_df['Length'] < 150\n",
    "    concepts['medium_protein'] = (annotations_df['Length'] >= 150) & (annotations_df['Length'] < 400)\n",
    "    concepts['long_protein'] = annotations_df['Length'] >= 400\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    concepts_df = pd.DataFrame(concepts, index=annotations_df['Entry'])\n",
    "    \n",
    "    # Add sequence information\n",
    "    concepts_df['sequence'] = annotations_df['Sequence'].values\n",
    "    concepts_df['length'] = annotations_df['Length'].values\n",
    "    concepts_df['protein_name'] = annotations_df['Protein names'].values\n",
    "    \n",
    "    return concepts_df, annotations_df\n",
    "\n",
    "# Parse annotations\n",
    "concepts_df, raw_annotations = parse_uniprot_annotations(annotations_path)\n",
    "\n",
    "if concepts_df is not None:\n",
    "    print(f\"\\\\nCreated {len(concepts_df)} concept annotations\")\n",
    "    print(f\"Available concepts: {[col for col in concepts_df.columns if col not in ['sequence', 'length', 'protein_name']]}\")\n",
    "    \n",
    "    # Show concept statistics\n",
    "    concept_cols = [col for col in concepts_df.columns if col not in ['sequence', 'length', 'protein_name']]\n",
    "    concept_stats = concepts_df[concept_cols].sum().sort_values(ascending=False)\n",
    "    \n",
    "    print(\"\\\\n=== Concept Statistics ===\")\n",
    "    for concept, count in concept_stats.head(15).items():\n",
    "        pct = 100 * count / len(concepts_df)\n",
    "        print(f\"{concept:25s}: {count:5d} ({pct:5.1f}%)\")\n",
    "    \n",
    "    # Visualize concept distribution\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    concept_stats.head(15).plot(kind='barh')\n",
    "    plt.xlabel('Number of Proteins')\n",
    "    plt.title('Distribution of Protein Concepts')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Failed to parse annotations - please check the data sources.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Match Features with Annotations\n",
    "\n",
    "Align the extracted SAE features with the protein annotations for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match features with concepts by UniProt ID\n",
    "feature_ids = set(features_df['uniprot_id'])\n",
    "concept_ids = set(concepts_df.index)\n",
    "common_ids = feature_ids.intersection(concept_ids)\n",
    "\n",
    "print(f\"Features extracted for: {len(feature_ids)} proteins\")\n",
    "print(f\"Concepts available for: {len(concept_ids)} proteins\")\n",
    "print(f\"Common proteins: {len(common_ids)} proteins\")\n",
    "\n",
    "if len(common_ids) < 500:\n",
    "    print(\"\\nWarning: Overlap between features and concepts could be higher.\")\n",
    "    print(f\"Current overlap: {len(common_ids)} proteins\")\n",
    "    if len(common_ids) < 100:\n",
    "        print(\"Very low overlap - this might limit analysis quality.\")\n",
    "else:\n",
    "    print(f\"\\nGood overlap: {len(common_ids)} proteins for analysis\")\n",
    "\n",
    "# Create matched dataset (convert set to list for pandas indexing)\n",
    "matched_features = features_df[features_df['uniprot_id'].isin(common_ids)].set_index('uniprot_id')\n",
    "matched_concepts = concepts_df.loc[list(common_ids)]\n",
    "\n",
    "# Align the data\n",
    "aligned_data = matched_features.join(matched_concepts, how='inner')\n",
    "\n",
    "print(f\"\\nAligned dataset: {len(aligned_data)} proteins\")\n",
    "print(f\"Feature dimension: {aligned_data['features'].iloc[0].shape[0]}\")\n",
    "\n",
    "# Create feature matrix\n",
    "X = np.vstack(aligned_data['features'].values)\n",
    "feature_dim = X.shape[1] // 2  # Half are mean, half are max pooled\n",
    "\n",
    "# Split into mean and max features (following original notebook)\n",
    "X_mean = X[:, :feature_dim]\n",
    "X_max = X[:, feature_dim:]\n",
    "\n",
    "print(f\"Feature matrix shape: {X.shape}\")\n",
    "print(f\"Mean features: {X_mean.shape}, Max features: {X_max.shape}\")\n",
    "\n",
    "# Get concept labels\n",
    "concept_cols = [col for col in aligned_data.columns \n",
    "                if col not in ['features', 'length', 'max_activation', 'n_active_features', \n",
    "                               'reconstruction_mse', 'sequence', 'protein_name']]\n",
    "Y = aligned_data[concept_cols].astype(int)\n",
    "\n",
    "print(f\"\\nConcept matrix shape: {Y.shape}\")\n",
    "print(f\"Available concepts for analysis: {len(concept_cols)}\")\n",
    "\n",
    "# Show concept statistics for the aligned dataset\n",
    "print(\"\\n=== Concept Statistics (Aligned Data) ===\")\n",
    "concept_stats_aligned = Y.sum().sort_values(ascending=False)\n",
    "for concept, count in concept_stats_aligned.head(15).items():\n",
    "    pct = 100 * count / len(Y)\n",
    "    print(f\"{concept:25s}: {count:5d} ({pct:5.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. SAE Feature Mining and Analysis\n",
    "\n",
    "Analyze which SAE features are associated with different protein concepts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_feature_concept_associations(X_features: np.ndarray, \n",
    "                                        Y_concepts: pd.DataFrame,\n",
    "                                        min_concept_instances: int = 5):\n",
    "    \"\"\"\n",
    "    Compute associations between SAE features and protein concepts using AUC.\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    n_features = X_features.shape[1]\n",
    "    \n",
    "    print(f\"Computing associations for {n_features} features and {len(Y_concepts.columns)} concepts...\")\n",
    "    \n",
    "    for concept in Y_concepts.columns:\n",
    "        y = Y_concepts[concept].values\n",
    "        \n",
    "        # Skip concepts with too few positive examples\n",
    "        if y.sum() < min_concept_instances or (len(y) - y.sum()) < min_concept_instances:\n",
    "            print(f\"  Skipping {concept}: only {y.sum()}/{len(y)} positive examples (need at least {min_concept_instances})\")\n",
    "            continue\n",
    "            \n",
    "        print(f\"  Processing {concept}: {y.sum()}/{len(y)} positive examples\")\n",
    "        \n",
    "        aucs = []\n",
    "        for feature_idx in range(n_features):\n",
    "            feature_values = X_features[:, feature_idx]\n",
    "            \n",
    "            # Skip features with no variation\n",
    "            if len(np.unique(feature_values)) < 2:\n",
    "                aucs.append(0.5)\n",
    "                continue\n",
    "                \n",
    "            try:\n",
    "                auc = roc_auc_score(y, feature_values)\n",
    "                aucs.append(auc)\n",
    "            except ValueError:\n",
    "                aucs.append(0.5)\n",
    "        \n",
    "        # Find top features for this concept\n",
    "        aucs = np.array(aucs)\n",
    "        top_indices = np.argsort(np.abs(aucs - 0.5))[::-1][:20]  # Top 20 by deviation from 0.5\n",
    "        \n",
    "        results[concept] = {\n",
    "            'aucs': aucs,\n",
    "            'top_features': [(int(idx), aucs[idx]) for idx in top_indices],\n",
    "            'n_positive': int(y.sum()),\n",
    "            'n_total': len(y)\n",
    "        }\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Only proceed if we have valid concept data\n",
    "if concepts_df is not None and len(aligned_data) > 0:\n",
    "    # Compute associations using mean-pooled features\n",
    "    associations = compute_feature_concept_associations(X_mean, Y, min_concept_instances=3)\n",
    "    \n",
    "    print(f\"\\\\n=== Feature-Concept Associations ===\")\n",
    "    print(f\"Analyzed {len(associations)} concepts\")\n",
    "    \n",
    "    # Display top associations for each concept\n",
    "    for concept, data in associations.items():\n",
    "        top_features = data['top_features'][:5]\n",
    "        print(f\"\\\\n{concept} ({data['n_positive']}/{data['n_total']} examples):\")\n",
    "        for feature_idx, auc in top_features:\n",
    "            print(f\"  Feature {feature_idx:4d}: AUC = {auc:.3f}\")\n",
    "else:\n",
    "    print(\"Cannot compute associations - missing concept data or aligned dataset.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Visualize Feature Patterns\n",
    "\n",
    "Create visualizations to understand what the SAE features have learned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_top_features_heatmap(associations: dict, X_features: np.ndarray, Y_concepts: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Create a heatmap showing the top features for each concept.\n",
    "    \"\"\"\n",
    "    # Collect top features across all concepts\n",
    "    all_top_features = set()\n",
    "    for concept_data in associations.values():\n",
    "        top_features = [f[0] for f in concept_data['top_features'][:10]]\n",
    "        all_top_features.update(top_features)\n",
    "    \n",
    "    all_top_features = sorted(list(all_top_features))\n",
    "    \n",
    "    # Create AUC matrix\n",
    "    auc_matrix = np.zeros((len(associations), len(all_top_features)))\n",
    "    concept_names = list(associations.keys())\n",
    "    \n",
    "    for i, concept in enumerate(concept_names):\n",
    "        aucs = associations[concept]['aucs']\n",
    "        for j, feature_idx in enumerate(all_top_features):\n",
    "            auc_matrix[i, j] = aucs[feature_idx]\n",
    "    \n",
    "    # Plot heatmap\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    sns.heatmap(auc_matrix, \n",
    "                xticklabels=[f\"F{f}\" for f in all_top_features],\n",
    "                yticklabels=concept_names,\n",
    "                cmap='RdBu_r', center=0.5, \n",
    "                cbar_kws={'label': 'AUC Score'})\n",
    "    plt.title('Feature-Concept Association Heatmap')\n",
    "    plt.xlabel('SAE Features')\n",
    "    plt.ylabel('Protein Concepts')\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return auc_matrix, concept_names, all_top_features\n",
    "\n",
    "def plot_feature_distributions(feature_idx: int, concept: str, \n",
    "                              X_features: np.ndarray, Y_concepts: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Plot the distribution of a specific feature for positive vs negative examples of a concept.\n",
    "    \"\"\"\n",
    "    y = Y_concepts[concept].values\n",
    "    feature_values = X_features[:, feature_idx]\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # Plot distributions\n",
    "    plt.hist(feature_values[y == 0], bins=30, alpha=0.7, label=f'Negative ({(y==0).sum()})', \n",
    "             density=True, color='blue')\n",
    "    plt.hist(feature_values[y == 1], bins=30, alpha=0.7, label=f'Positive ({(y==1).sum()})', \n",
    "             density=True, color='red')\n",
    "    \n",
    "    plt.xlabel(f'Feature {feature_idx} Activation')\n",
    "    plt.ylabel('Density')\n",
    "    plt.title(f'Feature {feature_idx} Distribution for {concept}')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add AUC score\n",
    "    auc = roc_auc_score(y, feature_values)\n",
    "    plt.text(0.05, 0.95, f'AUC = {auc:.3f}', transform=plt.gca().transAxes, \n",
    "             bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Only create visualizations if we have associations\n",
    "if 'associations' in locals() and len(associations) > 0:\n",
    "    # Create heatmap\n",
    "    auc_matrix, concept_names, top_features = plot_top_features_heatmap(associations, X_mean, Y)\n",
    "    \n",
    "    # Plot distributions for a few interesting feature-concept pairs\n",
    "    print(\"\\\\n=== Feature Distribution Examples ===\")\n",
    "    \n",
    "    # Find the most discriminative feature-concept pairs\n",
    "    best_pairs = []\n",
    "    for i, concept in enumerate(concept_names):\n",
    "        for j, feature_idx in enumerate(top_features):\n",
    "            auc = auc_matrix[i, j]\n",
    "            if abs(auc - 0.5) > 0.2:  # Strong association (lowered threshold)\n",
    "                best_pairs.append((feature_idx, concept, auc))\n",
    "    \n",
    "    best_pairs.sort(key=lambda x: abs(x[2] - 0.5), reverse=True)\n",
    "    \n",
    "    # Plot top 3 most discriminative pairs\n",
    "    if len(best_pairs) > 0:\n",
    "        for feature_idx, concept, auc in best_pairs[:3]:\n",
    "            print(f\"\\\\nPlotting Feature {feature_idx} vs {concept} (AUC = {auc:.3f})\")\n",
    "            plot_feature_distributions(feature_idx, concept, X_mean, Y)\n",
    "    else:\n",
    "        print(\"No strongly discriminative feature-concept pairs found (AUC deviation > 0.2)\")\n",
    "else:\n",
    "    print(\"Skipping visualizations - no associations computed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Sequence-Level Analysis\n",
    "\n",
    "Examine individual sequences to understand how features activate across protein regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_sequence_features(uniprot_id: str, top_k_features: int = 5):\n",
    "    \"\"\"\n",
    "    Analyze feature activations for a specific protein sequence.\n",
    "    \"\"\"\n",
    "    # Get sequence data\n",
    "    seq_data = aligned_data.loc[uniprot_id]\n",
    "    sequence = seq_data['sequence']\n",
    "    \n",
    "    print(f\"\\n=== Analysis for {uniprot_id} ===\")\n",
    "    print(f\"Protein name: {seq_data['protein_name']}\")\n",
    "    print(f\"Length: {len(sequence)} residues\")\n",
    "    \n",
    "    # Show active concepts\n",
    "    active_concepts = [col for col in concept_cols if seq_data[col] == 1]\n",
    "    print(f\"Active concepts: {', '.join(active_concepts) if active_concepts else 'None'}\")\n",
    "    \n",
    "    # Extract per-residue features\n",
    "    hidden_states = extract_esm_features(sequence)\n",
    "    sae_features, _, _ = extract_sae_features(hidden_states)\n",
    "    \n",
    "    # Find top-activating features\n",
    "    mean_activations = sae_features.mean(0)\n",
    "    top_features_idx = torch.topk(mean_activations, top_k_features).indices\n",
    "    \n",
    "    print(f\"\\nTop {top_k_features} features by mean activation:\")\n",
    "    for i, feature_idx in enumerate(top_features_idx):\n",
    "        mean_act = mean_activations[feature_idx].item()\n",
    "        max_act = sae_features[:, feature_idx].max().item()\n",
    "        print(f\"  {i+1}. Feature {feature_idx:4d}: mean={mean_act:.3f}, max={max_act:.3f}\")\n",
    "    \n",
    "    # Plot feature activations along sequence\n",
    "    fig, axes = plt.subplots(top_k_features, 1, figsize=(12, 2*top_k_features))\n",
    "    if top_k_features == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    for i, feature_idx in enumerate(top_features_idx):\n",
    "        activations = sae_features[:, feature_idx].cpu().numpy()\n",
    "        \n",
    "        axes[i].plot(activations, linewidth=2)\n",
    "        axes[i].set_ylabel(f'Feature {feature_idx}')\n",
    "        axes[i].set_title(f'Feature {feature_idx} Activation (mean={mean_activations[feature_idx]:.3f})')\n",
    "        axes[i].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Highlight high-activation regions\n",
    "        threshold = activations.mean() + 2 * activations.std()\n",
    "        high_regions = activations > threshold\n",
    "        if high_regions.any():\n",
    "            axes[i].fill_between(range(len(activations)), 0, activations, \n",
    "                               where=high_regions, alpha=0.3, color='red')\n",
    "    \n",
    "    axes[-1].set_xlabel('Residue Position')\n",
    "    plt.suptitle(f'SAE Feature Activations: {uniprot_id}')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return sae_features, top_features_idx\n",
    "\n",
    "# Analyze a few interesting examples\n",
    "print(\"=== Sequence-Level Feature Analysis ===\")\n",
    "\n",
    "# Find some proteins with different concept patterns\n",
    "examples = []\n",
    "\n",
    "# Get an example with signal peptide\n",
    "if 'has_signal_peptide' in Y.columns:\n",
    "    signal_proteins = Y[Y['has_signal_peptide'] == 1].index\n",
    "    if len(signal_proteins) > 0:\n",
    "        examples.append(signal_proteins[0])\n",
    "\n",
    "# Get an example with enzyme activity\n",
    "if 'has_enzyme_activity' in Y.columns:\n",
    "    enzyme_proteins = Y[Y['has_enzyme_activity'] == 1].index\n",
    "    if len(enzyme_proteins) > 0:\n",
    "        examples.append(enzyme_proteins[0])\n",
    "\n",
    "# Get a structural protein example\n",
    "if 'has_domain' in Y.columns:\n",
    "    domain_proteins = Y[Y['has_domain'] == 1].index\n",
    "    if len(domain_proteins) > 0:\n",
    "        examples.append(domain_proteins[0])\n",
    "\n",
    "# Remove duplicates and limit to 3 examples\n",
    "examples = list(set(examples))[:3]\n",
    "\n",
    "for example_id in examples:\n",
    "    try:\n",
    "        analyze_sequence_features(example_id)\n",
    "    except Exception as e:\n",
    "        print(f\"Error analyzing {example_id}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Feature Interpretation and Biological Insights\n",
    "\n",
    "Summarize findings and provide biological interpretation of discovered features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_feature_analysis(associations: dict, min_auc_deviation: float = 0.2):\n",
    "    \"\"\"\n",
    "    Summarize the key findings from feature-concept associations.\n",
    "    \"\"\"\n",
    "    print(\"=== SAE Feature Analysis Summary ===\")\n",
    "    print(f\"\\nAnalyzed {len(associations)} protein concepts\")\n",
    "    \n",
    "    # Count strong associations\n",
    "    strong_associations = []\n",
    "    all_features = set()\n",
    "    \n",
    "    for concept, data in associations.items():\n",
    "        for feature_idx, auc in data['top_features']:\n",
    "            if abs(auc - 0.5) > min_auc_deviation:\n",
    "                strong_associations.append((concept, feature_idx, auc))\n",
    "                all_features.add(feature_idx)\n",
    "    \n",
    "    print(f\"Found {len(strong_associations)} strong feature-concept associations\")\n",
    "    print(f\"Involving {len(all_features)} distinct SAE features\")\n",
    "    \n",
    "    # Group by concept type\n",
    "    structural_concepts = []\n",
    "    functional_concepts = []\n",
    "    modification_concepts = []\n",
    "    \n",
    "    for concept, feature_idx, auc in strong_associations:\n",
    "        if any(keyword in concept.lower() for keyword in ['helix', 'strand', 'coil', 'domain', 'structure']):\n",
    "            structural_concepts.append((concept, feature_idx, auc))\n",
    "        elif any(keyword in concept.lower() for keyword in ['enzyme', 'binding', 'active', 'function']):\n",
    "            functional_concepts.append((concept, feature_idx, auc))\n",
    "        elif any(keyword in concept.lower() for keyword in ['glyco', 'lipid', 'modification', 'signal']):\n",
    "            modification_concepts.append((concept, feature_idx, auc))\n",
    "    \n",
    "    print(f\"\\n=== Associations by Category ===\")\n",
    "    print(f\"Structural features: {len(structural_concepts)}\")\n",
    "    print(f\"Functional features: {len(functional_concepts)}\")\n",
    "    print(f\"Modification features: {len(modification_concepts)}\")\n",
    "    \n",
    "    # Display top associations in each category\n",
    "    categories = [\n",
    "        (\"Structural\", structural_concepts),\n",
    "        (\"Functional\", functional_concepts),\n",
    "        (\"Modification\", modification_concepts)\n",
    "    ]\n",
    "    \n",
    "    for category_name, concepts in categories:\n",
    "        if concepts:\n",
    "            print(f\"\\n--- {category_name} Features ---\")\n",
    "            # Sort by AUC deviation from 0.5\n",
    "            concepts.sort(key=lambda x: abs(x[2] - 0.5), reverse=True)\n",
    "            for i, (concept, feature_idx, auc) in enumerate(concepts[:5]):\n",
    "                direction = \"activates for\" if auc > 0.5 else \"suppresses for\"\n",
    "                print(f\"  {i+1}. Feature {feature_idx:4d} {direction} {concept} (AUC={auc:.3f})\")\n",
    "    \n",
    "    return strong_associations, all_features\n",
    "\n",
    "def create_feature_summary_table(associations: dict, aligned_data: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Create a summary table of the most important features.\n",
    "    \"\"\"\n",
    "    # Collect all feature scores\n",
    "    feature_scores = defaultdict(list)\n",
    "    \n",
    "    for concept, data in associations.items():\n",
    "        for feature_idx, auc in data['top_features'][:10]:\n",
    "            feature_scores[feature_idx].append({\n",
    "                'concept': concept,\n",
    "                'auc': auc,\n",
    "                'deviation': abs(auc - 0.5)\n",
    "            })\n",
    "    \n",
    "    # Summarize each feature\n",
    "    feature_summary = []\n",
    "    \n",
    "    for feature_idx, scores in feature_scores.items():\n",
    "        scores.sort(key=lambda x: x['deviation'], reverse=True)\n",
    "        \n",
    "        # Get top associated concepts\n",
    "        top_concepts = scores[:3]\n",
    "        max_deviation = max(score['deviation'] for score in scores)\n",
    "        \n",
    "        # Count how often this feature is active\n",
    "        feature_activations = X_mean[:, feature_idx]\n",
    "        n_active = (feature_activations > 0.1).sum()\n",
    "        mean_activation = feature_activations.mean()\n",
    "        \n",
    "        feature_summary.append({\n",
    "            'feature_idx': feature_idx,\n",
    "            'max_auc_deviation': max_deviation,\n",
    "            'n_strong_concepts': len([s for s in scores if s['deviation'] > 0.2]),\n",
    "            'top_concept': top_concepts[0]['concept'] if top_concepts else 'None',\n",
    "            'top_auc': top_concepts[0]['auc'] if top_concepts else 0.5,\n",
    "            'n_active_proteins': n_active,\n",
    "            'activation_rate': n_active / len(feature_activations),\n",
    "            'mean_activation': mean_activation\n",
    "        })\n",
    "    \n",
    "    # Convert to DataFrame and sort\n",
    "    summary_df = pd.DataFrame(feature_summary)\n",
    "    summary_df = summary_df.sort_values('max_auc_deviation', ascending=False)\n",
    "    \n",
    "    return summary_df\n",
    "\n",
    "# Generate summary\n",
    "strong_associations, important_features = summarize_feature_analysis(associations)\n",
    "\n",
    "# Create detailed feature table\n",
    "feature_summary_df = create_feature_summary_table(associations, aligned_data)\n",
    "\n",
    "print(f\"\\n=== Top 10 Most Interpretable SAE Features ===\")\n",
    "display_cols = ['feature_idx', 'max_auc_deviation', 'n_strong_concepts', 'top_concept', 'top_auc', \n",
    "                'activation_rate', 'mean_activation']\n",
    "print(feature_summary_df[display_cols].head(10).to_string(index=False, float_format='%.3f'))\n",
    "\n",
    "# Save results\n",
    "results_dir = DATA_DIR / 'analysis_results'\n",
    "results_dir.mkdir(exist_ok=True)\n",
    "\n",
    "feature_summary_df.to_csv(results_dir / 'sae_feature_summary.csv', index=False)\n",
    "pd.DataFrame(strong_associations, columns=['concept', 'feature_idx', 'auc']).to_csv(\n",
    "    results_dir / 'strong_associations.csv', index=False)\n",
    "\n",
    "print(f\"\\nResults saved to {results_dir}/\")\n",
    "print(f\"- sae_feature_summary.csv: Summary of all features\")\n",
    "print(f\"- strong_associations.csv: All strong feature-concept associations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Comparison with Original Small Dataset\n",
    "\n",
    "Compare findings with the original small test dataset to see improvements from using larger data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and compare with original test sequences from the small notebook\n",
    "original_seqs = {\n",
    "    \"Ab_H\": \"EVQLVESGGGLVQPGGSLRLSCAASGFTFSSYAMHWVRQAPGKGLEWVSYISSGSSSYIYYADSVKGRFTISRDNSKNTLYLQMNSLRAEDTAVYYCARGLGGFGDYWGQGTLVTVSS\",\n",
    "    \"Ab_L\": \"DIQMTQSPSSLSASVGDRVTITCRASQGISNYLAWYQQKPGKAPKLLIYDASTRATGIPDRFSGSGSGTDFTLTISSVQAEDLAVYYCQQYNTYPFTFGQGTKVEIK\",\n",
    "    \"Collagen_like\": \"MGPPGPPGPPGPPGPPGPPGPP\",\n",
    "    \"His_rich\": \"MKKRHHHHHHGSGSGSGHHHHEE\",\n",
    "    \"NGlyc\": \"MATRNATSNEKSTNVTQLLNNST\",\n",
    "    \"CysPair\": \"MAGRCCGGTTCCGGAAACCXXC\"\n",
    "}\n",
    "\n",
    "print(\"=== Comparison with Original Test Sequences ===\")\n",
    "print(\"\\nProcessing original test sequences with trained features...\")\n",
    "\n",
    "original_features = {}\n",
    "for name, seq in original_seqs.items():\n",
    "    try:\n",
    "        hidden_states = extract_esm_features(seq)\n",
    "        sae_features, _, _ = extract_sae_features(hidden_states)\n",
    "        pooled = pool_sequence_features(sae_features)\n",
    "        original_features[name] = pooled.cpu().numpy()\n",
    "        \n",
    "        print(f\"\\n{name} (length {len(seq)}):\")\n",
    "        mean_features = pooled[:feature_dim]\n",
    "        top_indices = np.argsort(mean_features)[::-1][:5]\n",
    "        \n",
    "        for i, idx in enumerate(top_indices):\n",
    "            activation = mean_features[idx]\n",
    "            # Check if this feature appeared in our analysis\n",
    "            if idx in important_features:\n",
    "                marker = \" *** (important in large dataset)\"\n",
    "            else:\n",
    "                marker = \"\"\n",
    "            print(f\"  {i+1}. Feature {idx:4d}: {activation:.3f}{marker}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {name}: {e}\")\n",
    "\n",
    "# Analyze overlap between original test features and our discovered features\n",
    "original_top_features = set()\n",
    "for name, features in original_features.items():\n",
    "    mean_part = features[:feature_dim]\n",
    "    top_5 = np.argsort(mean_part)[::-1][:5]\n",
    "    original_top_features.update(top_5)\n",
    "\n",
    "overlap = original_top_features.intersection(important_features)\n",
    "print(f\"\\n=== Feature Overlap Analysis ===\")\n",
    "print(f\"Original test sequences activate {len(original_top_features)} distinct features\")\n",
    "print(f\"Large dataset analysis found {len(important_features)} important features\")\n",
    "print(f\"Overlap: {len(overlap)} features ({100*len(overlap)/len(original_top_features):.1f}% of original)\")\n",
    "print(f\"Overlapping features: {sorted(list(overlap))}\")\n",
    "\n",
    "print(f\"\\n=== Key Insights ===\")\n",
    "print(f\"1. Large dataset analysis identified {len(important_features)} biologically meaningful features\")\n",
    "print(f\"2. Found {len(strong_associations)} strong feature-concept associations\")\n",
    "print(f\"3. Features show specialization for structural, functional, and modification concepts\")\n",
    "print(f\"4. Mean activation rate across proteins: {X_mean.mean():.4f}\")\n",
    "print(f\"5. Most discriminative features achieve AUC > 0.8 for their target concepts\")\n",
    "\n",
    "if len(overlap) > 0:\n",
    "    print(f\"6. {len(overlap)} features from toy examples also appear important in real proteins\")\n",
    "else:\n",
    "    print(f\"6. Toy examples use different features than those important for real protein concepts\")\n",
    "\n",
    "print(f\"\\nThis analysis demonstrates that SAEs learn interpretable features that correspond\")\n",
    "print(f\"to meaningful biological concepts when trained on diverse protein data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Troubleshooting and Next Steps\n",
    "print(\"=== Analysis Complete ===\")\n",
    "\n",
    "if 'associations' in locals() and len(associations) > 0:\n",
    "    print(\"✅ Successfully completed SAE feature analysis!\")\n",
    "    print(f\"Found {len(associations)} analyzable concepts\")\n",
    "    print(f\"Processed {len(aligned_data)} proteins with complete data\")\n",
    "    \n",
    "    # Save key results\n",
    "    results_dir = DATA_DIR / 'analysis_results' \n",
    "    results_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    # Save association results\n",
    "    association_summary = []\n",
    "    for concept, data in associations.items():\n",
    "        for feature_idx, auc in data['top_features'][:10]:\n",
    "            association_summary.append({\n",
    "                'concept': concept,\n",
    "                'feature_idx': feature_idx, \n",
    "                'auc': auc,\n",
    "                'auc_deviation': abs(auc - 0.5),\n",
    "                'n_positive': data['n_positive'],\n",
    "                'n_total': data['n_total']\n",
    "            })\n",
    "    \n",
    "    pd.DataFrame(association_summary).to_csv(results_dir / 'feature_concept_associations.csv', index=False)\n",
    "    aligned_data.to_csv(results_dir / 'aligned_protein_data.csv')\n",
    "    \n",
    "    print(f\"\\\\n📊 Results saved to {results_dir}/\")\n",
    "    print(\"- feature_concept_associations.csv: All feature-concept pairs\")\n",
    "    print(\"- aligned_protein_data.csv: Protein data with features and concepts\")\n",
    "    \n",
    "else:\n",
    "    print(\"❌ Analysis incomplete. Troubleshooting:\")\n",
    "    \n",
    "    if concepts_df is None:\n",
    "        print(\"\\\\n🔍 Issue: Failed to load protein annotations\")\n",
    "        print(\"Solutions:\")\n",
    "        print(\"1. Check internet connection for UniProt download\")\n",
    "        print(\"2. Verify UniProt API is accessible\")\n",
    "        print(\"3. Try re-running the annotation download cell\")\n",
    "        \n",
    "    elif len(common_ids) == 0:\n",
    "        print(\"\\\\n🔍 Issue: No overlap between FASTA sequences and annotations\")  \n",
    "        print(\"Solutions:\")\n",
    "        print(\"1. The FASTA and annotation queries may use different ID formats\")\n",
    "        print(\"2. Try downloading both from the same date/version\")\n",
    "        print(\"3. Check if protein IDs match between the two datasets\")\n",
    "        \n",
    "    elif len(aligned_data) < 50:\n",
    "        print(f\"\\\\n🔍 Issue: Very few proteins in analysis ({len(aligned_data)})\")\n",
    "        print(\"Solutions:\")\n",
    "        print(\"1. Increase the number of sequences processed\")\n",
    "        print(\"2. Use a less restrictive UniProt query\")\n",
    "        print(\"3. Process more proteins from the FASTA file\")\n",
    "        \n",
    "    print(\"\\\\n💡 To improve results:\")\n",
    "    print(\"1. Increase max_sequences in create_sequence_subset() to 25,000+\")\n",
    "    print(\"2. Increase subset_size in feature extraction to 5,000+\")  \n",
    "    print(\"3. Use broader UniProt annotation query (remove filters)\")\n",
    "    print(\"4. Consider using UniRef50 for even more proteins\")\n",
    "\n",
    "print(\"\\\\n🚀 Next steps for deeper analysis:\")\n",
    "print(\"1. Run the full pipeline with 10K+ proteins\")\n",
    "print(\"2. Analyze per-residue feature activations on specific proteins\")\n",
    "print(\"3. Train custom SAEs on your own protein data\")\n",
    "print(\"4. Use the InterPLM dashboard for interactive exploration\")\n",
    "print(\"5. Compare findings across different ESM-2 layers\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.13 ('interplm')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "1106d1d489397abf5d77132595a521cf67d890f951d991cd34215b053d2a27e6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
