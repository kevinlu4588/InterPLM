{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "from anthropic import Anthropic\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get key from environment\n",
    "api_key = os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "\n",
    "# Initialize client\n",
    "client = Anthropic(api_key=api_key)\n",
    "\n",
    "# Send a simple prompt\n",
    "response = client.messages.create(\n",
    "    model=\"claude-3-7-sonnet-20250219\",\n",
    "    max_tokens=200,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Say hello\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response.content[0].text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/.cs/conda/envs/interplm/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd, torch, os, gc\n",
    "from interplm.sae.inference import load_sae_from_hf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "DEVICE=\"cuda\"\n",
    "DTYPE=torch.float16\n",
    "\n",
    "DATA_DIR = Path(\"esm_sae_results\"); DATA_DIR.mkdir(exist_ok=True)\n",
    "SEQUENCES_DIR = Path(\"/home/ec2-user/SageMaker/InterPLM/data/uniprot/subset_25k.csv\")\n",
    "# ANNOTATIONS_DIR = Path(\"uniprotkb_swissprot_annotations.tsv.gz\")\n",
    "ANNOTATIONS_DIR = Path(\"/home/ec2-user/SageMaker/InterPLM/uniprotkb_swissprot_annotations.tsv.gz\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t33_650M_UR50D and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/esm2_t33_650M_UR50D\", do_lower_case=False)\n",
    "model     = AutoModel.from_pretrained(\"facebook/esm2_t33_650M_UR50D\",\n",
    "                                        output_hidden_states=True).to(DEVICE).eval()\n",
    "\n",
    "# Make sure the SAE you load matches the *plm_model* and *plm_layer* you want to use\n",
    "plm_model = \"esm2-650m\"   # matches your checkpoint naming\n",
    "plm_layer = 24            # <= MUST match esm_layer_sel\n",
    "sae = load_sae_from_hf(plm_model=plm_model, plm_layer=plm_layer).to(DEVICE).eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 6)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "features_all = pd.read_pickle(\"features_all.pkl\")\n",
    "features_all.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uniprot_id</th>\n",
       "      <th>length</th>\n",
       "      <th>features</th>\n",
       "      <th>max_activation</th>\n",
       "      <th>n_active_features</th>\n",
       "      <th>reconstruction_mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q9GL23</td>\n",
       "      <td>50</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002...</td>\n",
       "      <td>1.265625</td>\n",
       "      <td>1876</td>\n",
       "      <td>45.198380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q6GZU6</td>\n",
       "      <td>50</td>\n",
       "      <td>[0.00023197175, 0.0, 0.0, 0.0, 0.0013056946, 0...</td>\n",
       "      <td>0.843262</td>\n",
       "      <td>2168</td>\n",
       "      <td>13.467114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P9WJG6</td>\n",
       "      <td>50</td>\n",
       "      <td>[0.0, 0.00057144166, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>0.935059</td>\n",
       "      <td>1740</td>\n",
       "      <td>12.720748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P18924</td>\n",
       "      <td>51</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.000...</td>\n",
       "      <td>0.956543</td>\n",
       "      <td>1799</td>\n",
       "      <td>11.394856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q08076</td>\n",
       "      <td>52</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.000...</td>\n",
       "      <td>1.139648</td>\n",
       "      <td>1772</td>\n",
       "      <td>24.694654</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  uniprot_id  length                                           features  \\\n",
       "0     Q9GL23      50  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002...   \n",
       "1     Q6GZU6      50  [0.00023197175, 0.0, 0.0, 0.0, 0.0013056946, 0...   \n",
       "2     P9WJG6      50  [0.0, 0.00057144166, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "3     P18924      51  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.000...   \n",
       "4     Q08076      52  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.000...   \n",
       "\n",
       "   max_activation  n_active_features  reconstruction_mse  \n",
       "0        1.265625               1876           45.198380  \n",
       "1        0.843262               2168           13.467114  \n",
       "2        0.935059               1740           12.720748  \n",
       "3        0.956543               1799           11.394856  \n",
       "4        1.139648               1772           24.694654  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations_df = pd.read_csv(ANNOTATIONS_DIR, sep=\"\\t\", compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Entry</th>\n",
       "      <th>Reviewed</th>\n",
       "      <th>Protein names</th>\n",
       "      <th>Length</th>\n",
       "      <th>Sequence</th>\n",
       "      <th>EC number</th>\n",
       "      <th>Active site</th>\n",
       "      <th>Binding site</th>\n",
       "      <th>Cofactor</th>\n",
       "      <th>Disulfide bond</th>\n",
       "      <th>...</th>\n",
       "      <th>Helix</th>\n",
       "      <th>Turn</th>\n",
       "      <th>Beta strand</th>\n",
       "      <th>Coiled coil</th>\n",
       "      <th>Domain [CC]</th>\n",
       "      <th>Compositional bias</th>\n",
       "      <th>Domain [FT]</th>\n",
       "      <th>Motif</th>\n",
       "      <th>Region</th>\n",
       "      <th>Zinc finger</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A0A009IHW8</td>\n",
       "      <td>reviewed</td>\n",
       "      <td>2' cyclic ADP-D-ribose synthase AbTIR (2'cADPR...</td>\n",
       "      <td>269</td>\n",
       "      <td>MSLEQKKGADIISKILQIQNSIGKTTSPSTLKTKLSEISRKEQENA...</td>\n",
       "      <td>3.2.2.-; 3.2.2.6</td>\n",
       "      <td>ACT_SITE 208; /evidence=\"ECO:0000255|PROSITE-P...</td>\n",
       "      <td>BINDING 143; /ligand=\"NAD(+)\"; /ligand_id=\"ChE...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>HELIX 143..145; /evidence=\"ECO:0007829|PDB:7UW...</td>\n",
       "      <td>TURN 146..149; /evidence=\"ECO:0007829|PDB:7UWG...</td>\n",
       "      <td>STRAND 135..142; /evidence=\"ECO:0007829|PDB:7U...</td>\n",
       "      <td>COILED 31..99; /evidence=\"ECO:0000255\"</td>\n",
       "      <td>DOMAIN: The TIR domain mediates NAD(+) hydrola...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DOMAIN 133..266; /note=\"TIR\"; /evidence=\"ECO:0...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A0A023I7E1</td>\n",
       "      <td>reviewed</td>\n",
       "      <td>Glucan endo-1,3-beta-D-glucosidase 1 (Endo-1,3...</td>\n",
       "      <td>796</td>\n",
       "      <td>MRFQVIVAAATITMITSYIPGVASQSTSDGDDLFVPVSNFDPKSIF...</td>\n",
       "      <td>3.2.1.39</td>\n",
       "      <td>ACT_SITE 500; /evidence=\"ECO:0000255|PROSITE-P...</td>\n",
       "      <td>BINDING 504; /ligand=\"(1,3-beta-D-glucosyl)n\";...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>HELIX 42..44; /evidence=\"ECO:0007829|PDB:4K35\"...</td>\n",
       "      <td>TURN 287..289; /evidence=\"ECO:0007829|PDB:4K35...</td>\n",
       "      <td>STRAND 56..58; /evidence=\"ECO:0007829|PDB:4K35...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DOMAIN 31..759; /note=\"GH81\"; /evidence=\"ECO:0...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>REGION 31..276; /note=\"beta-sandwich subdomain...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A0A024B7W1</td>\n",
       "      <td>reviewed</td>\n",
       "      <td>Genome polyprotein [Cleaved into: Capsid prote...</td>\n",
       "      <td>3423</td>\n",
       "      <td>MKNPKKKSGGFRIVNMLKRGVARVSPFGGLKRLPAGLLLGHGPIRM...</td>\n",
       "      <td>2.1.1.56; 2.1.1.57; 2.7.7.48; 3.4.21.91; 3.6.1...</td>\n",
       "      <td>ACT_SITE 1553; /note=\"Charge relay system; for...</td>\n",
       "      <td>BINDING 1696..1703; /ligand=\"ATP\"; /ligand_id=...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DISULFID 350..406; /evidence=\"ECO:0000250|UniP...</td>\n",
       "      <td>...</td>\n",
       "      <td>HELIX 222..225; /evidence=\"ECO:0007829|PDB:6CO...</td>\n",
       "      <td>TURN 237..241; /evidence=\"ECO:0007829|PDB:6CO8...</td>\n",
       "      <td>STRAND 234..236; /evidence=\"ECO:0007829|PDB:6C...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DOMAIN: [Small envelope protein M]: The transm...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DOMAIN 1503..1680; /note=\"Peptidase S7\"; /evid...</td>\n",
       "      <td>MOTIF 1787..1790; /note=\"DEAH box\"; /evidence=...</td>\n",
       "      <td>REGION 1..25; /note=\"Disordered\"; /evidence=\"E...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A0A024RXP8</td>\n",
       "      <td>reviewed</td>\n",
       "      <td>Exoglucanase 1 (EC 3.2.1.91) (1,4-beta-cellobi...</td>\n",
       "      <td>514</td>\n",
       "      <td>MYRKLAVISAFLATARAQSACTLQSETHPPLTWQKCSSGGTCTQQT...</td>\n",
       "      <td>3.2.1.91</td>\n",
       "      <td>ACT_SITE 229; /note=\"Nucleophile\"; /evidence=\"...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DISULFID 21..89; /evidence=\"ECO:0000250|UniPro...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DOMAIN: The enzyme consists of two functional ...</td>\n",
       "      <td>COMPBIAS 401..437; /note=\"Polar residues\"; /ev...</td>\n",
       "      <td>DOMAIN 478..514; /note=\"CBM1\"; /evidence=\"ECO:...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>REGION 18..453; /note=\"Catalytic\"; /evidence=\"...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A0A024SC78</td>\n",
       "      <td>reviewed</td>\n",
       "      <td>Cutinase (EC 3.1.1.74)</td>\n",
       "      <td>248</td>\n",
       "      <td>MRSLAILTTLLAGHAFAYPKPAPQSVNRRDWPSINEFLSELAKVMP...</td>\n",
       "      <td>3.1.1.74</td>\n",
       "      <td>ACT_SITE 164; /note=\"Nucleophile\"; /evidence=\"...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DISULFID 55..91; /evidence=\"ECO:0000269|PubMed...</td>\n",
       "      <td>...</td>\n",
       "      <td>HELIX 51..69; /evidence=\"ECO:0007829|PDB:4PSC\"...</td>\n",
       "      <td>TURN 94..100; /evidence=\"ECO:0007829|PDB:4PSC\"...</td>\n",
       "      <td>STRAND 48..50; /evidence=\"ECO:0007829|PDB:4PSC...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DOMAIN: In contract to classical cutinases, po...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>REGION 31..70; /note=\"Lid covering the active ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Entry  Reviewed                                      Protein names  \\\n",
       "0  A0A009IHW8  reviewed  2' cyclic ADP-D-ribose synthase AbTIR (2'cADPR...   \n",
       "1  A0A023I7E1  reviewed  Glucan endo-1,3-beta-D-glucosidase 1 (Endo-1,3...   \n",
       "2  A0A024B7W1  reviewed  Genome polyprotein [Cleaved into: Capsid prote...   \n",
       "3  A0A024RXP8  reviewed  Exoglucanase 1 (EC 3.2.1.91) (1,4-beta-cellobi...   \n",
       "4  A0A024SC78  reviewed                             Cutinase (EC 3.1.1.74)   \n",
       "\n",
       "   Length                                           Sequence  \\\n",
       "0     269  MSLEQKKGADIISKILQIQNSIGKTTSPSTLKTKLSEISRKEQENA...   \n",
       "1     796  MRFQVIVAAATITMITSYIPGVASQSTSDGDDLFVPVSNFDPKSIF...   \n",
       "2    3423  MKNPKKKSGGFRIVNMLKRGVARVSPFGGLKRLPAGLLLGHGPIRM...   \n",
       "3     514  MYRKLAVISAFLATARAQSACTLQSETHPPLTWQKCSSGGTCTQQT...   \n",
       "4     248  MRSLAILTTLLAGHAFAYPKPAPQSVNRRDWPSINEFLSELAKVMP...   \n",
       "\n",
       "                                           EC number  \\\n",
       "0                                   3.2.2.-; 3.2.2.6   \n",
       "1                                           3.2.1.39   \n",
       "2  2.1.1.56; 2.1.1.57; 2.7.7.48; 3.4.21.91; 3.6.1...   \n",
       "3                                           3.2.1.91   \n",
       "4                                           3.1.1.74   \n",
       "\n",
       "                                         Active site  \\\n",
       "0  ACT_SITE 208; /evidence=\"ECO:0000255|PROSITE-P...   \n",
       "1  ACT_SITE 500; /evidence=\"ECO:0000255|PROSITE-P...   \n",
       "2  ACT_SITE 1553; /note=\"Charge relay system; for...   \n",
       "3  ACT_SITE 229; /note=\"Nucleophile\"; /evidence=\"...   \n",
       "4  ACT_SITE 164; /note=\"Nucleophile\"; /evidence=\"...   \n",
       "\n",
       "                                        Binding site Cofactor  \\\n",
       "0  BINDING 143; /ligand=\"NAD(+)\"; /ligand_id=\"ChE...      NaN   \n",
       "1  BINDING 504; /ligand=\"(1,3-beta-D-glucosyl)n\";...      NaN   \n",
       "2  BINDING 1696..1703; /ligand=\"ATP\"; /ligand_id=...      NaN   \n",
       "3                                                NaN      NaN   \n",
       "4                                                NaN      NaN   \n",
       "\n",
       "                                      Disulfide bond  ...  \\\n",
       "0                                                NaN  ...   \n",
       "1                                                NaN  ...   \n",
       "2  DISULFID 350..406; /evidence=\"ECO:0000250|UniP...  ...   \n",
       "3  DISULFID 21..89; /evidence=\"ECO:0000250|UniPro...  ...   \n",
       "4  DISULFID 55..91; /evidence=\"ECO:0000269|PubMed...  ...   \n",
       "\n",
       "                                               Helix  \\\n",
       "0  HELIX 143..145; /evidence=\"ECO:0007829|PDB:7UW...   \n",
       "1  HELIX 42..44; /evidence=\"ECO:0007829|PDB:4K35\"...   \n",
       "2  HELIX 222..225; /evidence=\"ECO:0007829|PDB:6CO...   \n",
       "3                                                NaN   \n",
       "4  HELIX 51..69; /evidence=\"ECO:0007829|PDB:4PSC\"...   \n",
       "\n",
       "                                                Turn  \\\n",
       "0  TURN 146..149; /evidence=\"ECO:0007829|PDB:7UWG...   \n",
       "1  TURN 287..289; /evidence=\"ECO:0007829|PDB:4K35...   \n",
       "2  TURN 237..241; /evidence=\"ECO:0007829|PDB:6CO8...   \n",
       "3                                                NaN   \n",
       "4  TURN 94..100; /evidence=\"ECO:0007829|PDB:4PSC\"...   \n",
       "\n",
       "                                         Beta strand  \\\n",
       "0  STRAND 135..142; /evidence=\"ECO:0007829|PDB:7U...   \n",
       "1  STRAND 56..58; /evidence=\"ECO:0007829|PDB:4K35...   \n",
       "2  STRAND 234..236; /evidence=\"ECO:0007829|PDB:6C...   \n",
       "3                                                NaN   \n",
       "4  STRAND 48..50; /evidence=\"ECO:0007829|PDB:4PSC...   \n",
       "\n",
       "                              Coiled coil  \\\n",
       "0  COILED 31..99; /evidence=\"ECO:0000255\"   \n",
       "1                                     NaN   \n",
       "2                                     NaN   \n",
       "3                                     NaN   \n",
       "4                                     NaN   \n",
       "\n",
       "                                         Domain [CC]  \\\n",
       "0  DOMAIN: The TIR domain mediates NAD(+) hydrola...   \n",
       "1                                                NaN   \n",
       "2  DOMAIN: [Small envelope protein M]: The transm...   \n",
       "3  DOMAIN: The enzyme consists of two functional ...   \n",
       "4  DOMAIN: In contract to classical cutinases, po...   \n",
       "\n",
       "                                  Compositional bias  \\\n",
       "0                                                NaN   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "3  COMPBIAS 401..437; /note=\"Polar residues\"; /ev...   \n",
       "4                                                NaN   \n",
       "\n",
       "                                         Domain [FT]  \\\n",
       "0  DOMAIN 133..266; /note=\"TIR\"; /evidence=\"ECO:0...   \n",
       "1  DOMAIN 31..759; /note=\"GH81\"; /evidence=\"ECO:0...   \n",
       "2  DOMAIN 1503..1680; /note=\"Peptidase S7\"; /evid...   \n",
       "3  DOMAIN 478..514; /note=\"CBM1\"; /evidence=\"ECO:...   \n",
       "4                                                NaN   \n",
       "\n",
       "                                               Motif  \\\n",
       "0                                                NaN   \n",
       "1                                                NaN   \n",
       "2  MOTIF 1787..1790; /note=\"DEAH box\"; /evidence=...   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "\n",
       "                                              Region Zinc finger  \n",
       "0                                                NaN         NaN  \n",
       "1  REGION 31..276; /note=\"beta-sandwich subdomain...         NaN  \n",
       "2  REGION 1..25; /note=\"Disordered\"; /evidence=\"E...         NaN  \n",
       "3  REGION 18..453; /note=\"Catalytic\"; /evidence=\"...         NaN  \n",
       "4  REGION 31..70; /note=\"Lid covering the active ...         NaN  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotations_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import random\n",
    "\n",
    "# # Parameters\n",
    "# N_FEATURES = 1200\n",
    "# BINS = np.arange(0, 1.1, 0.1)\n",
    "\n",
    "# # Randomly select feature ids\n",
    "# all_feature_ids = list(range(len(features_all.iloc[0].features)))\n",
    "# print(\"num features\", len(all_feature_ids))\n",
    "# selected_features = random.sample(all_feature_ids, N_FEATURES)\n",
    "\n",
    "# print(f\"Selected {len(selected_features)} features out of {len(all_feature_ids)}\")\n",
    "\n",
    "# # Build dataset for each feature\n",
    "# feature_datasets = {}\n",
    "\n",
    "# # Predefine bin labels\n",
    "# bin_labels = [f\"{BINS[i]:.1f}-{BINS[i+1]:.1f}\" for i in range(len(BINS)-1)]\n",
    "\n",
    "# for fid in selected_features:\n",
    "#     # Extract activations for this feature\n",
    "#     activations = [f[fid] for f in features_all[\"features\"]]\n",
    "#     df = pd.DataFrame({\n",
    "#         \"uniprot_id\": features_all[\"uniprot_id\"],\n",
    "#         \"activation\": activations\n",
    "#     })\n",
    "\n",
    "#     # Assign bins\n",
    "#     df[\"bin\"] = pd.cut(df[\"activation\"], bins=BINS, labels=bin_labels, include_lowest=True)\n",
    "\n",
    "#     sampled = []\n",
    "\n",
    "#     # Sample proteins per bin\n",
    "#     for b in df[\"bin\"].dropna().unique():\n",
    "#         bin_df = df[df[\"bin\"] == b]\n",
    "#         n = 10 if b == \"0.9-1.0\" else 2\n",
    "#         sampled.extend(bin_df.sample(min(len(bin_df), n), random_state=42).to_dict(orient=\"records\"))\n",
    "\n",
    "#     # Add 10 random zero-activation proteins \n",
    "#     zero_df = df[df[\"activation\"] == 0.0]\n",
    "#     if len(zero_df) > 0:\n",
    "#         sampled.extend(zero_df.sample(min(len(zero_df), 10), random_state=42).to_dict(orient=\"records\"))\n",
    "\n",
    "#     # Merge with metadata from annotations_df\n",
    "#     sampled_df = pd.DataFrame(sampled)\n",
    "#     merged = sampled_df.merge(annotations_df, left_on=\"uniprot_id\", right_on=\"Entry\", how=\"left\")\n",
    "\n",
    "#     feature_datasets[fid] = merged\n",
    "\n",
    "# # Example feature dataset\n",
    "# example_fid = selected_features[0]\n",
    "# feature_datasets[example_fid].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original max activation (feature 0): 0.02611415\n",
      "Normalized max activation (feature 0): 1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "#Stakc into [num_proteins, num_features]\n",
    "X = np.vstack(features_all['features'].values) #Shape (N, F)\n",
    "\n",
    "#Max activation per feature across all proteins\n",
    "max_per_feature = X.max(axis=0) # shape: (F,)\n",
    "eps = 1e-12\n",
    "max_safe = np.where(max_per_feature > 0, max_per_feature, eps)\n",
    "#Normalize\n",
    "X_norm = X / max_safe\n",
    "\n",
    "#Save back\n",
    "features_all = features_all.copy()\n",
    "features_all[\"features_norm\"] = [row for row in X_norm]\n",
    "print(\"Original max activation (feature 0):\", X[:,0].max())\n",
    "print(\"Normalized max activation (feature 0):\", X_norm[:,0].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num features 10240\n",
      "Selected 10240 features out of 10240\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "# Parameters\n",
    "N_FEATURES = 10240\n",
    "BINS = np.arange(0, 1.1, 0.1)\n",
    "\n",
    "# Randomly select feature ids\n",
    "all_feature_ids = list(range(len(features_all.iloc[0].features)))\n",
    "print(\"num features\", len(all_feature_ids))\n",
    "selected_features = random.sample(all_feature_ids, N_FEATURES)\n",
    "\n",
    "print(f\"Selected {len(selected_features)} features out of {len(all_feature_ids)}\")\n",
    "\n",
    "# Build dataset for each feature\n",
    "feature_datasets = {}\n",
    "\n",
    "# Predefine bin labels\n",
    "bin_labels = [f\"{BINS[i]:.1f}-{BINS[i+1]:.1f}\" for i in range(len(BINS)-1)]\n",
    "\n",
    "for fid in selected_features:\n",
    "    # Extract activations for this feature\n",
    "    activations = [f[fid] for f in features_all[\"features_norm\"]]\n",
    "    df = pd.DataFrame({\n",
    "        \"uniprot_id\": features_all[\"uniprot_id\"],\n",
    "        \"activation\": activations\n",
    "    })\n",
    "\n",
    "    # Assign bins\n",
    "    df[\"bin\"] = pd.cut(df[\"activation\"], bins=BINS, labels=bin_labels, include_lowest=True)\n",
    "\n",
    "    sampled = []\n",
    "\n",
    "    # Sample proteins per bin\n",
    "    for b in df[\"bin\"].dropna().unique():\n",
    "        bin_df = df[df[\"bin\"] == b]\n",
    "        n = 10 if b == \"0.9-1.0\" else 2\n",
    "        sampled.extend(bin_df.sample(min(len(bin_df), n), random_state=42).to_dict(orient=\"records\"))\n",
    "\n",
    "    # Add 10 random zero-activation proteins \n",
    "    zero_df = df[df[\"activation\"] == 0.0]\n",
    "    if len(zero_df) > 0:\n",
    "        sampled.extend(zero_df.sample(min(len(zero_df), 10), random_state=42).to_dict(orient=\"records\"))\n",
    "\n",
    "    # Merge with metadata from annotations_df\n",
    "    sampled_df = pd.DataFrame(sampled)\n",
    "    merged = sampled_df.merge(annotations_df, left_on=\"uniprot_id\", right_on=\"Entry\", how=\"left\")\n",
    "\n",
    "    feature_datasets[fid] = merged\n",
    "\n",
    "# Example feature dataset\n",
    "example_fid = selected_features[0]\n",
    "feature_datasets[example_fid].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "feature_datasets.to_pickle(\"feature_datasets.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Amino Acid Indices and activations for better LLM annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import extract_esm_features_batch\n",
    "\n",
    "@torch.no_grad()\n",
    "def extract_sae_features(hidden_states: torch.Tensor, sae):\n",
    "    \"\"\"\n",
    "    Pass ESM hidden states through the Sparse Autoencoder (SAE).\n",
    "\n",
    "    Args\n",
    "    ----\n",
    "    hidden_states : torch.Tensor\n",
    "        Shape [B, L, d] or [L, d].\n",
    "        - B = batch size (optional if unsqueezed)\n",
    "        - L = sequence length\n",
    "        - d = ESM embedding dimension (e.g., 1280 for esm2_t33_650M)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    sae_features : torch.Tensor\n",
    "        Shape [B, L, F]\n",
    "        Sparse latent features per residue.\n",
    "        F = number of SAE dictionary atoms / features.\n",
    "\n",
    "    recon : torch.Tensor\n",
    "        Shape [B, L, d]\n",
    "        Reconstructed embeddings in token space.\n",
    "\n",
    "    error : torch.Tensor\n",
    "        Shape [B, L, d]\n",
    "        Residual = hidden_states - recon\n",
    "    \"\"\"\n",
    "    if hidden_states.dim() == 2:          # [L, d]\n",
    "        hidden_states = hidden_states.unsqueeze(0)  # → [1, L, d]\n",
    "    x = hidden_states.to(torch.float32)      # <- ensure fp32 for SAE\n",
    "\n",
    "    # SAE should have encode() and decode() that operate on last dimension\n",
    "    sae_features = sae.encode(x)     # [B, L, F]\n",
    "    recon        = sae.decode(sae_features)      # [B, L, d]\n",
    "    error        = hidden_states - recon         # [B, L, d]\n",
    "\n",
    "    return sae_features, recon, error\n",
    "\n",
    "#Config for extracting activated positions\n",
    "\n",
    "TOP_K = 8 # How many positions to record per protein\n",
    "MIN_ACT = 0.0 #Only consider positions with activation > MIN_ACT\n",
    "BATCH_SIZE = 16 #For ESM/SAE Inference\n",
    "\n",
    "\n",
    "def _batched(iterable, n):\n",
    "    \"\"\"Yield Successive n-sized chunks from iterable\n",
    "    \"\"\"\n",
    "    it = list(iterable)\n",
    "    for i in range(0, len(it), n):\n",
    "        yield it[i:i+n]\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from typing import List, Tuple, Optional, Literal\n",
    "\n",
    "TOP_K = 8\n",
    "MIN_ACT = 0.0\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "def _batched(iterable, n):\n",
    "    it = list(iterable)\n",
    "    for i in range(0, len(it), n):\n",
    "        yield it[i:i+n]\n",
    "\n",
    "def _normalize_1d(\n",
    "    x: np.ndarray,\n",
    "    mode: Literal[\"seq_max\",\"feature_global_max\",\"zscore\",\"none\"] = \"seq_max\",\n",
    "    global_max: Optional[float] = None,\n",
    "    eps: float = 1e-8\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Normalize a 1D activation vector x (valid positions only).\n",
    "    \"\"\"\n",
    "    if mode == \"none\":\n",
    "        return x.copy()\n",
    "\n",
    "    if mode == \"feature_global_max\":\n",
    "        if global_max is None or global_max <= eps:\n",
    "            # fallback to seq_max if global not available/safe\n",
    "            mode = \"seq_max\"\n",
    "        else:\n",
    "            return x / (global_max + eps)\n",
    "\n",
    "    if mode == \"seq_max\":\n",
    "        m = np.max(x) if x.size else 0.0\n",
    "        return x / (m + eps)\n",
    "\n",
    "    if mode == \"zscore\":\n",
    "        mu = float(np.mean(x)) if x.size else 0.0\n",
    "        sd = float(np.std(x)) if x.size else 0.0\n",
    "        return (x - mu) / (sd + eps)\n",
    "\n",
    "    # Fallback (shouldn't hit)\n",
    "    return x.copy()\n",
    "\n",
    "@torch.no_grad()\n",
    "def compute_activated_positions_for_feature(\n",
    "    fid: int,\n",
    "    seqs: List[str],\n",
    "    batch_size: int = BATCH_SIZE,\n",
    "    max_per_feature: Optional[np.ndarray] = None,\n",
    "    norm_mode: Literal[\"seq_max\",\"feature_global_max\",\"zscore\",\"none\"] = \"seq_max\",\n",
    "    top_k: int = TOP_K,\n",
    "    min_act: float = MIN_ACT,\n",
    "    device: str = \"cuda\"\n",
    ") -> Tuple[List[List[int]], List[List[str]], List[List[float]], List[List[float]]]:\n",
    "    \"\"\"\n",
    "    For a list of sequences and a single SAE feature id (fid),\n",
    "    return per-sequence top-K activated residue indices, AA identities,\n",
    "    normalized scores (per selected position), and raw scores.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    all_indices : List[List[int]]\n",
    "        Per-sequence Top-K indices (0-based).\n",
    "    all_aas : List[List[str]]\n",
    "        Per-sequence amino acids at those indices.\n",
    "    norm_vals : List[List[float]]\n",
    "        Per-sequence normalized activations aligned with Top-K order.\n",
    "    raw_vals : List[List[float]]\n",
    "        Per-sequence raw activations aligned with Top-K order.\n",
    "    \"\"\"\n",
    "    all_indices: List[List[int]] = []\n",
    "    all_aas: List[List[str]] = []\n",
    "    norm_vals: List[List[float]] = []\n",
    "    raw_vals: List[List[float]] = []\n",
    "\n",
    "    # Optional global max for this feature (for 'feature_global_max' mode)\n",
    "    global_max = None\n",
    "    if norm_mode == \"feature_global_max\" and max_per_feature is not None:\n",
    "        if 0 <= fid < len(max_per_feature):\n",
    "            gm = float(max_per_feature[fid])\n",
    "            global_max = gm if np.isfinite(gm) else None\n",
    "\n",
    "    for chunk in _batched(seqs, batch_size):\n",
    "        # ESM -> SAE: token representations and mask\n",
    "        token_reps, attn_mask = extract_esm_features_batch(\n",
    "            chunk, layer_sel=plm_layer, device=device, model=model, tokenizer=tokenizer\n",
    "        )  # token_reps: [B, L, H], attn_mask: [B, L] bool\n",
    "        sae_feats, _, _ = extract_sae_features(token_reps, sae)  # [B, L, F]\n",
    "\n",
    "        # Select feature channel -> [B, L] on CPU\n",
    "        feat_act = sae_feats[..., fid].float().cpu()\n",
    "        mask = attn_mask.cpu()  # [B, L] bool\n",
    "\n",
    "        for seq, act_row, m in zip(chunk, feat_act, mask):\n",
    "            L = int(m.sum().item())  # valid residues\n",
    "            act_valid = act_row[:L].numpy() if L > 0 else np.array([], dtype=np.float32)\n",
    "\n",
    "            # positions above threshold\n",
    "            valid_idx = np.where(act_valid > min_act)[0]\n",
    "            if valid_idx.size == 0:\n",
    "                all_indices.append([])\n",
    "                all_aas.append([])\n",
    "                norm_vals.append([])\n",
    "                raw_vals.append([])\n",
    "                continue\n",
    "\n",
    "            # sort by activation desc within valid subset and take top_k\n",
    "            order = np.argsort(-act_valid[valid_idx])\n",
    "            chosen_local = valid_idx[order[:top_k]].tolist()\n",
    "\n",
    "            # raw values for the chosen positions\n",
    "            chosen_raw = act_valid[chosen_local]\n",
    "\n",
    "            # normalization (done on the full valid slice, then gather chosen)\n",
    "            norm_full = _normalize_1d(\n",
    "                act_valid, mode=norm_mode, global_max=global_max\n",
    "            )\n",
    "            chosen_norm = norm_full[chosen_local]\n",
    "\n",
    "            # map to AAs (defensive indexing)\n",
    "            aas = [seq[i] if i < len(seq) else \"X\" for i in chosen_local]\n",
    "\n",
    "            all_indices.append(chosen_local)\n",
    "            all_aas.append(aas)\n",
    "            norm_vals.append([float(v) for v in chosen_norm])\n",
    "            raw_vals.append([float(v) for v in chosen_raw])\n",
    "\n",
    "        # free tensors early\n",
    "        del token_reps, sae_feats, feat_act, attn_mask\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    return all_indices, all_aas, norm_vals, raw_vals\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integrate with feature_datasets dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Features: 100%|██████████| 1/1 [00:00<00:00,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 25 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uniprot_id</th>\n",
       "      <th>activation</th>\n",
       "      <th>seq_max_activation_norm</th>\n",
       "      <th>activated_indices_str</th>\n",
       "      <th>activated_aas_str</th>\n",
       "      <th>seq_max_activation_norm_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q1C0M8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A5WV69</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q7YRC1</td>\n",
       "      <td>0.138688</td>\n",
       "      <td>[1.0, 0.9184075593948364, 0.31311237812042236,...</td>\n",
       "      <td>185,237,271,278,204,192,197,205</td>\n",
       "      <td>G,C,G,W,A,G,A,I</td>\n",
       "      <td>1.0,0.9184075593948364,0.31311237812042236,0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q8TXW1</td>\n",
       "      <td>0.156860</td>\n",
       "      <td>[0.9999998807907104, 0.5972216725349426, 0.583...</td>\n",
       "      <td>63,62,60,59,61,70,64,74</td>\n",
       "      <td>R,L,D,L,T,D,G,G</td>\n",
       "      <td>0.9999998807907104,0.5972216725349426,0.583204...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P29305</td>\n",
       "      <td>0.383721</td>\n",
       "      <td>[1.0, 0.9846875071525574, 0.8020842671394348, ...</td>\n",
       "      <td>183,131,138,14,58,137,136,184</td>\n",
       "      <td>S,G,A,A,I,L,Y,V</td>\n",
       "      <td>1.0,0.9846875071525574,0.8020842671394348,0.38...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  uniprot_id  activation                            seq_max_activation_norm  \\\n",
       "0     Q1C0M8    0.000000                                                 []   \n",
       "1     A5WV69    0.000000                                                 []   \n",
       "2     Q7YRC1    0.138688  [1.0, 0.9184075593948364, 0.31311237812042236,...   \n",
       "3     Q8TXW1    0.156860  [0.9999998807907104, 0.5972216725349426, 0.583...   \n",
       "4     P29305    0.383721  [1.0, 0.9846875071525574, 0.8020842671394348, ...   \n",
       "\n",
       "             activated_indices_str activated_aas_str  \\\n",
       "0                                                      \n",
       "1                                                      \n",
       "2  185,237,271,278,204,192,197,205   G,C,G,W,A,G,A,I   \n",
       "3          63,62,60,59,61,70,64,74   R,L,D,L,T,D,G,G   \n",
       "4    183,131,138,14,58,137,136,184   S,G,A,A,I,L,Y,V   \n",
       "\n",
       "                         seq_max_activation_norm_str  \n",
       "0                                                     \n",
       "1                                                     \n",
       "2  1.0,0.9184075593948364,0.31311237812042236,0.1...  \n",
       "3  0.9999998807907104,0.5972216725349426,0.583204...  \n",
       "4  1.0,0.9846875071525574,0.8020842671394348,0.38...  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#feature_datasets: Dict[int, pd.DataFrame] where each df includes 'Sequence'\n",
    "from tqdm import tqdm\n",
    "for fid, df in tqdm(list(feature_datasets.items())[:1], total=1, desc=\"Features\"):\n",
    "    #make a copy to avoid mutating original reference\n",
    "    work = df.copy()\n",
    "\n",
    "    # Ensure sequences are present and aligned\n",
    "    if \"Sequence\" not in work.columns:\n",
    "        # If your UniProt column is named differently, adjust here\n",
    "        raise KeyError(\"Expected a 'Sequence' column in merged annotations.\")\n",
    "    seqs = work[\"Sequence\"].astype(str).fillna(\"\").tolist()\n",
    "\n",
    "    idx_lists, aa_lists, norm_vals, raw_vals = compute_activated_positions_for_feature(fid, seqs, batch_size=BATCH_SIZE, max_per_feature = max_safe)\n",
    "    print(len(idx_lists), len(aa_lists), len(norm_vals))\n",
    "    #compute per-row activated positions for this feature\n",
    "    work['activated_indices'] = idx_lists\n",
    "    work['activated_aas'] = aa_lists\n",
    "    work['seq_max_activation_norm'] = norm_vals\n",
    "\n",
    "    # # (Optional) also add a compact string column for the prompt table\n",
    "    work[\"activated_indices_str\"] = work[\"activated_indices\"].apply(lambda xs: \",\".join(map(str, xs)) if xs else \"\")\n",
    "    work[\"activated_aas_str\"]     = work[\"activated_aas\"].apply(lambda xs: \",\".join(xs) if xs else \"\")\n",
    "    work[\"seq_max_activation_norm_str\"] = work[\"seq_max_activation_norm\"].apply(lambda xs: \",\".join(map(str, xs)) if xs else \"\")\n",
    "\n",
    "    feature_datasets[fid] = work\n",
    "\n",
    "first_fid = list(feature_datasets.keys())[0]\n",
    "feature_datasets[first_fid][[\"uniprot_id\",\"activation\",\"seq_max_activation_norm\", \"activated_indices_str\",\"activated_aas_str\", \"seq_max_activation_norm_str\"]].head()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_16079/871195895.py:91: DeprecationWarning: The model 'claude-3-5-sonnet-20240620' is deprecated and will reach end-of-life on October 22, 2025.\n",
      "Please migrate to a newer model. Visit https://docs.anthropic.com/en/docs/resources/model-deprecations for more information.\n",
      "  resp = client.messages.create(\n",
      "/tmp/ipykernel_16079/871195895.py:91: DeprecationWarning: The model 'claude-3-5-sonnet-20240620' is deprecated and will reach end-of-life on October 22, 2025.\n",
      "Please migrate to a newer model. Visit https://docs.anthropic.com/en/docs/resources/model-deprecations for more information.\n",
      "  resp = client.messages.create(\n",
      "/tmp/ipykernel_16079/871195895.py:91: DeprecationWarning: The model 'claude-3-5-sonnet-20240620' is deprecated and will reach end-of-life on October 22, 2025.\n",
      "Please migrate to a newer model. Visit https://docs.anthropic.com/en/docs/resources/model-deprecations for more information.\n",
      "  resp = client.messages.create(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[done] 3 features → claude_feature_annotations.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_id</th>\n",
       "      <th>n_rows_shown</th>\n",
       "      <th>description</th>\n",
       "      <th>summary</th>\n",
       "      <th>raw_response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2457</td>\n",
       "      <td>25</td>\n",
       "      <td>The activation patterns are characterized by:\\...</td>\n",
       "      <td>The feature activates on conserved structural ...</td>\n",
       "      <td>The activation patterns are characterized by:\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7950</td>\n",
       "      <td>23</td>\n",
       "      <td>The activation patterns are characterized by:\\...</td>\n",
       "      <td>The feature activates on small, single-domain ...</td>\n",
       "      <td>The activation patterns are characterized by:\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>780</td>\n",
       "      <td>30</td>\n",
       "      <td>The activation patterns are characterized by:\\...</td>\n",
       "      <td>The feature activates on ATP synthase subunit ...</td>\n",
       "      <td>The activation patterns are characterized by:\\...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature_id  n_rows_shown  \\\n",
       "0        2457            25   \n",
       "1        7950            23   \n",
       "2         780            30   \n",
       "\n",
       "                                         description  \\\n",
       "0  The activation patterns are characterized by:\\...   \n",
       "1  The activation patterns are characterized by:\\...   \n",
       "2  The activation patterns are characterized by:\\...   \n",
       "\n",
       "                                             summary  \\\n",
       "0  The feature activates on conserved structural ...   \n",
       "1  The feature activates on small, single-domain ...   \n",
       "2  The feature activates on ATP synthase subunit ...   \n",
       "\n",
       "                                        raw_response  \n",
       "0  The activation patterns are characterized by:\\...  \n",
       "1  The activation patterns are characterized by:\\...  \n",
       "2  The activation patterns are characterized by:\\...  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Setup (once per notebook) ---\n",
    "# pip install anthropic python-dotenv\n",
    "from anthropic import Anthropic\n",
    "from dotenv import load_dotenv\n",
    "import os, time, json, math, textwrap\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Dict\n",
    "\n",
    "# Load .env (expects ANTHROPIC_API_KEY=...)\n",
    "load_dotenv()\n",
    "client = Anthropic(api_key=os.getenv(\"ANTHROPIC_API_KEY\"))\n",
    "\n",
    "# --- Config ---\n",
    "MODEL_NAME = \"claude-3-5-sonnet-20240620\"\n",
    "MAX_TOKENS = 800  # enough for description + summary\n",
    "TEMPERATURE = 0.0 # deterministic\n",
    "CHECKPOINT_EVERY = 50\n",
    "OUTPUT_PATH = \"claude_feature_annotations.csv\"\n",
    "\n",
    "# Columns to show Claude (customize as you like)\n",
    "# We'll include what exists; missing columns are auto-dropped\n",
    "PREFERRED_COLS = [\n",
    "    # keys/ids\n",
    "    \"uniprot_id\", \"Entry\", \"Protein names\",\n",
    "    # size/sequence shape\n",
    "    \"Length\",\n",
    "    # functional annotations\n",
    "    \"EC number\", \"Active site\", \"Binding site\", \"Cofactor\", \"Disulfide bond\",\n",
    "    \"Helix\", \"Turn\", \"Beta strand\", \"Coiled coil\",\n",
    "    \"Domain [CC]\", \"Compositional bias\", \"Domain [FT]\", \"Motif\", \"Region\", \"Zinc finger\",\n",
    "    # your per-feature fields\n",
    "    \"activation\", \"bin\",\n",
    "    # optional (only used if present)\n",
    "    \"activated_indices\", \"activated_aas\"\n",
    "]\n",
    "\n",
    "# Limit rows/cols so the table fits comfortably in context\n",
    "MAX_ROWS = 80   # you can raise/lower if you hit token limits\n",
    "TRUNCATE_STR_LEN = 120  # truncate long text fields so tables stay compact\n",
    "\n",
    "\n",
    "def _coerce_and_trim_cols(df: pd.DataFrame, cols: list[str]) -> pd.DataFrame:\n",
    "    \"\"\"Select existing columns, stringify, and truncate long strings so the table is compact.\"\"\"\n",
    "    use_cols = [c for c in cols if c in df.columns]\n",
    "    if not use_cols:\n",
    "        # Fallback: show whatever is available\n",
    "        use_cols = list(df.columns)\n",
    "\n",
    "    out = df[use_cols].copy()\n",
    "\n",
    "    # Coerce to string and truncate long values\n",
    "    for c in use_cols:\n",
    "        out[c] = out[c].astype(str).str.replace(r\"\\s+\", \" \", regex=True)\n",
    "        out[c] = out[c].apply(lambda s: s[:TRUNCATE_STR_LEN] + \"…\" if len(s) > TRUNCATE_STR_LEN else s)\n",
    "\n",
    "    # Keep only first MAX_ROWS to control token usage\n",
    "    return out.head(MAX_ROWS)\n",
    "\n",
    "\n",
    "PROMPT_TEMPLATE = \"\"\"Generate description and summary\n",
    "Analyze this protein dataset to determine what predicts the ’Maximum activation value’ and ‘Amino acids of\n",
    "highest activated indices in protein’ columns. This description should be as concise as possible but sufficient to\n",
    "predict these two columns on held-out data given only the description and the rest of the protein metadata\n",
    "provided. The feature could be specific to a protein family, a structural motif, a sequence motif, a functional\n",
    "role, etc. These WILL be used to predict how much unseen proteins are activated by the feature so only\n",
    "highlight relevant factors for this.\n",
    "\n",
    "Focus on:\n",
    "• Properties of proteins from the metadata that are associated with high vs medium vs low activation.\n",
    "• Where in the protein sequence activation occurs (in relation to the protein sequence, length, structure,\n",
    "  or other properties)\n",
    "• What functional annotations (binding sites, domains, etc.) and amino acids are present at or near the\n",
    "  activated positions\n",
    "• This description that will be used to help predict missing activation values should start with:\n",
    "  “The activation patterns are characterized by:”\n",
    "\n",
    "Then, in 1 sentence, summarize what biological feature or pattern this neural network activation is detecting.\n",
    "This concise summary should start with “The feature activates on”.\n",
    "\n",
    "Protein record:\n",
    "{TABLE}\n",
    "\"\"\"\n",
    "\n",
    "def build_prompt(table_df: pd.DataFrame) -> str:\n",
    "    table_md = table_df.to_markdown(index=False)\n",
    "    return PROMPT_TEMPLATE.replace(\"{TABLE}\", table_md)\n",
    "\n",
    "def call_claude(prompt: str) -> str:\n",
    "    \"\"\"Call Claude, return raw text.\"\"\"\n",
    "    resp = client.messages.create(\n",
    "        model=MODEL_NAME,\n",
    "        max_tokens=MAX_TOKENS,\n",
    "        temperature=TEMPERATURE,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "    )\n",
    "    return resp.content[0].text\n",
    "\n",
    "def parse_description_and_summary(text: str) -> dict:\n",
    "    \"\"\"\n",
    "    Best-effort parse: extract the long description (must start with the required phrase)\n",
    "    and the one-sentence summary (starts with 'The feature activates on').\n",
    "    Falls back to raw if patterns aren’t found.\n",
    "    \"\"\"\n",
    "    desc = \"\"\n",
    "    summ = \"\"\n",
    "    lines = [l.strip() for l in text.splitlines() if l.strip()]\n",
    "\n",
    "    # Find the description block\n",
    "    start_idx = None\n",
    "    for i, l in enumerate(lines):\n",
    "        if l.lower().startswith(\"the activation patterns are characterized by:\"):\n",
    "            start_idx = i\n",
    "            break\n",
    "    if start_idx is not None:\n",
    "        # collect until we hit the summary or end\n",
    "        buff = []\n",
    "        for j in range(start_idx, len(lines)):\n",
    "            if lines[j].lower().startswith(\"the feature activates on\"):\n",
    "                break\n",
    "            buff.append(lines[j])\n",
    "        desc = \"\\n\".join(buff).strip()\n",
    "\n",
    "    # Find the one-sentence summary\n",
    "    for l in lines:\n",
    "        if l.lower().startswith(\"the feature activates on\"):\n",
    "            # keep first sentence\n",
    "            summ = l.split(\"\\n\")[0].strip()\n",
    "            break\n",
    "\n",
    "    return {\n",
    "        \"description\": desc or \"\",\n",
    "        \"summary\": summ or \"\",\n",
    "        \"raw\": text.strip()\n",
    "    }\n",
    "\n",
    "# --- Main loop over feature datasets ---\n",
    "# Expects: feature_datasets: Dict[int, pd.DataFrame]\n",
    "results_rows = []\n",
    "\n",
    "processed = 0\n",
    "for fid, df in list(feature_datasets.items())[:3]:\n",
    "    # Build a compact table for the model\n",
    "    view = _coerce_and_trim_cols(df, PREFERRED_COLS)\n",
    "    prompt = build_prompt(view)\n",
    "\n",
    "    try:\n",
    "        text = call_claude(prompt)\n",
    "        parsed = parse_description_and_summary(text)\n",
    "    except Exception as e:\n",
    "        parsed = {\"description\": \"\", \"summary\": \"\", \"raw\": f\"[ERROR] {e}\"}\n",
    "\n",
    "    results_rows.append({\n",
    "        \"feature_id\": fid,\n",
    "        \"n_rows_shown\": len(view),\n",
    "        \"description\": parsed[\"description\"],\n",
    "        \"summary\": parsed[\"summary\"],\n",
    "        \"raw_response\": parsed[\"raw\"],\n",
    "    })\n",
    "\n",
    "    processed += 1\n",
    "    if processed % CHECKPOINT_EVERY == 0:\n",
    "        pd.DataFrame(results_rows).to_parquet(OUTPUT_PATH, index=False)\n",
    "        print(f\"[checkpoint] saved {processed} → {OUTPUT_PATH}\")\n",
    "\n",
    "# Final save\n",
    "df_results = pd.DataFrame(results_rows)\n",
    "df_results.to_csv(OUTPUT_PATH, index=False)\n",
    "print(f\"[done] {len(df_results)} features → {OUTPUT_PATH}\")\n",
    "df_results.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "2167",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[72]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m fid, df \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\u001b[43mfeature_datasets\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m2167\u001b[39;49m\u001b[43m]\u001b[49m.items())[:\u001b[32m3\u001b[39m]:\n\u001b[32m      2\u001b[39m     \u001b[38;5;66;03m# Build a compact table for the model\u001b[39;00m\n\u001b[32m      3\u001b[39m     view = _coerce_and_trim_cols(df, PREFERRED_COLS)\n\u001b[32m      4\u001b[39m     prompt = build_prompt(view)\n",
      "\u001b[31mKeyError\u001b[39m: 2167"
     ]
    }
   ],
   "source": [
    "for fid, df in list(feature_datasets.items())[:3]:\n",
    "    # Build a compact table for the model\n",
    "    view = _coerce_and_trim_cols(df, PREFERRED_COLS)\n",
    "    prompt = build_prompt(view)\n",
    "\n",
    "    try:\n",
    "        text = call_claude(prompt)\n",
    "        parsed = parse_description_and_summary(text)\n",
    "    except Exception as e:\n",
    "        parsed = {\"description\": \"\", \"summary\": \"\", \"raw\": f\"[ERROR] {e}\"}\n",
    "\n",
    "    results_rows.append({\n",
    "        \"feature_id\": fid,\n",
    "        \"n_rows_shown\": len(view),\n",
    "        \"description\": parsed[\"description\"],\n",
    "        \"summary\": parsed[\"summary\"],\n",
    "        \"raw_response\": parsed[\"raw\"],\n",
    "    })\n",
    "\n",
    "    processed += 1\n",
    "    if processed % CHECKPOINT_EVERY == 0:\n",
    "        pd.DataFrame(results_rows).to_parquet(OUTPUT_PATH, index=False)\n",
    "        print(f\"[checkpoint] saved {processed} → {OUTPUT_PATH}\")\n",
    "\n",
    "# Final save\n",
    "df_results = pd.DataFrame(results_rows)\n",
    "df_results.to_csv(OUTPUT_PATH, index=False)\n",
    "print(f\"[done] {len(df_results)} features → {OUTPUT_PATH}\")\n",
    "df_results.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.13 ('interplm')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1106d1d489397abf5d77132595a521cf67d890f951d991cd34215b053d2a27e6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
