{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "from anthropic import Anthropic\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get key from environment\n",
    "api_key = os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "\n",
    "# Initialize client\n",
    "client = Anthropic(api_key=api_key)\n",
    "\n",
    "# Send a simple prompt\n",
    "response = client.messages.create(\n",
    "    model=\"claude-3-7-sonnet-20250219\",\n",
    "    max_tokens=200,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Say hello\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response.content[0].text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/.cs/conda/envs/interplm/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd, torch, os, gc\n",
    "from interplm.sae.inference import load_sae_from_hf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "DEVICE=\"cuda\"\n",
    "\n",
    "DATA_DIR = Path(\"esm_sae_results\"); DATA_DIR.mkdir(exist_ok=True)\n",
    "SEQUENCES_DIR = Path(\"/home/ec2-user/InterPLM/data/uniprot/subset_25k.csv\")\n",
    "# ANNOTATIONS_DIR = Path(\"uniprotkb_swissprot_annotations.tsv.gz\")\n",
    "ANNOTATIONS_DIR = Path(\"/home/ec2-user/InterPLM/subset_annotations.tsv.gz\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 6)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "parts = [pd.read_pickle(p) for p in sorted(glob.glob(str(DATA_DIR / \"sae_features_rank*.final.pkl\")))]\n",
    "features_all = pd.concat(parts, ignore_index=True).drop_duplicates(subset=[\"uniprot_id\"])\n",
    "features_all.to_pickle(DATA_DIR / \"sae_features_all.pkl\")\n",
    "features_all.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uniprot_id</th>\n",
       "      <th>length</th>\n",
       "      <th>features</th>\n",
       "      <th>max_activation</th>\n",
       "      <th>n_active_features</th>\n",
       "      <th>reconstruction_mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q9GL23</td>\n",
       "      <td>50</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002...</td>\n",
       "      <td>1.265625</td>\n",
       "      <td>1876</td>\n",
       "      <td>45.198380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q6GZU6</td>\n",
       "      <td>50</td>\n",
       "      <td>[0.00023197175, 0.0, 0.0, 0.0, 0.0013056946, 0...</td>\n",
       "      <td>0.843262</td>\n",
       "      <td>2168</td>\n",
       "      <td>13.467114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P9WJG6</td>\n",
       "      <td>50</td>\n",
       "      <td>[0.0, 0.00057144166, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>0.935059</td>\n",
       "      <td>1740</td>\n",
       "      <td>12.720748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P18924</td>\n",
       "      <td>51</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.000...</td>\n",
       "      <td>0.956543</td>\n",
       "      <td>1799</td>\n",
       "      <td>11.394856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q08076</td>\n",
       "      <td>52</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.000...</td>\n",
       "      <td>1.139648</td>\n",
       "      <td>1772</td>\n",
       "      <td>24.694654</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  uniprot_id  length                                           features  \\\n",
       "0     Q9GL23      50  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002...   \n",
       "1     Q6GZU6      50  [0.00023197175, 0.0, 0.0, 0.0, 0.0013056946, 0...   \n",
       "2     P9WJG6      50  [0.0, 0.00057144166, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "3     P18924      51  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.000...   \n",
       "4     Q08076      52  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.000...   \n",
       "\n",
       "   max_activation  n_active_features  reconstruction_mse  \n",
       "0        1.265625               1876           45.198380  \n",
       "1        0.843262               2168           13.467114  \n",
       "2        0.935059               1740           12.720748  \n",
       "3        0.956543               1799           11.394856  \n",
       "4        1.139648               1772           24.694654  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations_df = pd.read_csv(ANNOTATIONS_DIR, sep=\"\\t\", compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Entry</th>\n",
       "      <th>Reviewed</th>\n",
       "      <th>Protein names</th>\n",
       "      <th>Length</th>\n",
       "      <th>Sequence</th>\n",
       "      <th>EC number</th>\n",
       "      <th>Active site</th>\n",
       "      <th>Binding site</th>\n",
       "      <th>Cofactor</th>\n",
       "      <th>Disulfide bond</th>\n",
       "      <th>...</th>\n",
       "      <th>Helix</th>\n",
       "      <th>Turn</th>\n",
       "      <th>Beta strand</th>\n",
       "      <th>Coiled coil</th>\n",
       "      <th>Domain [CC]</th>\n",
       "      <th>Compositional bias</th>\n",
       "      <th>Domain [FT]</th>\n",
       "      <th>Motif</th>\n",
       "      <th>Region</th>\n",
       "      <th>Zinc finger</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A0A009IHW8</td>\n",
       "      <td>reviewed</td>\n",
       "      <td>2' cyclic ADP-D-ribose synthase AbTIR (2'cADPR...</td>\n",
       "      <td>269</td>\n",
       "      <td>MSLEQKKGADIISKILQIQNSIGKTTSPSTLKTKLSEISRKEQENA...</td>\n",
       "      <td>3.2.2.-; 3.2.2.6</td>\n",
       "      <td>ACT_SITE 208; /evidence=\"ECO:0000255|PROSITE-P...</td>\n",
       "      <td>BINDING 143; /ligand=\"NAD(+)\"; /ligand_id=\"ChE...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>HELIX 143..145; /evidence=\"ECO:0007829|PDB:7UW...</td>\n",
       "      <td>TURN 146..149; /evidence=\"ECO:0007829|PDB:7UWG...</td>\n",
       "      <td>STRAND 135..142; /evidence=\"ECO:0007829|PDB:7U...</td>\n",
       "      <td>COILED 31..99; /evidence=\"ECO:0000255\"</td>\n",
       "      <td>DOMAIN: The TIR domain mediates NAD(+) hydrola...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DOMAIN 133..266; /note=\"TIR\"; /evidence=\"ECO:0...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A0A059WI14</td>\n",
       "      <td>reviewed</td>\n",
       "      <td>Trivalent organoarsenical cleaving enzyme (EC ...</td>\n",
       "      <td>161</td>\n",
       "      <td>MKYAHVGLNVTNLEKSIEFYSKLFGAEPVKVKPDYAKFLLESPGLN...</td>\n",
       "      <td>1.13.11.-</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BINDING 5; /ligand=\"Fe(2+)\"; /ligand_id=\"ChEBI...</td>\n",
       "      <td>COFACTOR: Name=Fe(2+); Xref=ChEBI:CHEBI:29033;...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DOMAIN: The thiolates of the vicinal cysteine ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DOMAIN 2..119; /note=\"VOC\"; /evidence=\"ECO:000...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A0A067XGX8</td>\n",
       "      <td>reviewed</td>\n",
       "      <td>Phospho-2-dehydro-3-deoxyheptonate aldolase 2,...</td>\n",
       "      <td>512</td>\n",
       "      <td>MALTATATTRGGSALPNSCLQTPKFQSLQKPTFISSFPTNKKTKPR...</td>\n",
       "      <td>2.5.1.54</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BINDING 126; /ligand=\"Mn(2+)\"; /ligand_id=\"ChE...</td>\n",
       "      <td>COFACTOR: Name=Mn(2+); Xref=ChEBI:CHEBI:29035;...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>REGION 37..57; /note=\"Disordered\"; /evidence=\"...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A0A067XH53</td>\n",
       "      <td>reviewed</td>\n",
       "      <td>Phospho-2-dehydro-3-deoxyheptonate aldolase 1,...</td>\n",
       "      <td>533</td>\n",
       "      <td>MALSTNSTTSSLLPKTPLVQQPLLKNASLPTTTKAIRFIQPISAIH...</td>\n",
       "      <td>2.5.1.54</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BINDING 145; /ligand=\"Mn(2+)\"; /ligand_id=\"ChE...</td>\n",
       "      <td>COFACTOR: Name=Mn(2+); Xref=ChEBI:CHEBI:29035;...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPBIAS 47..56; /note=\"Polar residues\"; /evid...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>REGION 47..70; /note=\"Disordered\"; /evidence=\"...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A0A0A1H8I4</td>\n",
       "      <td>reviewed</td>\n",
       "      <td>Aconitate isomerase (AI) (EC 5.3.3.7)</td>\n",
       "      <td>262</td>\n",
       "      <td>MFPRLPTLALGALLLASTPLLAAQPVTTLTVLSSGGIMGTIREVAP...</td>\n",
       "      <td>5.3.3.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Entry  Reviewed                                      Protein names  \\\n",
       "0  A0A009IHW8  reviewed  2' cyclic ADP-D-ribose synthase AbTIR (2'cADPR...   \n",
       "1  A0A059WI14  reviewed  Trivalent organoarsenical cleaving enzyme (EC ...   \n",
       "2  A0A067XGX8  reviewed  Phospho-2-dehydro-3-deoxyheptonate aldolase 2,...   \n",
       "3  A0A067XH53  reviewed  Phospho-2-dehydro-3-deoxyheptonate aldolase 1,...   \n",
       "4  A0A0A1H8I4  reviewed              Aconitate isomerase (AI) (EC 5.3.3.7)   \n",
       "\n",
       "   Length                                           Sequence  \\\n",
       "0     269  MSLEQKKGADIISKILQIQNSIGKTTSPSTLKTKLSEISRKEQENA...   \n",
       "1     161  MKYAHVGLNVTNLEKSIEFYSKLFGAEPVKVKPDYAKFLLESPGLN...   \n",
       "2     512  MALTATATTRGGSALPNSCLQTPKFQSLQKPTFISSFPTNKKTKPR...   \n",
       "3     533  MALSTNSTTSSLLPKTPLVQQPLLKNASLPTTTKAIRFIQPISAIH...   \n",
       "4     262  MFPRLPTLALGALLLASTPLLAAQPVTTLTVLSSGGIMGTIREVAP...   \n",
       "\n",
       "          EC number                                        Active site  \\\n",
       "0  3.2.2.-; 3.2.2.6  ACT_SITE 208; /evidence=\"ECO:0000255|PROSITE-P...   \n",
       "1         1.13.11.-                                                NaN   \n",
       "2          2.5.1.54                                                NaN   \n",
       "3          2.5.1.54                                                NaN   \n",
       "4           5.3.3.7                                                NaN   \n",
       "\n",
       "                                        Binding site  \\\n",
       "0  BINDING 143; /ligand=\"NAD(+)\"; /ligand_id=\"ChE...   \n",
       "1  BINDING 5; /ligand=\"Fe(2+)\"; /ligand_id=\"ChEBI...   \n",
       "2  BINDING 126; /ligand=\"Mn(2+)\"; /ligand_id=\"ChE...   \n",
       "3  BINDING 145; /ligand=\"Mn(2+)\"; /ligand_id=\"ChE...   \n",
       "4                                                NaN   \n",
       "\n",
       "                                            Cofactor Disulfide bond  ...  \\\n",
       "0                                                NaN            NaN  ...   \n",
       "1  COFACTOR: Name=Fe(2+); Xref=ChEBI:CHEBI:29033;...            NaN  ...   \n",
       "2  COFACTOR: Name=Mn(2+); Xref=ChEBI:CHEBI:29035;...            NaN  ...   \n",
       "3  COFACTOR: Name=Mn(2+); Xref=ChEBI:CHEBI:29035;...            NaN  ...   \n",
       "4                                                NaN            NaN  ...   \n",
       "\n",
       "                                               Helix  \\\n",
       "0  HELIX 143..145; /evidence=\"ECO:0007829|PDB:7UW...   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "\n",
       "                                                Turn  \\\n",
       "0  TURN 146..149; /evidence=\"ECO:0007829|PDB:7UWG...   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "\n",
       "                                         Beta strand  \\\n",
       "0  STRAND 135..142; /evidence=\"ECO:0007829|PDB:7U...   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "\n",
       "                              Coiled coil  \\\n",
       "0  COILED 31..99; /evidence=\"ECO:0000255\"   \n",
       "1                                     NaN   \n",
       "2                                     NaN   \n",
       "3                                     NaN   \n",
       "4                                     NaN   \n",
       "\n",
       "                                         Domain [CC]  \\\n",
       "0  DOMAIN: The TIR domain mediates NAD(+) hydrola...   \n",
       "1  DOMAIN: The thiolates of the vicinal cysteine ...   \n",
       "2                                                NaN   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "\n",
       "                                  Compositional bias  \\\n",
       "0                                                NaN   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "3  COMPBIAS 47..56; /note=\"Polar residues\"; /evid...   \n",
       "4                                                NaN   \n",
       "\n",
       "                                         Domain [FT] Motif  \\\n",
       "0  DOMAIN 133..266; /note=\"TIR\"; /evidence=\"ECO:0...   NaN   \n",
       "1  DOMAIN 2..119; /note=\"VOC\"; /evidence=\"ECO:000...   NaN   \n",
       "2                                                NaN   NaN   \n",
       "3                                                NaN   NaN   \n",
       "4                                                NaN   NaN   \n",
       "\n",
       "                                              Region Zinc finger  \n",
       "0                                                NaN         NaN  \n",
       "1                                                NaN         NaN  \n",
       "2  REGION 37..57; /note=\"Disordered\"; /evidence=\"...         NaN  \n",
       "3  REGION 47..70; /note=\"Disordered\"; /evidence=\"...         NaN  \n",
       "4                                                NaN         NaN  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotations_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num features 10240\n",
      "Selected 1200 features out of 10240\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "# Parameters\n",
    "N_FEATURES = 1200\n",
    "BINS = np.arange(0, 1.1, 0.1)\n",
    "\n",
    "# Randomly select feature ids\n",
    "all_feature_ids = list(range(len(features_all.iloc[0].features)))\n",
    "print(\"num features\", len(all_feature_ids))\n",
    "selected_features = random.sample(all_feature_ids, N_FEATURES)\n",
    "\n",
    "print(f\"Selected {len(selected_features)} features out of {len(all_feature_ids)}\")\n",
    "\n",
    "# Build dataset for each feature\n",
    "feature_datasets = {}\n",
    "\n",
    "# Predefine bin labels\n",
    "bin_labels = [f\"{BINS[i]:.1f}-{BINS[i+1]:.1f}\" for i in range(len(BINS)-1)]\n",
    "\n",
    "for fid in selected_features:\n",
    "    # Extract activations for this feature\n",
    "    activations = [f[fid] for f in features_all[\"features\"]]\n",
    "    df = pd.DataFrame({\n",
    "        \"uniprot_id\": features_all[\"uniprot_id\"],\n",
    "        \"activation\": activations\n",
    "    })\n",
    "\n",
    "    # Assign bins\n",
    "    df[\"bin\"] = pd.cut(df[\"activation\"], bins=BINS, labels=bin_labels, include_lowest=True)\n",
    "\n",
    "    sampled = []\n",
    "\n",
    "    # Sample proteins per bin\n",
    "    for b in df[\"bin\"].dropna().unique():\n",
    "        bin_df = df[df[\"bin\"] == b]\n",
    "        n = 10 if b == \"0.9-1.0\" else 2\n",
    "        sampled.extend(bin_df.sample(min(len(bin_df), n), random_state=42).to_dict(orient=\"records\"))\n",
    "\n",
    "    # Add 10 random zero-activation proteins \n",
    "    zero_df = df[df[\"activation\"] == 0.0]\n",
    "    if len(zero_df) > 0:\n",
    "        sampled.extend(zero_df.sample(min(len(zero_df), 10), random_state=42).to_dict(orient=\"records\"))\n",
    "\n",
    "    # Merge with metadata from annotations_df\n",
    "    sampled_df = pd.DataFrame(sampled)\n",
    "    merged = sampled_df.merge(annotations_df, left_on=\"uniprot_id\", right_on=\"Entry\", how=\"left\")\n",
    "\n",
    "    feature_datasets[fid] = merged\n",
    "\n",
    "# Example feature dataset\n",
    "example_fid = selected_features[0]\n",
    "feature_datasets[example_fid].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'features_all' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m#Stakc into [num_proteins, num_features]\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m X = np.vstack(\u001b[43mfeatures_all\u001b[49m[\u001b[33m'\u001b[39m\u001b[33mfeatures\u001b[39m\u001b[33m'\u001b[39m].values) \u001b[38;5;66;03m#Shape (N, F)\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m#Max activation per feature across all proteins\u001b[39;00m\n\u001b[32m      7\u001b[39m max_per_feature = X.max(axis=\u001b[32m0\u001b[39m) \u001b[38;5;66;03m# shape: (F,)\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'features_all' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "#Stakc into [num_proteins, num_features]\n",
    "X = np.vstack(features_all['features'].values) #Shape (N, F)\n",
    "\n",
    "#Max activation per feature across all proteins\n",
    "max_per_feature = X.max(axis=0) # shape: (F,)\n",
    "eps = 1e-12\n",
    "max_safe = np.where(max_per_feature > 0, max_per_feature, eps)\n",
    "#Normalize\n",
    "X_norm = X / max_safe\n",
    "\n",
    "#Save back\n",
    "features_all = features_all.copy()\n",
    "features_all[\"features_norm\"] = [row for row in X_norm]\n",
    "print(\"Original max activation (feature 0):\", X[:,0].max())\n",
    "print(\"Normalized max activation (feature 0):\", X_norm[:,0].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "# Parameters\n",
    "N_FEATURES = 1200\n",
    "BINS = np.arange(0, 1.1, 0.1)\n",
    "\n",
    "# Randomly select feature ids\n",
    "all_feature_ids = list(range(len(features_all.iloc[0].features)))\n",
    "print(\"num features\", len(all_feature_ids))\n",
    "selected_features = random.sample(all_feature_ids, N_FEATURES)\n",
    "\n",
    "print(f\"Selected {len(selected_features)} features out of {len(all_feature_ids)}\")\n",
    "\n",
    "# Build dataset for each feature\n",
    "feature_datasets = {}\n",
    "\n",
    "# Predefine bin labels\n",
    "bin_labels = [f\"{BINS[i]:.1f}-{BINS[i+1]:.1f}\" for i in range(len(BINS)-1)]\n",
    "\n",
    "for fid in selected_features:\n",
    "    # Extract activations for this feature\n",
    "    activations = [f[fid] for f in features_all[\"features_norm\"]]\n",
    "    df = pd.DataFrame({\n",
    "        \"uniprot_id\": features_all[\"uniprot_id\"],\n",
    "        \"activation\": activations\n",
    "    })\n",
    "\n",
    "    # Assign bins\n",
    "    df[\"bin\"] = pd.cut(df[\"activation\"], bins=BINS, labels=bin_labels, include_lowest=True)\n",
    "\n",
    "    sampled = []\n",
    "\n",
    "    # Sample proteins per bin\n",
    "    for b in df[\"bin\"].dropna().unique():\n",
    "        bin_df = df[df[\"bin\"] == b]\n",
    "        n = 10 if b == \"0.9-1.0\" else 2\n",
    "        sampled.extend(bin_df.sample(min(len(bin_df), n), random_state=42).to_dict(orient=\"records\"))\n",
    "\n",
    "    # Add 10 random zero-activation proteins \n",
    "    zero_df = df[df[\"activation\"] == 0.0]\n",
    "    if len(zero_df) > 0:\n",
    "        sampled.extend(zero_df.sample(min(len(zero_df), 10), random_state=42).to_dict(orient=\"records\"))\n",
    "\n",
    "    # Merge with metadata from annotations_df\n",
    "    sampled_df = pd.DataFrame(sampled)\n",
    "    merged = sampled_df.merge(annotations_df, left_on=\"uniprot_id\", right_on=\"Entry\", how=\"left\")\n",
    "\n",
    "    feature_datasets[fid] = merged\n",
    "\n",
    "# Example feature dataset\n",
    "example_fid = selected_features[0]\n",
    "feature_datasets[example_fid].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Setup (once per notebook) ---\n",
    "# pip install anthropic python-dotenv\n",
    "from anthropic import Anthropic\n",
    "from dotenv import load_dotenv\n",
    "import os, time, json, math, textwrap\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Dict\n",
    "\n",
    "# Load .env (expects ANTHROPIC_API_KEY=...)\n",
    "load_dotenv()\n",
    "client = Anthropic(api_key=os.getenv(\"ANTHROPIC_API_KEY\"))\n",
    "\n",
    "# --- Config ---\n",
    "MODEL_NAME = \"claude-3-5-sonnet-20240620\"\n",
    "MAX_TOKENS = 800  # enough for description + summary\n",
    "TEMPERATURE = 0.0 # deterministic\n",
    "CHECKPOINT_EVERY = 50\n",
    "OUTPUT_PATH = \"claude_feature_annotations.parquet\"\n",
    "\n",
    "# Columns to show Claude (customize as you like)\n",
    "# We'll include what exists; missing columns are auto-dropped\n",
    "PREFERRED_COLS = [\n",
    "    # keys/ids\n",
    "    \"uniprot_id\", \"Entry\", \"Protein names\",\n",
    "    # size/sequence shape\n",
    "    \"Length\",\n",
    "    # functional annotations\n",
    "    \"EC number\", \"Active site\", \"Binding site\", \"Cofactor\", \"Disulfide bond\",\n",
    "    \"Helix\", \"Turn\", \"Beta strand\", \"Coiled coil\",\n",
    "    \"Domain [CC]\", \"Compositional bias\", \"Domain [FT]\", \"Motif\", \"Region\", \"Zinc finger\",\n",
    "    # your per-feature fields\n",
    "    \"activation\", \"bin\",\n",
    "    # optional (only used if present)\n",
    "    \"activated_indices\", \"activated_aas\"\n",
    "]\n",
    "\n",
    "# Limit rows/cols so the table fits comfortably in context\n",
    "MAX_ROWS = 80   # you can raise/lower if you hit token limits\n",
    "TRUNCATE_STR_LEN = 120  # truncate long text fields so tables stay compact\n",
    "\n",
    "\n",
    "def _coerce_and_trim_cols(df: pd.DataFrame, cols: list[str]) -> pd.DataFrame:\n",
    "    \"\"\"Select existing columns, stringify, and truncate long strings so the table is compact.\"\"\"\n",
    "    use_cols = [c for c in cols if c in df.columns]\n",
    "    if not use_cols:\n",
    "        # Fallback: show whatever is available\n",
    "        use_cols = list(df.columns)\n",
    "\n",
    "    out = df[use_cols].copy()\n",
    "\n",
    "    # Coerce to string and truncate long values\n",
    "    for c in use_cols:\n",
    "        out[c] = out[c].astype(str).str.replace(r\"\\s+\", \" \", regex=True)\n",
    "        out[c] = out[c].apply(lambda s: s[:TRUNCATE_STR_LEN] + \"…\" if len(s) > TRUNCATE_STR_LEN else s)\n",
    "\n",
    "    # Keep only first MAX_ROWS to control token usage\n",
    "    return out.head(MAX_ROWS)\n",
    "\n",
    "\n",
    "PROMPT_TEMPLATE = \"\"\"Generate description and summary\n",
    "Analyze this protein dataset to determine what predicts the ’Maximum activation value’ and ‘Amino acids of\n",
    "highest activated indices in protein’ columns. This description should be as concise as possible but sufficient to\n",
    "predict these two columns on held-out data given only the description and the rest of the protein metadata\n",
    "provided. The feature could be specific to a protein family, a structural motif, a sequence motif, a functional\n",
    "role, etc. These WILL be used to predict how much unseen proteins are activated by the feature so only\n",
    "highlight relevant factors for this.\n",
    "\n",
    "Focus on:\n",
    "• Properties of proteins from the metadata that are associated with high vs medium vs low activation.\n",
    "• Where in the protein sequence activation occurs (in relation to the protein sequence, length, structure,\n",
    "  or other properties)\n",
    "• What functional annotations (binding sites, domains, etc.) and amino acids are present at or near the\n",
    "  activated positions\n",
    "• This description that will be used to help predict missing activation values should start with:\n",
    "  “The activation patterns are characterized by:”\n",
    "\n",
    "Then, in 1 sentence, summarize what biological feature or pattern this neural network activation is detecting.\n",
    "This concise summary should start with “The feature activates on”.\n",
    "\n",
    "Protein record:\n",
    "{TABLE}\n",
    "\"\"\"\n",
    "\n",
    "def build_prompt(table_df: pd.DataFrame) -> str:\n",
    "    table_md = table_df.to_markdown(index=False)\n",
    "    return PROMPT_TEMPLATE.replace(\"{TABLE}\", table_md)\n",
    "\n",
    "def call_claude(prompt: str) -> str:\n",
    "    \"\"\"Call Claude, return raw text.\"\"\"\n",
    "    resp = client.messages.create(\n",
    "        model=MODEL_NAME,\n",
    "        max_tokens=MAX_TOKENS,\n",
    "        temperature=TEMPERATURE,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "    )\n",
    "    return resp.content[0].text\n",
    "\n",
    "def parse_description_and_summary(text: str) -> dict:\n",
    "    \"\"\"\n",
    "    Best-effort parse: extract the long description (must start with the required phrase)\n",
    "    and the one-sentence summary (starts with 'The feature activates on').\n",
    "    Falls back to raw if patterns aren’t found.\n",
    "    \"\"\"\n",
    "    desc = \"\"\n",
    "    summ = \"\"\n",
    "    lines = [l.strip() for l in text.splitlines() if l.strip()]\n",
    "\n",
    "    # Find the description block\n",
    "    start_idx = None\n",
    "    for i, l in enumerate(lines):\n",
    "        if l.lower().startswith(\"the activation patterns are characterized by:\"):\n",
    "            start_idx = i\n",
    "            break\n",
    "    if start_idx is not None:\n",
    "        # collect until we hit the summary or end\n",
    "        buff = []\n",
    "        for j in range(start_idx, len(lines)):\n",
    "            if lines[j].lower().startswith(\"the feature activates on\"):\n",
    "                break\n",
    "            buff.append(lines[j])\n",
    "        desc = \"\\n\".join(buff).strip()\n",
    "\n",
    "    # Find the one-sentence summary\n",
    "    for l in lines:\n",
    "        if l.lower().startswith(\"the feature activates on\"):\n",
    "            # keep first sentence\n",
    "            summ = l.split(\"\\n\")[0].strip()\n",
    "            break\n",
    "\n",
    "    return {\n",
    "        \"description\": desc or \"\",\n",
    "        \"summary\": summ or \"\",\n",
    "        \"raw\": text.strip()\n",
    "    }\n",
    "\n",
    "# --- Main loop over feature datasets ---\n",
    "# Expects: feature_datasets: Dict[int, pd.DataFrame]\n",
    "results_rows = []\n",
    "\n",
    "processed = 0\n",
    "for fid, df in feature_datasets[0].items():\n",
    "    # Build a compact table for the model\n",
    "    view = _coerce_and_trim_cols(df, PREFERRED_COLS)\n",
    "    prompt = build_prompt(view)\n",
    "\n",
    "    try:\n",
    "        text = call_claude(prompt)\n",
    "        parsed = parse_description_and_summary(text)\n",
    "    except Exception as e:\n",
    "        parsed = {\"description\": \"\", \"summary\": \"\", \"raw\": f\"[ERROR] {e}\"}\n",
    "\n",
    "    results_rows.append({\n",
    "        \"feature_id\": fid,\n",
    "        \"n_rows_shown\": len(view),\n",
    "        \"description\": parsed[\"description\"],\n",
    "        \"summary\": parsed[\"summary\"],\n",
    "        \"raw_response\": parsed[\"raw\"],\n",
    "    })\n",
    "\n",
    "    processed += 1\n",
    "    if processed % CHECKPOINT_EVERY == 0:\n",
    "        pd.DataFrame(results_rows).to_parquet(OUTPUT_PATH, index=False)\n",
    "        print(f\"[checkpoint] saved {processed} → {OUTPUT_PATH}\")\n",
    "\n",
    "# Final save\n",
    "df_results = pd.DataFrame(results_rows)\n",
    "df_results.to_parquet(OUTPUT_PATH, index=False)\n",
    "print(f\"[done] {len(df_results)} features → {OUTPUT_PATH}\")\n",
    "df_results.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick the first feature id\n",
    "first_fid = list(feature_datasets.keys())[0]\n",
    "\n",
    "# Get its protein dataframe\n",
    "df = feature_datasets[first_fid]\n",
    "\n",
    "# Build a compact table for Claude\n",
    "view = _coerce_and_trim_cols(df, PREFERRED_COLS)\n",
    "prompt = build_prompt(view)\n",
    "\n",
    "# Send to Claude\n",
    "text = call_claude(prompt)\n",
    "parsed = parse_description_and_summary(text)\n",
    "\n",
    "print(\"Feature ID:\", first_fid)\n",
    "print(\"Description:\\n\", parsed[\"description\"])\n",
    "print(\"\\nSummary:\", parsed[\"summary\"])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.13 ('interplm')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1106d1d489397abf5d77132595a521cf67d890f951d991cd34215b053d2a27e6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
